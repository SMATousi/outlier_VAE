{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceff6ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 20),\n",
       " [99900, 99901, 99902, 99903, 99904, 99905, 99906, 99907, 99908, 99909],\n",
       " [(0, 14),\n",
       "  (0, 14),\n",
       "  (0, 14),\n",
       "  (0, 14),\n",
       "  (0, 14),\n",
       "  (0, 14),\n",
       "  (0, 14),\n",
       "  (0, 14),\n",
       "  (0, 14),\n",
       "  (0, 14)])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_dataset_refined(n_samples=100000, n_outliers=100, dimensions=20):\n",
    "    # Generate inliers uniformly within a range\n",
    "    inliers = np.random.uniform(-1, 1, size=(n_samples - n_outliers, dimensions))\n",
    "\n",
    "    # Prepare to generate outliers\n",
    "    outlier_samples = []\n",
    "    outlier_indices = []\n",
    "    outlier_dims = []\n",
    "\n",
    "    # Define different clusters of outliers\n",
    "    cluster_definitions = [\n",
    "        (0, 7),    # First 7 dimensions\n",
    "        (5, 10),   # 5 dimensions in the middle\n",
    "        (3, 8),    # Another set of 5 dimensions, overlapping with the first\n",
    "        (1, 6),    # 5 dimensions starting from second\n",
    "        (6, 10),   # Last 4 dimensions\n",
    "        (0, 4),    # First 4 dimensions\n",
    "        (2, 7),    # 5 dimensions starting from third\n",
    "        (4, 9),    # 5 dimensions starting near the middle\n",
    "        (3, 6),    # 3 dimensions in the middle\n",
    "        (7, 10)    # Last 3 dimensions\n",
    "    ]\n",
    "\n",
    "    # Adjust if the number of dimensions is different\n",
    "    if dimensions != 10:\n",
    "        scaling_factor = dimensions // 10\n",
    "        cluster_definitions = [(start * scaling_factor, min(end * scaling_factor, dimensions)) for start, end in cluster_definitions]\n",
    "\n",
    "    # Generate outliers for each cluster\n",
    "    for start, end in cluster_definitions:\n",
    "        for _ in range(n_outliers // len(cluster_definitions)):\n",
    "            # Normal values for non-deviating dimensions\n",
    "            normal_dims = list(set(range(dimensions)) - set(range(start, end)))\n",
    "            outlier = np.random.uniform(-1, 1, dimensions)\n",
    "            # More extreme values for the deviating dimensions\n",
    "            outlier[start:end] = np.random.uniform(1, 10, end - start)\n",
    "            \n",
    "            outlier_samples.append(outlier)\n",
    "            outlier_indices.append(len(inliers) + len(outlier_samples) - 1)\n",
    "            outlier_dims.append((start, end))\n",
    "\n",
    "    # Combine inliers and outliers\n",
    "    dataset = np.vstack([inliers, np.array(outlier_samples)])\n",
    "\n",
    "    return dataset, outlier_indices, outlier_dims\n",
    "\n",
    "# Example usage with 20 dimensions\n",
    "dataset_refined, outlier_indices_refined, outlier_dims_refined = generate_dataset_refined(dimensions=20)\n",
    "\n",
    "# Show some details about the generated dataset\n",
    "dataset_refined.shape, outlier_indices_refined[:10], outlier_dims_refined[:10]  # Displaying the shape and some of the outlier indices and dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b110d525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.85014661e+00  9.52686681e+00  8.04773645e+00  1.58311848e+00\n",
      "  1.11156149e+00  1.37681425e+00  6.63531996e+00  1.68197813e+00\n",
      "  7.34665157e+00  7.79260837e+00  9.20191937e+00  1.33944793e+00\n",
      "  6.84117393e+00  5.13482208e+00 -7.54419762e-01  1.28547983e-01\n",
      "  2.21224127e-03 -8.09729614e-02 -9.60154386e-01 -4.09687961e-01]\n",
      "(0, 14)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_refined[outlier_indices[1],:])\n",
    "print(outlier_dims_refined[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e199fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09381236 -0.29806589 -0.46524531 -0.38053464  0.0726339   0.37105881\n",
      " -0.59153716  0.91395219  0.52950104  0.65878209  0.271685   -0.49476214\n",
      "  0.58861706  0.66072736  0.47341661 -0.64412631 -0.96381697 -0.21474503\n",
      "  0.18271335 -0.21766542]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[outlier_indices[0]-1,:])\n",
    "# print(outlier_dims[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
