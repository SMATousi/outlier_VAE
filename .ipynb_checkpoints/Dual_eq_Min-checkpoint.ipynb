{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2aff49c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 10:18:37.313084: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-16 10:18:37.402955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-08-16 10:18:37.402970: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-16 10:18:40.083011: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-08-16 10:18:40.083111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-08-16 10:18:40.083120: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5325091428948298536\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 10:18:45.508784: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-16 10:18:45.537243: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-16 10:18:45.537471: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-08-16 10:18:45.537567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-08-16 10:18:45.537658: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-08-16 10:18:45.537742: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-08-16 10:18:45.537826: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-08-16 10:18:45.537908: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-08-16 10:18:45.537998: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-08-16 10:18:45.538667: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pygad\n",
    "import wandb\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9af5fffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "num_dimensions = 30\n",
    "\n",
    "# Generate random samples\n",
    "raw_data = np.random.rand(num_samples, num_dimensions)\n",
    "\n",
    "outlier_indices_1 = [0,1,2,3,4,5,6]\n",
    "outlyin_amount_1 = 20\n",
    "outlier_indices_2 = [0,2,4,6,8,10,12]\n",
    "outlyin_amount_2 = 10\n",
    "outlier_indices_3 = [0,3,6,9,12,15,18]\n",
    "outlyin_amount_3 = 5\n",
    "outlier_indices_4 = [0,4,8,12,16,20,24]\n",
    "outlyin_amount_4 = 2\n",
    "outlier_indices_5 = [0,5,10,15,20,25,29]\n",
    "outlyin_amount_5 = 1.1\n",
    "outlier_indices_6 = [0,1,2,3,4,5,6]\n",
    "outlyin_amount_6 = [20,15,10,5,2,1.1,1.05]\n",
    "\n",
    "corrupted_data = raw_data\n",
    "\n",
    "corrupted_data[100:120, outlier_indices_1] = outlyin_amount_1\n",
    "corrupted_data[200:220, outlier_indices_2] = outlyin_amount_2\n",
    "corrupted_data[300:320, outlier_indices_3] = outlyin_amount_3\n",
    "corrupted_data[400:420, outlier_indices_4] = outlyin_amount_4\n",
    "corrupted_data[500:520, outlier_indices_5] = outlyin_amount_5\n",
    "corrupted_data[600:620, outlier_indices_6] = outlyin_amount_6\n",
    "\n",
    "for outlier_gene_index in range(corrupted_data.shape[1]+1):\n",
    "    corrupted_data[700+outlier_gene_index,:outlier_gene_index] = outlyin_amount_1\n",
    "    \n",
    "\n",
    "# print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e0b531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 10:19:46.141426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-08-16 10:19:46.141585: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 3ms/step - loss: 1.2138 - reconstruction_loss: 1.3027 - kl_loss: 0.0394\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1334 - reconstruction_loss: 1.1524 - kl_loss: 0.1003\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1198 - reconstruction_loss: 1.0301 - kl_loss: 0.1756\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1112 - reconstruction_loss: 0.9824 - kl_loss: 0.2218\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9598 - reconstruction_loss: 0.9718 - kl_loss: 0.2145\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9217 - reconstruction_loss: 0.9341 - kl_loss: 0.1769\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9740 - reconstruction_loss: 0.9489 - kl_loss: 0.1408\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9726 - reconstruction_loss: 0.9414 - kl_loss: 0.1214\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9651 - reconstruction_loss: 0.9471 - kl_loss: 0.1101\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9042 - reconstruction_loss: 0.9335 - kl_loss: 0.0986\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9297 - reconstruction_loss: 0.9463 - kl_loss: 0.0922\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0197 - reconstruction_loss: 0.9514 - kl_loss: 0.0856\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9817 - reconstruction_loss: 0.9345 - kl_loss: 0.0827\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8419 - reconstruction_loss: 0.9415 - kl_loss: 0.0796\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9460 - reconstruction_loss: 0.9479 - kl_loss: 0.0778\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8218 - reconstruction_loss: 0.9431 - kl_loss: 0.0741\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0562 - reconstruction_loss: 0.9387 - kl_loss: 0.0726\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0989 - reconstruction_loss: 0.9470 - kl_loss: 0.0717\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9329 - reconstruction_loss: 0.9290 - kl_loss: 0.0720\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9428 - reconstruction_loss: 0.9391 - kl_loss: 0.0713\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7238 - reconstruction_loss: 0.9649 - kl_loss: 0.0716\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1387 - reconstruction_loss: 0.9349 - kl_loss: 0.0714\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9881 - reconstruction_loss: 0.9286 - kl_loss: 0.0723\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0312 - reconstruction_loss: 0.9333 - kl_loss: 0.0772\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8713 - reconstruction_loss: 0.9357 - kl_loss: 0.0804\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9922 - reconstruction_loss: 0.9435 - kl_loss: 0.0822\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0197 - reconstruction_loss: 0.9228 - kl_loss: 0.0840\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0382 - reconstruction_loss: 0.9181 - kl_loss: 0.0882\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1331 - reconstruction_loss: 0.9312 - kl_loss: 0.0894\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9575 - reconstruction_loss: 0.9249 - kl_loss: 0.0903\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0131 - reconstruction_loss: 0.9160 - kl_loss: 0.0892\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9824 - reconstruction_loss: 0.9110 - kl_loss: 0.0880\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8845 - reconstruction_loss: 0.9095 - kl_loss: 0.0870\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9325 - reconstruction_loss: 0.9107 - kl_loss: 0.0852\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9128 - reconstruction_loss: 0.9116 - kl_loss: 0.0856\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8564 - reconstruction_loss: 0.9231 - kl_loss: 0.0849\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7871 - reconstruction_loss: 0.9083 - kl_loss: 0.0804\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0268 - reconstruction_loss: 0.9039 - kl_loss: 0.0814\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8857 - reconstruction_loss: 0.9101 - kl_loss: 0.0798\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9538 - reconstruction_loss: 0.8945 - kl_loss: 0.0811\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9861 - reconstruction_loss: 0.8965 - kl_loss: 0.0787\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9085 - reconstruction_loss: 0.8958 - kl_loss: 0.0766\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8903 - reconstruction_loss: 0.9013 - kl_loss: 0.0756\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1048 - reconstruction_loss: 0.9072 - kl_loss: 0.0755\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0184 - reconstruction_loss: 0.9002 - kl_loss: 0.0755\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9280 - reconstruction_loss: 0.9066 - kl_loss: 0.0739\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9343 - reconstruction_loss: 0.8962 - kl_loss: 0.0741\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9314 - reconstruction_loss: 0.8988 - kl_loss: 0.0748\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9125 - reconstruction_loss: 0.9142 - kl_loss: 0.0713\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.1116 - reconstruction_loss: 0.8979 - kl_loss: 0.0708\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9029 - reconstruction_loss: 0.9022 - kl_loss: 0.0682\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8520 - reconstruction_loss: 0.9221 - kl_loss: 0.0720\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9352 - reconstruction_loss: 0.9177 - kl_loss: 0.0715\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7688 - reconstruction_loss: 0.8964 - kl_loss: 0.0714\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9226 - reconstruction_loss: 0.9231 - kl_loss: 0.0709\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9544 - reconstruction_loss: 0.9049 - kl_loss: 0.0710\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7507 - reconstruction_loss: 0.9199 - kl_loss: 0.0723\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0006 - reconstruction_loss: 0.9020 - kl_loss: 0.0696\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9069 - reconstruction_loss: 0.9016 - kl_loss: 0.0677\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9768 - reconstruction_loss: 0.9191 - kl_loss: 0.0669\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8649 - reconstruction_loss: 0.9242 - kl_loss: 0.0613\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9049 - reconstruction_loss: 0.9114 - kl_loss: 0.0654\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9061 - reconstruction_loss: 0.9005 - kl_loss: 0.0642\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9699 - reconstruction_loss: 0.9039 - kl_loss: 0.0647\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9791 - reconstruction_loss: 0.9117 - kl_loss: 0.0647\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9546 - reconstruction_loss: 0.9044 - kl_loss: 0.0625\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9608 - reconstruction_loss: 0.9036 - kl_loss: 0.0661\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9010 - reconstruction_loss: 0.9052 - kl_loss: 0.0643\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9111 - reconstruction_loss: 0.9039 - kl_loss: 0.0615\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7892 - reconstruction_loss: 0.9206 - kl_loss: 0.0592\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0770 - reconstruction_loss: 0.8934 - kl_loss: 0.0594\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9177 - reconstruction_loss: 0.9042 - kl_loss: 0.0604\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0112 - reconstruction_loss: 0.9043 - kl_loss: 0.0641\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9253 - reconstruction_loss: 0.8982 - kl_loss: 0.0607\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9790 - reconstruction_loss: 0.8988 - kl_loss: 0.0627\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9726 - reconstruction_loss: 0.9053 - kl_loss: 0.0631\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0461 - reconstruction_loss: 0.8905 - kl_loss: 0.0580\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9783 - reconstruction_loss: 0.8914 - kl_loss: 0.0561\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9736 - reconstruction_loss: 0.8872 - kl_loss: 0.0584\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9547 - reconstruction_loss: 0.8991 - kl_loss: 0.0555\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0131 - reconstruction_loss: 0.9175 - kl_loss: 0.0561\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8990 - reconstruction_loss: 0.9065 - kl_loss: 0.0556\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8293 - reconstruction_loss: 0.9088 - kl_loss: 0.0566\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8024 - reconstruction_loss: 0.9100 - kl_loss: 0.0539\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7704 - reconstruction_loss: 0.8982 - kl_loss: 0.0553\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 3ms/step - loss: 0.8481 - reconstruction_loss: 0.9065 - kl_loss: 0.0532\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9270 - reconstruction_loss: 0.8968 - kl_loss: 0.0513\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9338 - reconstruction_loss: 0.9013 - kl_loss: 0.0527\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9310 - reconstruction_loss: 0.8952 - kl_loss: 0.0513\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9105 - reconstruction_loss: 0.9100 - kl_loss: 0.0531\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8614 - reconstruction_loss: 0.9264 - kl_loss: 0.0499\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8666 - reconstruction_loss: 0.9251 - kl_loss: 0.0508\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9133 - reconstruction_loss: 0.9134 - kl_loss: 0.0508\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0618 - reconstruction_loss: 0.9064 - kl_loss: 0.0507\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 1.0089 - reconstruction_loss: 0.9035 - kl_loss: 0.0527\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9402 - reconstruction_loss: 0.9168 - kl_loss: 0.0505\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.8810 - reconstruction_loss: 0.8977 - kl_loss: 0.0490\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9303 - reconstruction_loss: 0.8948 - kl_loss: 0.0508\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.9083 - reconstruction_loss: 0.8998 - kl_loss: 0.0522\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 0.7781 - reconstruction_loss: 0.9128 - kl_loss: 0.0505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f406c46a1d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "latent_dim = 64\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(num_dimensions,))\n",
    "# x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "# x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# x = layers.Flatten()(x)\n",
    "x = layers.Dense(30, activation=\"tanh\")(encoder_inputs)\n",
    "x = layers.Dense(20, activation=\"tanh\")(x)\n",
    "x = layers.Dense(18, activation=\"tanh\")(x)\n",
    "x = layers.Dense(16, activation=\"tanh\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "# x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "# x = layers.Reshape((7, 7, 64))(x)\n",
    "# x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "x = layers.Dense(16, activation=\"tanh\")(latent_inputs)\n",
    "x = layers.Dense(18, activation=\"tanh\")(x)\n",
    "x = layers.Dense(20, activation=\"tanh\")(x)\n",
    "decoder_outputs = layers.Dense(num_dimensions, activation=\"tanh\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "#             reconstruction_loss = tf.reduce_mean(\n",
    "#                 tf.reduce_sum(\n",
    "#                     keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "#                 )\n",
    "#             )\n",
    "            reconstruction_loss = tf.keras.losses.MeanSquaredError()(data,reconstruction)\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "#             kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + 0.1 * kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "creditdata = np.concatenate([corrupted_data], axis=0)\n",
    "creditdata = np.expand_dims(creditdata, -1).astype(\"float32\")\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "vae.fit(creditdata, epochs=100, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640ebed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.47596\n",
      "84.47679\n",
      "84.478\n",
      "84.47864\n",
      "84.47622\n",
      "84.482574\n",
      "84.47655\n",
      "84.47663\n",
      "84.47732\n",
      "84.47903\n",
      "MEAN_MEAN =  84.47777\n",
      "std_MEAN =  0.0018735796\n"
     ]
    }
   ],
   "source": [
    "inliers = corrupted_data[5:80,:]\n",
    "mean_data = np.mean(corrupted_data, axis=0)\n",
    "outlier1 = corrupted_data[101,:]\n",
    "\n",
    "\n",
    "\n",
    "# #------------------ replacing the genes here ---------------------\n",
    "\n",
    "# inliers[:,1] = mean_data[1]\n",
    "\n",
    "# outlier1[1] = mean_data[1]\n",
    "\n",
    "# # ----------------------------------------------------------------\n",
    "\n",
    "mean_mean = []\n",
    "\n",
    "for step in range(10):\n",
    "\n",
    "    mean_data = mean_data.reshape([1,30])\n",
    "\n",
    "    z_mean, z_log_var, z = vae.encoder(mean_data)\n",
    "    reconstruction = vae.decoder(z)\n",
    "\n",
    "    reconstruction_loss = tf.keras.losses.MeanSquaredError()(mean_data,reconstruction)\n",
    "\n",
    "    print(reconstruction_loss.numpy())\n",
    "    \n",
    "    mean_mean.append(reconstruction_loss.numpy())\n",
    "\n",
    "print(\"MEAN_MEAN = \", np.mean(np.array(mean_mean)))\n",
    "print(\"std_MEAN = \", np.std(np.array(mean_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8248b1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean =  0.08685019\n",
      "mean =  0.0860827\n",
      "mean =  0.086468294\n",
      "mean =  0.086056724\n",
      "mean =  0.0910867\n",
      "mean =  0.08703793\n",
      "mean =  0.08570242\n",
      "mean =  0.08692093\n",
      "mean =  0.08628608\n",
      "mean =  0.08673436\n",
      "MEAN_MEAN =  0.08692263\n",
      "std_MEAN =  0.0014473866\n"
     ]
    }
   ],
   "source": [
    "mean_mean = []\n",
    "\n",
    "for step in range(10):\n",
    "\n",
    "    mean_ins_error = []\n",
    "\n",
    "    for index in range(inliers.shape[0]):\n",
    "\n",
    "        cand = inliers[index,:]\n",
    "\n",
    "        cand = cand.reshape([1,30])\n",
    "\n",
    "        mean_data = mean_data.reshape([1,30])\n",
    "\n",
    "        z_mean, z_log_var, z = vae.encoder(cand)\n",
    "        reconstruction = vae.decoder(z)\n",
    "\n",
    "        reconstruction_loss = tf.keras.losses.MeanSquaredError()(cand,reconstruction)\n",
    "\n",
    "        mean_ins_error.append(reconstruction_loss.numpy())\n",
    "\n",
    "    #     print(\"MEAN\", index, \" = \", reconstruction_loss.numpy())\n",
    "\n",
    "    mean_ins_error = np.array(mean_ins_error)\n",
    "    print(\"mean = \", np.mean(mean_ins_error))\n",
    "    \n",
    "    mean_mean.append(np.mean(mean_ins_error))\n",
    "    \n",
    "\n",
    "print(\"MEAN_MEAN = \", np.mean(np.array(mean_mean)))\n",
    "print(\"std_MEAN = \", np.std(np.array(mean_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "890006a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_test(solution): \n",
    "       \n",
    "    inliers = corrupted_data[10:13,:]\n",
    "    \n",
    "    avg_ins = np.mean(inliers, axis=0)\n",
    "    avg_ins = avg_ins.reshape([1,30])\n",
    "    \n",
    "    particle = corrupted_data[101,:]\n",
    "    particle = particle.reshape([1,30])\n",
    "    \n",
    "#     abn_subspace = solution * val_features[6728,:]\n",
    "    \n",
    "#     abn_subspace = abn_subspace.reshape([1,30])\n",
    "\n",
    "    avg_in_rec = []\n",
    "    \n",
    "    for index in range(inliers.shape[0]):\n",
    "        \n",
    "        candidate_inlier = inliers[index,:]\n",
    "        candidate_inlier = candidate_inlier.reshape([1,30])\n",
    "        \n",
    "        in_normal_subspace = solution\n",
    "        in_bad_subspace = 1 - solution        \n",
    "        \n",
    "        in_remain = candidate_inlier * in_normal_subspace\n",
    "        \n",
    "\n",
    "        \n",
    "        in_replace = in_bad_subspace * avg_ins\n",
    "        \n",
    "        in_candidate = in_remain + in_replace\n",
    "        \n",
    "        z_mean, z_log_var, z = vae.encoder(in_candidate)\n",
    "        in_candidate_rec = vae.decoder(z)\n",
    "        \n",
    "        \n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "        \n",
    "        avg_in_rec.append(rec_loss.numpy())\n",
    "    \n",
    "    avg_in_rec = np.array(avg_in_rec)\n",
    "    avg_in_rec = np.mean(avg_in_rec)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "#     z_mean, z_log_var, z = vae.encoder(particle)\n",
    "#     reconstruction_1 = vae.decoder(z)\n",
    "\n",
    "    out_normal_subspace = solution\n",
    "    out_bad_subspace = 1 - solution\n",
    "    \n",
    "    out_remain = particle * out_normal_subspace\n",
    "    \n",
    "\n",
    "    \n",
    "    out_replace = avg_ins * out_bad_subspace\n",
    "    \n",
    "    out_candidate = out_remain + out_replace\n",
    "    \n",
    "    \n",
    "    z_mean, z_log_var, z = vae.encoder(out_candidate)\n",
    "    out_candidate_rec = vae.decoder(z)\n",
    "    \n",
    "    rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "    rec_loss = rec_loss.numpy()\n",
    "    \n",
    "    fitness = rec_loss / avg_in_rec\n",
    "    \n",
    "    return -fitness\n",
    "\n",
    "\n",
    "\n",
    "def fitness_func_avg(ga_instance, solution, solution_idx):\n",
    "    \n",
    "    fit_mean = []\n",
    "\n",
    "    for i in range(10):\n",
    "        fit_mean.append(fit_test(solution))\n",
    "\n",
    "    return np.mean(np.array(fit_mean))\n",
    "\n",
    "def on_generation(ga):\n",
    "    print(\"Generation\", ga.generations_completed)\n",
    "    \n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    \n",
    "#     wandb.log({\"solution_fitness\": solution_fitness})\n",
    "    \n",
    "    print(solution_fitness)\n",
    "\n",
    "\n",
    "    \n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"my-project-dual-test\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "# #     config={\n",
    "# #     \"learning_rate\": 0.02,\n",
    "# #     \"architecture\": \"CNN\",\n",
    "# #     \"dataset\": \"CIFAR-100\",\n",
    "# #     \"epochs\": 20,\n",
    "# #     }\n",
    "# )\n",
    "\n",
    "fitness_function = fitness_func_avg\n",
    "\n",
    "num_generations = 40\n",
    "num_parents_mating = 2\n",
    "\n",
    "sol_per_pop = 10\n",
    "num_genes = corrupted_data.shape[1]\n",
    "\n",
    "init_range_low = -2\n",
    "init_range_high = 5\n",
    "\n",
    "parent_selection_type = \"sss\"\n",
    "keep_parents = 1\n",
    "\n",
    "space = [[0,1] for i in range(num_genes)]\n",
    "\n",
    "crossover_type = \"single_point\"\n",
    "\n",
    "mutation_type = \"random\"\n",
    "mutation_percent_genes = 10\n",
    "keep_elitism = 5\n",
    "\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "#                        keep_parents=keep_parents,\n",
    "                       keep_elitism = keep_elitism,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_percent_genes=mutation_percent_genes,\n",
    "                       on_generation=on_generation,\n",
    "                       gene_space = space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ba36f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1\n",
      "-409.7479\n",
      "Generation 2\n",
      "-406.71332\n",
      "Generation 3\n",
      "-398.761\n",
      "Generation 4\n",
      "-376.8354\n",
      "Generation 5\n",
      "-212.04866\n",
      "Generation 6\n",
      "-207.36613\n",
      "Generation 7\n",
      "-196.63754\n",
      "Generation 8\n",
      "-193.98148\n",
      "Generation 9\n",
      "-196.03761\n",
      "Generation 10\n",
      "-196.03761\n",
      "Generation 11\n",
      "-196.03761\n",
      "Generation 12\n",
      "-196.03761\n",
      "Generation 13\n",
      "-196.03761\n",
      "Generation 14\n",
      "-196.03761\n",
      "Generation 15\n",
      "-192.92493\n",
      "Generation 16\n",
      "-0.6934384\n",
      "Generation 17\n",
      "-0.70246756\n",
      "Generation 18\n",
      "-0.5470918\n",
      "Generation 19\n",
      "-0.51984453\n",
      "Generation 20\n",
      "-0.51874584\n",
      "Generation 21\n",
      "-0.38416567\n",
      "Generation 22\n",
      "-0.41924635\n",
      "Generation 23\n",
      "-0.41924635\n",
      "Generation 24\n",
      "-0.41924635\n",
      "Generation 25\n",
      "-0.41924635\n",
      "Generation 26\n",
      "-0.41924635\n",
      "Generation 27\n",
      "-0.41924635\n",
      "Generation 28\n",
      "-0.41924635\n",
      "Generation 29\n",
      "-0.41924635\n",
      "Generation 30\n",
      "-0.41924635\n",
      "Generation 31\n",
      "-0.41924635\n",
      "Generation 32\n",
      "-0.41924635\n",
      "Generation 33\n",
      "-0.41924635\n",
      "Generation 34\n",
      "-0.41924635\n",
      "Generation 35\n",
      "-0.41924635\n",
      "Generation 36\n",
      "-0.41924635\n",
      "Generation 37\n",
      "-0.41924635\n",
      "Generation 38\n",
      "-0.41924635\n",
      "Generation 39\n",
      "-0.41924635\n",
      "Generation 40\n",
      "-0.41924635\n"
     ]
    }
   ],
   "source": [
    "ga_instance.run()\n",
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2edaf00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best solution : [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0.\n",
      " 0. 1. 1. 1. 1. 1.]\n",
      "Fitness value of the best solution = -0.4192463457584381\n"
     ]
    }
   ],
   "source": [
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad6ed447",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78b1c2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6686041\n",
      "-0.7054567\n"
     ]
    }
   ],
   "source": [
    "# candid_sol = np.ones([1,30])\n",
    "# candid_sol[0,outlier_indices_1] = 0\n",
    "# # print(fit_test(solution))\n",
    "\n",
    "# sol_mean = []\n",
    "# candid_sol_mean = []\n",
    "\n",
    "# for i in range(100):\n",
    "#     sol_mean.append(fit_test(solution))\n",
    "# print(np.mean(np.array(sol_mean)))\n",
    "\n",
    "# for i in range(100):\n",
    "#     candid_sol_mean.append(fit_test(candid_sol))\n",
    "# print(np.mean(np.array(candid_sol_mean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f8207",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0788bb28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cf4f748",
   "metadata": {},
   "source": [
    "# For Loop for Genetic Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dfe7fe4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f4e35ade7f4579a371c4c0f38b1e38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016669826457897823, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /tmp/ipykernel_367187/256348332.py 5 <module>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_367187/256348332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m wandb.init(\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# set the wandb project where this run will be logged\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"VAE_Outlier_GA_Without_Penalty_KL_fixed_out=10\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# track hyperparameters and run metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"interrupted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0merror_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m             \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    740\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m             \u001b[0mon_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_on_progress_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m             \u001b[0mcancel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    743\u001b[0m         )\n\u001b[1;32m    744\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, on_probe, on_progress, release, cancel)\u001b[0m\n\u001b[1;32m    281\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mMailboxError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transport failed\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mfound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabandoned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;31m# Always update progress to 100% when done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36m_get_and_clear\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0mfound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/wandb/sdk/lib/mailbox.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_and_clear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResult\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_solutions = []\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"VAE_Outlier_GA_Without_Penalty_KL_fixed_out=10\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "#     \"epochs\": 20,\n",
    "#     }\n",
    ")\n",
    "\n",
    "for out_indexing in range(1,corrupted_data.shape[1]+1):\n",
    "    \n",
    "    def fit_test(solution): \n",
    "\n",
    "        inliers = corrupted_data[10:13,:]\n",
    "\n",
    "        avg_ins = np.mean(inliers, axis=0)\n",
    "        avg_ins = avg_ins.reshape([1,30])\n",
    "\n",
    "        particle = corrupted_data[700+out_indexing,:]\n",
    "        particle = particle.reshape([1,30])\n",
    "\n",
    "    #     abn_subspace = solution * val_features[6728,:]\n",
    "\n",
    "    #     abn_subspace = abn_subspace.reshape([1,30])\n",
    "\n",
    "        avg_in_rec = []\n",
    "\n",
    "        for index in range(inliers.shape[0]):\n",
    "\n",
    "            candidate_inlier = inliers[index,:]\n",
    "            candidate_inlier = candidate_inlier.reshape([1,30])\n",
    "\n",
    "            in_normal_subspace = solution\n",
    "            in_bad_subspace = 1 - solution        \n",
    "\n",
    "            in_remain = candidate_inlier * in_normal_subspace\n",
    "\n",
    "\n",
    "\n",
    "            in_replace = in_bad_subspace * avg_ins\n",
    "\n",
    "            in_candidate = in_remain + in_replace\n",
    "\n",
    "            z_mean, z_log_var, z = vae.encoder(in_candidate)\n",
    "            in_candidate_rec = vae.decoder(z)\n",
    "\n",
    "\n",
    "            rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "\n",
    "            avg_in_rec.append(rec_loss.numpy())\n",
    "\n",
    "        avg_in_rec = np.array(avg_in_rec)\n",
    "        avg_in_rec = np.mean(avg_in_rec)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     z_mean, z_log_var, z = vae.encoder(particle)\n",
    "    #     reconstruction_1 = vae.decoder(z)\n",
    "\n",
    "        out_normal_subspace = solution\n",
    "        out_bad_subspace = 1 - solution\n",
    "\n",
    "        out_remain = particle * out_normal_subspace\n",
    "\n",
    "\n",
    "\n",
    "        out_replace = avg_ins * out_bad_subspace\n",
    "\n",
    "        out_candidate = out_remain + out_replace\n",
    "\n",
    "\n",
    "        z_mean, z_log_var, z = vae.encoder(out_candidate)\n",
    "        out_candidate_rec = vae.decoder(z)\n",
    "\n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "        rec_loss = rec_loss.numpy()\n",
    "\n",
    "        fitness = rec_loss / avg_in_rec\n",
    "\n",
    "        return -fitness\n",
    "\n",
    "\n",
    "\n",
    "    def fitness_func_avg(ga_instance, solution, solution_idx):\n",
    "\n",
    "        fit_mean = []\n",
    "\n",
    "        for i in range(10):\n",
    "            fit_mean.append(fit_test(solution))\n",
    "\n",
    "        return np.mean(np.array(fit_mean))\n",
    "\n",
    "    def on_generation(ga):\n",
    "        print(\"Generation\", ga.generations_completed)\n",
    "\n",
    "        solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "        \n",
    "        wandb.log({\"GA - \" + str(out_indexing) + \"/solution_fitness\": solution_fitness})\n",
    "\n",
    "        print(solution_fitness)\n",
    "\n",
    "\n",
    "    fitness_function = fitness_func_avg\n",
    "\n",
    "    num_generations = 40\n",
    "    num_parents_mating = 2\n",
    "\n",
    "    sol_per_pop = 10\n",
    "    num_genes = corrupted_data.shape[1]\n",
    "\n",
    "    init_range_low = -2\n",
    "    init_range_high = 5\n",
    "\n",
    "    parent_selection_type = \"sss\"\n",
    "    keep_parents = 1\n",
    "\n",
    "    space = [[0,1] for i in range(num_genes)]\n",
    "\n",
    "    crossover_type = \"single_point\"\n",
    "\n",
    "    mutation_type = \"random\"\n",
    "    mutation_percent_genes = 15\n",
    "\n",
    "    ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                           num_parents_mating=num_parents_mating,\n",
    "                           fitness_func=fitness_function,\n",
    "                           sol_per_pop=sol_per_pop,\n",
    "                           num_genes=num_genes,\n",
    "                           init_range_low=init_range_low,\n",
    "                           init_range_high=init_range_high,\n",
    "                           parent_selection_type=parent_selection_type,\n",
    "                           keep_parents=keep_parents,\n",
    "#                            keep_elitism=2,\n",
    "                           crossover_type=crossover_type,\n",
    "                           mutation_type=mutation_type,\n",
    "                           mutation_percent_genes=mutation_percent_genes,\n",
    "                           on_generation=on_generation,\n",
    "                           gene_space = space)\n",
    "\n",
    "    ga_instance.run()\n",
    "\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    print(\"##########  End of the \", out_indexing, \" epoch ##########\")\n",
    "    print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "\n",
    "    best_solutions.append(solution)\n",
    "    \n",
    "    sample = corrupted_data[700+out_indexing,:]\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for gene_no in range(30):\n",
    "        \n",
    "        if ((sample[gene_no] != 20) and (solution[gene_no] == 1)):\n",
    "            \n",
    "            TP = TP + 1\n",
    "        \n",
    "        elif (sample[gene_no] == 20) and (solution[gene_no] == 1):\n",
    "            \n",
    "            FP = FP + 1\n",
    "            \n",
    "        elif (sample[gene_no] != 20) and (solution[gene_no] == 0):\n",
    "            \n",
    "            TN = TN + 1\n",
    "            \n",
    "        elif (sample[gene_no] == 20) and (solution[gene_no] == 0):\n",
    "            \n",
    "            FN = FN + 1\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    F1 = 2 * (precision * recall)/(precision + recall)\n",
    "    \n",
    "    MCC = (TP * TN - FP * FN) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    \n",
    "    wandb.log({\"Metrics/precision\": precision, \n",
    "               \"Metrics/recall\": recall,\n",
    "               \"Metrics/F1\": F1,\n",
    "               \"Metrics/MCC\": MCC,\n",
    "               \"Metrics/num\": out_indexing})\n",
    "    \n",
    "best_solutions = np.array(best_solutions)\n",
    "np.save('best_solutions.npy', best_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc46e2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d90501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
