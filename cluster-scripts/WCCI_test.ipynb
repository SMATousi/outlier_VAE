{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82452ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pygad\n",
    "# import wandb\n",
    "import pandas as pd\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9745d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_refined(n_samples=100000, n_outliers=100, dimensions=20):\n",
    "    # Generate inliers uniformly within a range\n",
    "    inliers = np.random.uniform(-1, 1, size=(n_samples - n_outliers, dimensions))\n",
    "\n",
    "    # Prepare to generate outliers\n",
    "    outlier_samples = []\n",
    "    outlier_indices = []\n",
    "    outlier_dims = []\n",
    "\n",
    "    # Define different clusters of outliers\n",
    "    cluster_definitions = [\n",
    "        (0, 7),    # First 7 dimensions\n",
    "        (5, 10),   # 5 dimensions in the middle\n",
    "        (3, 8),    # Another set of 5 dimensions, overlapping with the first\n",
    "        (1, 6),    # 5 dimensions starting from second\n",
    "        (6, 10),   # Last 4 dimensions\n",
    "        (0, 4),    # First 4 dimensions\n",
    "        (2, 7),    # 5 dimensions starting from third\n",
    "        (4, 9),    # 5 dimensions starting near the middle\n",
    "        (3, 6),    # 3 dimensions in the middle\n",
    "        (7, 10)    # Last 3 dimensions\n",
    "    ]\n",
    "\n",
    "    # Adjust if the number of dimensions is different\n",
    "    if dimensions != 10:\n",
    "        scaling_factor = dimensions // 10\n",
    "        cluster_definitions = [(start * scaling_factor, min(end * scaling_factor, dimensions)) for start, end in cluster_definitions]\n",
    "\n",
    "    # Generate outliers for each cluster\n",
    "    for start, end in cluster_definitions:\n",
    "        for _ in range(n_outliers // len(cluster_definitions)):\n",
    "            # Normal values for non-deviating dimensions\n",
    "            normal_dims = list(set(range(dimensions)) - set(range(start, end)))\n",
    "            outlier = np.random.uniform(-1, 1, dimensions)\n",
    "            # More extreme values for the deviating dimensions\n",
    "            outlier[start:end] = np.random.uniform(1, 10, end - start)\n",
    "            \n",
    "            outlier_samples.append(outlier)\n",
    "            outlier_indices.append(len(inliers) + len(outlier_samples) - 1)\n",
    "            outlier_dims.append((start, end))\n",
    "\n",
    "    # Combine inliers and outliers\n",
    "    dataset = np.vstack([inliers, np.array(outlier_samples)])\n",
    "\n",
    "    return dataset, outlier_indices, outlier_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec73d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_VAE(data,\n",
    "              latent_dim = 2,\n",
    "              hidden_layer_n = [20,18,16],\n",
    "              num_dims = 10,\n",
    "              kl_loss_factor = 0.01,\n",
    "              epochs = 100,\n",
    "              batch_size = 128\n",
    "              ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Training the VAE on the data\n",
    "    \"\"\"\n",
    "\n",
    "    class Sampling(layers.Layer):\n",
    "        \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "        def call(self, inputs):\n",
    "            z_mean, z_log_var = inputs\n",
    "            batch = tf.shape(z_mean)[0]\n",
    "            dim = tf.shape(z_mean)[1]\n",
    "            epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "            return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    latent_dim = latent_dim\n",
    "\n",
    "    encoder_inputs = keras.Input(shape=(num_dims,))\n",
    "    x = layers.Dense(num_dims, activation=\"sigmoid\")(encoder_inputs)\n",
    "    x = layers.Dense(hidden_layer_n[0], activation=\"sigmoid\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[1], activation=\"sigmoid\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[2], activation=\"sigmoid\")(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(hidden_layer_n[2], activation=\"sigmoid\")(latent_inputs)\n",
    "    x = layers.Dense(hidden_layer_n[1], activation=\"sigmoid\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[0], activation=\"sigmoid\")(x)\n",
    "    decoder_outputs = layers.Dense(num_dims, activation=\"linear\")(x)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "    class VAE(keras.Model):\n",
    "        def __init__(self, encoder, decoder, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "            self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "            self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "                name=\"reconstruction_loss\"\n",
    "            )\n",
    "            self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "        @property\n",
    "        def metrics(self):\n",
    "            return [\n",
    "                self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.kl_loss_tracker,\n",
    "            ]\n",
    "\n",
    "        def train_step(self, data):\n",
    "            with tf.GradientTape() as tape:\n",
    "                z_mean, z_log_var, z = self.encoder(data)\n",
    "                reconstruction = self.decoder(z)\n",
    "                reconstruction_loss = tf.keras.losses.MeanSquaredError()(data,reconstruction)\n",
    "                kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "                total_loss = reconstruction_loss + kl_loss_factor * kl_loss\n",
    "        \n",
    "            grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "            self.total_loss_tracker.update_state(total_loss)\n",
    "            self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "            self.kl_loss_tracker.update_state(kl_loss)\n",
    "            return {\n",
    "                \"loss\": self.total_loss_tracker.result(),\n",
    "                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "                \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            }\n",
    "    \n",
    "    creditdata = np.concatenate([data], axis=0)\n",
    "    creditdata = np.expand_dims(creditdata, -1).astype(\"float32\")\n",
    "\n",
    "    vae = VAE(encoder, decoder)\n",
    "    vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "    history = vae.fit(creditdata,epochs=epochs,batch_size=batch_size,verbose=0)\n",
    "\n",
    "    return vae, history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_RAE(data,\n",
    "              latent_dim = 2,\n",
    "              hidden_layer_n = [20,18,16],\n",
    "              num_dims = 10,\n",
    "              z_loss_w = 0.01,\n",
    "              REG_loss_w = 0.01,\n",
    "              epochs = 100,\n",
    "              batch_size = 128\n",
    "              ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Training the RAE on the data\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    encoder_inputs = keras.Input(shape=(num_dims,))\n",
    "    x = layers.Dense(hidden_layer_n[0], activation=\"sigmoid\")(encoder_inputs)\n",
    "    x = layers.Dense(hidden_layer_n[1], activation=\"sigmoid\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[2], activation=\"sigmoid\")(x)\n",
    "    encoder_output = layers.Dense(latent_dim, activation=\"sigmoid\")(x)\n",
    "    encoder = keras.Model(encoder_inputs, encoder_output, name=\"encoder\")\n",
    "\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(hidden_layer_n[2], activation=\"sigmoid\")(latent_inputs)\n",
    "    x = layers.Dense(hidden_layer_n[1], activation=\"sigmoid\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[0], activation=\"sigmoid\")(x)\n",
    "    decoder_outputs = layers.Dense(num_dims, activation=\"linear\")(x)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "\n",
    "\n",
    "    class RAE(keras.Model):\n",
    "        def __init__(self, encoder, decoder, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "            self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "            self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "                name=\"reconstruction_loss\"\n",
    "            )\n",
    "            self.z_tracker = keras.metrics.Mean(name=\"z_loss\")\n",
    "            self.REG_tracker = keras.metrics.Mean(name=\"REG_loss\")\n",
    "\n",
    "        @property\n",
    "        def metrics(self):\n",
    "            return [\n",
    "                self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.z_tracker,\n",
    "                self.REG_tracker,\n",
    "            ]\n",
    "\n",
    "        def train_step(self, data):\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                z = self.encoder(data)\n",
    "                reconstruction = self.decoder(z)\n",
    "\n",
    "                reconstruction_loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)(data,reconstruction)\n",
    "\n",
    "                z_loss = K.mean(K.square(z), axis=[1])\n",
    "        \n",
    "                REG_loss = K.mean(K.square(K.gradients(K.square(reconstruction), z)))\n",
    "\n",
    "\n",
    "                total_loss = reconstruction_loss +  z_loss_w * z_loss + REG_loss_w * REG_loss\n",
    "            \n",
    "                grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "                self.total_loss_tracker.update_state(total_loss)\n",
    "                self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "                self.z_tracker.update_state(z_loss)\n",
    "                self.REG_tracker.update_state(REG_loss)\n",
    "                del tape\n",
    "                return {\n",
    "                    \"loss\": self.total_loss_tracker.result(),\n",
    "                    \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "                    \"z_loss\": self.z_tracker.result(),\n",
    "                    \"REG_loss\": self.REG_tracker.result(),\n",
    "                }\n",
    "\n",
    "    tdata = np.concatenate([data], axis=0)\n",
    "    tdata = np.expand_dims(tdata, -1).astype(\"float32\")\n",
    "\n",
    "    rae = RAE(encoder, decoder)\n",
    "    rae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "    history = rae.fit(tdata,epochs=epochs,batch_size=batch_size,verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "    return rae, history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a781b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, outlier_inds, outlier_dims = generate_dataset_refined(n_samples=10000, n_outliers=100, dimensions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ae0061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    }
   ],
   "source": [
    "rae, history = train_RAE(dataset,\n",
    "              latent_dim = 10,\n",
    "              hidden_layer_n = [64,32,16],\n",
    "              num_dims = 20,\n",
    "              z_loss_w = 0.01,\n",
    "              REG_loss_w = 0.01,\n",
    "              epochs = 100,\n",
    "              batch_size = 128\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f44839e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5444197654724121,\n",
       " 0.5040704011917114,\n",
       " 0.5043322443962097,\n",
       " 0.5043763518333435,\n",
       " 0.5042622089385986,\n",
       " 0.5042601823806763,\n",
       " 0.5043074488639832,\n",
       " 0.5043081641197205,\n",
       " 0.504589855670929,\n",
       " 0.5044249296188354,\n",
       " 0.5043990612030029,\n",
       " 0.5042928457260132,\n",
       " 0.50437992811203,\n",
       " 0.5045304298400879,\n",
       " 0.504183292388916,\n",
       " 0.5041775107383728,\n",
       " 0.5046468377113342,\n",
       " 0.5040521621704102,\n",
       " 0.5028225183486938,\n",
       " 0.49740472435951233,\n",
       " 0.4896623492240906,\n",
       " 0.48600414395332336,\n",
       " 0.48446372151374817,\n",
       " 0.4830969274044037,\n",
       " 0.480182945728302,\n",
       " 0.47248896956443787,\n",
       " 0.4624408185482025,\n",
       " 0.45395419001579285,\n",
       " 0.44280678033828735,\n",
       " 0.42835283279418945,\n",
       " 0.4156312048435211,\n",
       " 0.40661507844924927,\n",
       " 0.4014735221862793,\n",
       " 0.3984443247318268,\n",
       " 0.39599815011024475,\n",
       " 0.39398297667503357,\n",
       " 0.39235419034957886,\n",
       " 0.39042022824287415,\n",
       " 0.3885226845741272,\n",
       " 0.38640230894088745,\n",
       " 0.38430550694465637,\n",
       " 0.38214775919914246,\n",
       " 0.3803544044494629,\n",
       " 0.3782356381416321,\n",
       " 0.3765733540058136,\n",
       " 0.374873548746109,\n",
       " 0.3737649619579315,\n",
       " 0.37299013137817383,\n",
       " 0.3725617825984955,\n",
       " 0.37218475341796875,\n",
       " 0.3715426027774811,\n",
       " 0.3705909550189972,\n",
       " 0.37010905146598816,\n",
       " 0.36965590715408325,\n",
       " 0.36893272399902344,\n",
       " 0.36871424317359924,\n",
       " 0.3682609796524048,\n",
       " 0.36759111285209656,\n",
       " 0.36743929982185364,\n",
       " 0.3668556213378906,\n",
       " 0.3668633699417114,\n",
       " 0.3661525547504425,\n",
       " 0.3654404282569885,\n",
       " 0.3644504249095917,\n",
       " 0.36385536193847656,\n",
       " 0.36323291063308716,\n",
       " 0.3626492917537689,\n",
       " 0.3621745705604553,\n",
       " 0.3618306517601013,\n",
       " 0.36160385608673096,\n",
       " 0.3612116575241089,\n",
       " 0.3611634373664856,\n",
       " 0.3608205318450928,\n",
       " 0.36031192541122437,\n",
       " 0.3597935736179352,\n",
       " 0.35972633957862854,\n",
       " 0.3593820333480835,\n",
       " 0.35916852951049805,\n",
       " 0.35880541801452637,\n",
       " 0.3585319519042969,\n",
       " 0.3583844304084778,\n",
       " 0.35826969146728516,\n",
       " 0.3578443229198456,\n",
       " 0.35783836245536804,\n",
       " 0.35741126537323,\n",
       " 0.3571173846721649,\n",
       " 0.3567532002925873,\n",
       " 0.3564803898334503,\n",
       " 0.3562973737716675,\n",
       " 0.3560343384742737,\n",
       " 0.35572484135627747,\n",
       " 0.3553277254104614,\n",
       " 0.3552243411540985,\n",
       " 0.35488441586494446,\n",
       " 0.35451939702033997,\n",
       " 0.3542862832546234,\n",
       " 0.35399580001831055,\n",
       " 0.3536031246185303,\n",
       " 0.3532413840293884,\n",
       " 0.35277706384658813]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"reconstruction_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ea5d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rae_detect_outliers(data,\n",
    "                        rae_model,\n",
    "                        num_dims,\n",
    "                        std_k\n",
    "                        ):\n",
    "\n",
    "    data_mean = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "            \n",
    "        sample = data[i,:].reshape([1,num_dims])\n",
    "        sample = sample.astype('float32')\n",
    "\n",
    "        z = rae_model.encoder(sample)\n",
    "        reconstruction = rae_model.decoder(z)\n",
    "\n",
    "        reconstruction_loss = tf.keras.losses.MeanSquaredError()(sample,reconstruction)\n",
    "        \n",
    "        data_mean.append(reconstruction_loss)\n",
    "    \n",
    "    data_mean = np.array(data_mean)\n",
    "    i_mean = np.mean(data_mean)\n",
    "    data_std = np.std(data_mean)\n",
    "\n",
    "    threshold = i_mean + std_k*data_std\n",
    "\n",
    "    classes = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "            \n",
    "        sample = data[i,:].reshape([1,num_dims])\n",
    "        sample = sample.astype('float32')\n",
    "\n",
    "        z = rae_model.encoder(sample)\n",
    "        reconstruction = rae_model.decoder(z)\n",
    "\n",
    "        reconstruction_loss = tf.keras.losses.MeanSquaredError()(sample,reconstruction)\n",
    "        \n",
    "        if reconstruction_loss > threshold:\n",
    "            \n",
    "            classes.append(0)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            classes.append(1)\n",
    "\n",
    "    classes = np.array(classes)\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e0c428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = rae_detect_outliers(dataset, rae, num_dims=20, std_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ad75fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9902"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0239a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_genetic_on_sample(inlier_samples,\n",
    "                          outlier_sample,\n",
    "                          rae_model,\n",
    "                          num_dims,\n",
    "                          num_generations = 40,\n",
    "                          num_parents_mating = 2,\n",
    "                          sol_per_pop = 20,\n",
    "                          init_range_low = -2,\n",
    "                          init_range_high = 5,\n",
    "                          parent_selection_type = \"tournament\",\n",
    "                          K_tournament = 5,\n",
    "                          keep_parents = 1,\n",
    "                          crossover_type = \"single_point\",\n",
    "                          mutation_type = \"random\",\n",
    "                          mutation_probability = 0.5,\n",
    "                            ):\n",
    "    \n",
    "    def outlier_subspace_fitness(ga_instance, solution, solution_idx):\n",
    "        \n",
    "        \n",
    "        query_point = outlier_sample\n",
    "        query_point = query_point.reshape([1,num_dims])\n",
    "        \n",
    "#         print(query_point)\n",
    "        \n",
    "        abnormal_subspace = solution\n",
    "        normal_subspace = 1 - solution\n",
    "        \n",
    "        abnormal_array = query_point * abnormal_subspace\n",
    "        normal_array = query_point * normal_subspace\n",
    "        \n",
    "        outlier_aspect_average_amount = np.mean(abnormal_array, axis=1)\n",
    "        normal_aspect_average_amount = np.mean(normal_array, axis=1)\n",
    "        \n",
    "        outlier_aspect_average_array = abnormal_array + (normal_subspace * outlier_aspect_average_amount)\n",
    "        normal_aspect_average_array = normal_array + (abnormal_subspace * normal_aspect_average_amount)\n",
    "        \n",
    "        \n",
    "        z_normal = rae_model.encoder(normal_aspect_average_array)\n",
    "        normal_reconstruction = rae_model.decoder(z_normal)\n",
    "        normal_rec_loss = tf.keras.losses.MeanSquaredError()(normal_aspect_average_array,normal_reconstruction)\n",
    "        \n",
    "        z_abnormal = rae_model.encoder(outlier_aspect_average_array)\n",
    "        abnormal_reconstruction = rae_model.decoder(z_abnormal)\n",
    "        abnormal_rec_loss = tf.keras.losses.MeanSquaredError()(outlier_aspect_average_array,abnormal_reconstruction)\n",
    "        \n",
    "#         print(abnormal_rec_loss.numpy())\n",
    "        \n",
    "        fitness = abnormal_rec_loss.numpy() - normal_rec_loss.numpy()\n",
    "#         fitness = abnormal_rec_loss.numpy()\n",
    "        \n",
    "        return fitness\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def fitness_func(ga_instance, solution, solution_idx):\n",
    "\n",
    "        inliers = inlier_samples\n",
    "\n",
    "        avg_ins = np.mean(inliers, axis=0)\n",
    "        avg_ins = avg_ins.reshape([1,num_dims])\n",
    "\n",
    "        particle = outlier_sample\n",
    "        particle = particle.reshape([1,num_dims])\n",
    "\n",
    "        avg_in_rec = []\n",
    "        avg_in_z = []\n",
    "\n",
    "        for index in range(inliers.shape[0]):\n",
    "\n",
    "            candidate_inlier = inliers[index,:]\n",
    "            candidate_inlier = candidate_inlier.reshape([1,num_dims])\n",
    "\n",
    "            in_normal_subspace = solution\n",
    "            in_bad_subspace = 1 - solution        \n",
    "\n",
    "            in_remain = candidate_inlier * in_normal_subspace\n",
    "\n",
    "\n",
    "\n",
    "            in_replace = in_bad_subspace * avg_ins\n",
    "\n",
    "            in_candidate = in_remain + in_replace\n",
    "\n",
    "            z = rae_model.encoder(in_candidate)\n",
    "            in_candidate_rec = rae_model.decoder(z)\n",
    "\n",
    "\n",
    "            rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "            z_loss = K.mean(K.square(z), axis=[1])\n",
    "\n",
    "            avg_in_rec.append(rec_loss.numpy())\n",
    "            avg_in_z.append(z_loss.numpy())\n",
    "\n",
    "        avg_in_rec = np.array(avg_in_rec)\n",
    "        avg_in_rec = np.mean(avg_in_rec)\n",
    "        avg_in_z = np.array(avg_in_z)\n",
    "        avg_in_z = np.mean(avg_in_z)\n",
    "\n",
    "\n",
    "        out_normal_subspace = solution\n",
    "        out_bad_subspace = 1 - solution\n",
    "        \n",
    "        number_of_bad_genes = np.sum(out_bad_subspace)\n",
    "\n",
    "        out_remain = particle * out_normal_subspace\n",
    "\n",
    "\n",
    "\n",
    "        out_replace = avg_ins * out_bad_subspace\n",
    "\n",
    "        out_candidate = out_remain + out_replace\n",
    "\n",
    "\n",
    "        z = rae_model.encoder(out_candidate)\n",
    "        out_candidate_rec = rae_model.decoder(z)\n",
    "\n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "        outlier_z_loss = K.mean(K.square(z), axis=[1])\n",
    "        outlier_z_loss = outlier_z_loss.numpy()\n",
    "        rec_loss = rec_loss.numpy()\n",
    "        \n",
    "#         fitness = outlier_z_loss / avg_in_z\n",
    "#         fitness = outlier_z_loss / (avg_in_rec + 10*avg_in_z)\n",
    "        l2_regularization = 0.1 * np.sum(np.square(1-solution))\n",
    "\n",
    "        # Penalty for over-identification of outliers\n",
    "        outlier_penalty = 0.1 * number_of_bad_genes\n",
    "\n",
    "        # Threshold for identifying outliers (you may need to adjust this)\n",
    "        outlier_threshold = 0.7\n",
    "\n",
    "        # Calculate the fitness value\n",
    "        fitness = (rec_loss / avg_in_rec) + l2_regularization + outlier_penalty\n",
    "\n",
    "        # Adjust fitness based on the threshold\n",
    "#         if fitness > outlier_threshold:\n",
    "#             fitness = -fitness\n",
    "#         else:\n",
    "#             # Add some positive value to promote good solutions\n",
    "#             fitness = -fitness + 0.1\n",
    "\n",
    "        return -fitness\n",
    "\n",
    "    fitness_function = fitness_func\n",
    "    num_generations = num_generations\n",
    "    num_parents_mating = num_parents_mating\n",
    "    sol_per_pop = sol_per_pop\n",
    "    num_genes = num_dims\n",
    "    init_range_low = init_range_low\n",
    "    init_range_high = init_range_high\n",
    "    parent_selection_type = parent_selection_type\n",
    "    K_tournament = K_tournament\n",
    "    keep_parents = keep_parents\n",
    "    space = [[0,1] for i in range(num_genes)]\n",
    "    crossover_type = crossover_type\n",
    "    mutation_type = mutation_type\n",
    "    mutation_probability = mutation_probability\n",
    "\n",
    "    ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       K_tournament = K_tournament,\n",
    "                       keep_parents=keep_parents,\n",
    "                    #    keep_elitism=5,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_probability=mutation_probability,\n",
    "#                        on_generation=on_generation,\n",
    "                       gene_space = space)\n",
    "    ga_instance.run()\n",
    "\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "\n",
    "    return ga_instance, solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9ca6d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_samples = dataset[:3, :]\n",
    "outlier_sample = dataset[outlier_inds[1], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "478130f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance, solution = run_genetic_on_sample(inlier_samples,\n",
    "                                              outlier_sample, \n",
    "                                              rae, \n",
    "                                              num_dims=20, \n",
    "                                              num_generations = 100, \n",
    "                                              mutation_probability=0.1,\n",
    "                                              sol_per_pop=20,\n",
    "                                              crossover_type=\"single_point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6f604e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.45886788  2.78515778  3.68532116  9.24414908  9.18685923  4.01205122\n",
      "  3.50350387  5.13256701  9.88499132  8.95072899  4.10967059  5.51709378\n",
      "  7.70607861  5.92116112 -0.89366365 -0.68128234  0.95260201 -0.31248075\n",
      "  0.22575025  0.70034011]\n",
      "[0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(outlier_sample)\n",
    "print(solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "008f97ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1.]),\n",
       " -22.176020431518552,\n",
       " 0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_instance.best_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6898385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53f9fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.45491008]\n",
      "[-0.00043672]\n",
      "[[9.45886788 2.78515778 3.68532116 9.24414908 9.18685923 4.01205122\n",
      "  3.50350387 5.13256701 9.88499132 8.95072899 4.10967059 5.51709378\n",
      "  7.70607861 5.92116112 4.45491008 4.45491008 4.45491008 4.45491008\n",
      "  4.45491008 4.45491008]]\n",
      "[[-4.36718125e-04 -4.36718125e-04 -4.36718125e-04 -4.36718125e-04\n",
      "  -4.36718125e-04 -4.36718125e-04 -4.36718125e-04 -4.36718125e-04\n",
      "  -4.36718125e-04 -4.36718125e-04 -4.36718125e-04 -4.36718125e-04\n",
      "  -4.36718125e-04 -4.36718125e-04 -8.93663653e-01 -6.81282339e-01\n",
      "   9.52602012e-01 -3.12480746e-01  2.25750251e-01  7.00340112e-01]]\n",
      "16.437168\n",
      "0.12857437\n",
      "16.308594\n"
     ]
    }
   ],
   "source": [
    "cand_solution = np.array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "num_dims=20\n",
    "query_point = outlier_sample\n",
    "query_point = query_point.reshape([1,num_dims])\n",
    "\n",
    "#         print(query_point)\n",
    "\n",
    "abnormal_subspace = cand_solution\n",
    "normal_subspace = 1 - cand_solution\n",
    "\n",
    "abnormal_array = query_point * abnormal_subspace\n",
    "normal_array = query_point * normal_subspace\n",
    "\n",
    "outlier_aspect_average_amount = np.mean(abnormal_array, axis=1)\n",
    "normal_aspect_average_amount = np.mean(normal_array, axis=1)\n",
    "\n",
    "print(outlier_aspect_average_amount)\n",
    "print(normal_aspect_average_amount)\n",
    "\n",
    "outlier_aspect_average_array = abnormal_array + (normal_subspace * outlier_aspect_average_amount)\n",
    "normal_aspect_average_array = normal_array + (abnormal_subspace * normal_aspect_average_amount)\n",
    "\n",
    "print(outlier_aspect_average_array)\n",
    "print(normal_aspect_average_array)\n",
    "\n",
    "z_normal = rae.encoder(normal_aspect_average_array)\n",
    "normal_reconstruction = rae.decoder(z_normal)\n",
    "normal_rec_loss = tf.keras.losses.MeanSquaredError()(normal_aspect_average_array,normal_reconstruction)\n",
    "\n",
    "z_abnormal = rae.encoder(outlier_aspect_average_array)\n",
    "abnormal_reconstruction = rae.decoder(z_abnormal)\n",
    "abnormal_rec_loss = tf.keras.losses.MeanSquaredError()(outlier_aspect_average_array,abnormal_reconstruction)\n",
    "\n",
    "#         print(abnormal_rec_loss.numpy())\n",
    "\n",
    "fitness = abnormal_rec_loss.numpy() - normal_rec_loss.numpy()\n",
    "print(abnormal_rec_loss.numpy())\n",
    "print(normal_rec_loss.numpy())\n",
    "print(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c4b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a17598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def fitness_func_test(solution):\n",
    "\n",
    "    inliers = inlier_samples\n",
    "\n",
    "    avg_ins = np.mean(inliers, axis=0)\n",
    "    avg_ins = avg_ins.reshape([1,num_dims])\n",
    "\n",
    "    particle = outlier_sample\n",
    "    particle = particle.reshape([1,num_dims])\n",
    "\n",
    "    avg_in_rec = []\n",
    "    avg_in_z = []\n",
    "\n",
    "    for index in range(inliers.shape[0]):\n",
    "\n",
    "        candidate_inlier = inliers[index,:]\n",
    "        candidate_inlier = candidate_inlier.reshape([1,num_dims])\n",
    "\n",
    "        in_normal_subspace = solution\n",
    "        in_bad_subspace = 1 - solution        \n",
    "\n",
    "        in_remain = candidate_inlier * in_normal_subspace\n",
    "\n",
    "\n",
    "\n",
    "        in_replace = in_bad_subspace * avg_ins\n",
    "\n",
    "        in_candidate = in_remain + in_replace\n",
    "\n",
    "        z = rae.encoder(in_candidate)\n",
    "        in_candidate_rec = rae.decoder(z)\n",
    "\n",
    "\n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "        z_loss = K.mean(K.square(z), axis=[1])\n",
    "\n",
    "        avg_in_rec.append(rec_loss.numpy())\n",
    "        avg_in_z.append(z_loss.numpy())\n",
    "\n",
    "    avg_in_rec = np.array(avg_in_rec)\n",
    "    avg_in_rec = np.mean(avg_in_rec)\n",
    "    avg_in_z = np.array(avg_in_z)\n",
    "    avg_in_z = np.mean(avg_in_z)\n",
    "\n",
    "\n",
    "    out_normal_subspace = solution\n",
    "    out_bad_subspace = 1 - solution\n",
    "\n",
    "    number_of_bad_genes = np.sum(out_bad_subspace)\n",
    "\n",
    "    out_remain = particle * out_normal_subspace\n",
    "\n",
    "\n",
    "\n",
    "    out_replace = avg_ins * out_bad_subspace\n",
    "\n",
    "    out_candidate = out_remain + out_replace\n",
    "\n",
    "\n",
    "    z = rae.encoder(out_candidate)\n",
    "    out_candidate_rec = rae.decoder(z)\n",
    "\n",
    "    rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "    outlier_z_loss = K.mean(K.square(z), axis=[1])\n",
    "    outlier_z_loss = outlier_z_loss.numpy()\n",
    "    rec_loss = rec_loss.numpy()\n",
    "\n",
    "#         fitness = outlier_z_loss / avg_in_z\n",
    "#         fitness = outlier_z_loss / (avg_in_rec + 10*avg_in_z)\n",
    "    # Regularization term (L2)\n",
    "    l2_regularization = 0.1 * np.sum(np.square(1-solution))\n",
    "\n",
    "    # Penalty for over-identification of outliers\n",
    "    outlier_penalty = 0.1 * number_of_bad_genes\n",
    "\n",
    "    # Threshold for identifying outliers (you may need to adjust this)\n",
    "    outlier_threshold = 0.7\n",
    "\n",
    "    # Calculate the fitness value\n",
    "    fitness = (rec_loss / avg_in_rec) + l2_regularization + outlier_penalty\n",
    "\n",
    "    # Adjust fitness based on the threshold\n",
    "    if fitness > outlier_threshold:\n",
    "        fitness = -fitness\n",
    "    else:\n",
    "        # Add some positive value to promote good solutions\n",
    "        fitness = -fitness + 0.1\n",
    "\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b32a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e118299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dims = 20\n",
    "cand_solution = np.array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de078570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32.29293327331543\n",
      "-32.29293327331543\n"
     ]
    }
   ],
   "source": [
    "print(fitness_func_test(1-cand_solution))\n",
    "print(fitness_func_test(solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e279b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de5ddc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEbCAYAAAArhqjIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAl0ElEQVR4nO3deZhcZZn+8e+dDknYhGDCFghhCUsCCNgiiCAOMCwiAWUUZFBBjXFQXIbRwYwScZhxFNSfgkhAXIawCbIIyBJwREXQECIEwhJIAiEIYctG9jy/P97T1klR3dXVXV1VXXV/rquunK3OeU6dTj31Luc9igjMzMy6MqDeAZiZWeNzsjAzs7KcLMzMrCwnCzMzK8vJwszMynKyMDOzspwszBqYpJB0Yr3j6EuSJkmaWe84rGtOFk1A0s+yL5WQtFrSM5LOl7RxhfvZR9JVkhZIWinpWUm3STpB0pv+ViTdLGmtpCNKrJuUi2mNpFcl3SfpbEmb9OZ8i46zk6TLJM3LYl4g6beSPiZpULWO09eya3hLiVXbAL+udTzVVvT3kH8dD5wPvCe3bWefhdXRwHoHYFUzFTgV2AA4GLgM2Bj4THfeLOlY4HrgbuA04ClgEHAAMBH4CzA/t/02wGHA94BPAneV2O0TwKGAgC2AdwNnA6dLOjgi/lbhORbH3J7FOwv4HPA4sA7Yl3Tes4E/9uYYvSVpUESs6un7e/sZNZiOv4e81yJiJbC09uFYRSLCr37+An4G3FK07FLgBdIX9WzgrKL1o4EA9iMllYXAr7o4hormzyYllx2A5cBbi9ZPAmaW2M82wCvAz3t5zgIeBaYBA8rFDIwArgZey163AqOL4wVOAp4GlgA3AsOK9nka8BiwAngS+GL++NlnegbwK2AZ6VdzG/ATYE72WT0FfLnjfdmxo+h1aG5/J+b2vxfph8Fy4NXs2m9W/LcAfB54PjvXnwIbdfIZDQCeAz5XtHzXjr+PbP7T2fmuAF4G7gAGVnC9Sv49FK/r7LMARmXTHyT9MHkjuw5HFO1rTHZtlwAvAVcBWxd9fncDi0kJ6q/Ae7N1GwA/ABYAK7PP5Vv1/v/dKC9XQzWv5cAGkf4X/IT0JZd3OjAjIqYD/wgMA77d2c6y/QAgSdn7r4iIecADpFJNWRHxAjAFOL5U1VYF9iF9MZwfEeu6ilnSRsBvSV907wEOJCXSqdm6DqOADwMnkD6TfYHzOlZK+hTwX8DXgT2AfwW+AvxL0aHPAW4jfTFdRPpCfh74UPa+icBXKVyT84FrSUlgm+x1X/H5ZNWKd5C+5PbP4nwXcHnRpgcDewKH587n8518RutIX6inFK06BZgVEdOzEtxFwDeA3UglyttL7a8Kyn0W55G+0N9GKu1e3VGtmZV27yUl/f1J578JcFPub+1K0rXfn/Q3NIn0dwFwJumzOon0Y+rDpNKQgUsWzfCiqGRB+o/wMnBNNr81sBo4IJtvI315fTab/wrpV9vQ3D72In0pdbxOya07lFQ6GJTNnw48UhTTJDr/JTkhO96WvTjnD2f72De3bLOimL+ai+8p1i9ptGXn8KFcvCtY/1f6RGB2bv5Z4NSiOL4APJabD+CH3Yj/W8DUzq5h0f5OzKY/BSwCNi26FgHsktvPc0BbbptL88cqcYy9s33snFv2VO7z+0DxcXtwvSYBa4uuz6Ol/lZKfRYUShafzi0bkS17dzZ/LnB30fuGZtvsn80vBj7WSYw/IJU61JNzbPaXSxbN4yhJSyWtAP5E+oX1Ofh7vfctpC9NgKNIbQhTutjfE6RfXvuQqnw2yK37JHBtFOrirwN2lvTObsaq7N+So1hKejQ7l6WSftPNfUKqeuiIeQGpzQXg7cCOwJKO/ZK+/IYCO+fePy8iFuXmFwBbZjENB7YHLsnFtpT0pZ/fB6SqseJzmiBpmqSF2fu+CIys4NwglUoejogluWX3kdppxuSWPRYRa0udRykR8TDwCFnpIruOO1P4+7gLmAfMkTQl6zywaYWxQ6re2yf3OqYH+3g4N70g+7fj3N4OHFJ0fZ7L1nVco+8Cl0m6R9JESbvn9vezLK4nJV0k6X29LP02FTdwN497gfGkEsSCiFhdtP4y4EpJXyAljRsi4rVs3ZPZv7uTEg1ZIpgNqftmx04kbU6qNx6UVct0aCMlkQe6EesY0i+8VzpZfwyF5LS8k23yMT+UxbwuF3O+UXkAMINUvVDs1dx08WcWFHoMdvw7gRJVREWW5WckfRj4PnBW9t7FpHaNE8rspxL5xNvVeXTmCuATpF/npwB/iFTFSEQskbQfcAhwBKm96r8kvSMiFnS2wxJWRcTsCrYv5e/nFhGRakTXu0a3kj7nYi9m75kkaQpwNHAkcI6kCRFxeaQqt1HZ8sOAnwN/lXREdFLV2UqcLJrHG2X+I95O+pKaALyf9X/V3Un64j4bOK7McU4hNYYX/yo8ELhA0hciYtmb35Zk9cofITWmd9bWMK9MDJC+/GcBX5Z0bdEv6WLTgZOBlyPi9W7su1RML0paQKqq+UWFb3838EBEXNixQFJxaWQVKeF2ZRapJ9mmudLFu0hfkrMqjKnYlcB/SzqAVMX3tfzKiFgD3APcI+kcUuPxscDkXh63lO58FqVMJ7ULzSvxY+nvIuIpUjXbDyRdTPqRc3m2bgmppHydpJ8B9wO7UPhx0rJcxGoR2Zfp5cB/k9or7s6tW0b6VXmUpNslHSVpZ0l7SfoSMIRU30y23XURMTP/Iv0KW0f6oukwUNLWkraRNFbSeFLJ5VVSYurN+QTwcVL1wp8kjZO0q6Q9JH0S2C4X8xTSL8ubJL1H0o6SDpF0gaTRFRz2HFJy+qKk3STtKemjksqdy5PAfpKOljRa0tfI3VeQmQvsme13mKQN3rSXdB5vAL/Irs0hwCWkxNurX+wRMR/4HfBjUtvPLzvWSTpW0ucl7StpB1Ky35QsQSndh/O4pBG9iSFnLuU/i1IuymK/RtI7le7BOVzSZEmbStowq146VNKorLrt3aReVUj6kqSTs7+hXbLzXEyuy3grc7JoLZeT6vF/mn3Z/l1E3ES6p2IRqavl48D/kYrrpwFTsqqIfUm/vCh6/yrgZtKvtA67kXqezAf+kO1nMqk7Zq/vH4iIP5O6/j4C/JDUC+Z+4GOkxulvZ9u9QapCeYb0Jfg4KbkNJXUt7e7xLiNV4Z1K6nL5e1LV35wyb72E1MPnSlIPnlHABUXbXEr68p1GKrkdVOL4b5CqSN4C/Bm4iZR8Ty/etoeuIPUyui1XRQnwOnA8qYfS46Rqnk9GxO+z9ZuRrnV3v9TLKftZlJJViR1E+tFyO6lr9UWkbrArST8ehpLaJp4AbiB9fl/KdrEE+DfSZzud1H5xdPa5tzwVfWdYE8t+Sf0R2Ckinq13PGbWfzhZtABJg4HhpJLFooj4pzqHZGb9jKuhWsPJpK6PwygUuc3Mus0lCzMzK8slCzMzK6sp77MYNmxYjBo1qt5hmJn1Kw8++ODLETG81LqmTBajRo1i2rQ3jbhgZmZdkNTpDbGuhjIzs7KcLMzMrCwnCzMzK8vJwszMynKyMDOzspwszMysrKbsOmvNb/UaeG1p6XVr1sIbK9Nr1ZraxmXWCEYOhy03r+4+nSysX1m4CK75Hdz4J1i2ot7RmDWmfzsRPtCtgd27z8nC6uKJ+XD9H+DVJeW37bBmLTw4O/1rZrXlZGF9btUaeCMrBby6BH52F9z1UO/3u9nGMKjEX3DbANhoCGw0CAZtAOr9ocz6leGbVX+fThbWp+59BL4xJbUfVMteo+DUw+CgMTDAXTTMaqLhk4WkScCnSI9XBPhqRNxWv4isEv97T+eJ4pA94eh3pJJAd209FEZX60nPZtZtDZ8sMt+LiPPrHYRVZu06mL2gMP+WjWCAYLft4RNHphKCmfUP/SVZWD80/2VYsSpNv3VTuOXc+sZjZj3XX2p8PyvpYUmXSxpaagNJ4yVNkzRt4cKFpTaxGnvq+cL0Lq46MuvXGiJZSJoqaWaJ1zjgYmBnYB/gBeCCUvuIiMkR0R4R7cOHl3x2h9XYU7kqqF23rV8cZtZ7DVENFRGHd2c7SZcCt/RxOFYls3MlCzdKm/VvDVGy6IqkbXKzJwAz6xWLVebJXMnCycKsf2uIkkUZ35a0DxDAXODTdY3GuuW1pfDyojQ9eAPY3jWDZv1awyeLiDi13jFY5fKN2zttU9m9FGbWePxf2PqEG7fNmouThfWJ2e42a9ZUnCysT6zXuO2ShVm/52RhVbdyNcx7sTC/i5OFWb/nZGFVN/dvaVwogBHDYOMh9Y3HzHrPycKq7kk3bps1nYbvOmuNLwIeeAJ+85f0qNNnc0NzuXHbrDk4WVjFlq1I7RIAzy2Eyb+B6bNLb+vGbbPm4GRh3bZoGVzwK7j7IVgX5bcf9hbYb5e+j8vM+p6ThXXLn5+Ab15VGMKjWNsAOO4AOHCPwvzeO7px26xZOFlYl9aug0tuTY9HzRu6Sfq3rQ3aR8Pp/+jxn8yamZOFdWr5Sph0BdybG+d36CZw9ofh4D3rF5eZ1Z6TRROY+yI8Oq+6+4yA6/4AT8wvLDtgd/jaR2CLTat7LDNrfE4W/dyMp+HMi2H12r49zsmHwhnv9+ixZq3KyaIfe3kR/MfP+zZRtA2Asz4Ix7+r745hZo3PyaKfWrMWvvYLeGVJmt9sYzhoTHWPMWQQHPMOGLtDdfdrZv2Pk0WD+9MseOZvb17++HMw45k0PUBw7qmw/261jc3MWoeTRQO78rfww5vLb/epo50ozKxvubmyQd09o3uJ4t1j4aOH9Xk4ZtbiXLJoQH99Bs6dUpjffTvYt8SwGVtsCie+GwY45ZtZH3OyaDDPvwxfuRxWrUnzI4fD9yekBmwzs3ppiN+kkv5J0qOS1klqL1p3tqTZkp6QdGS9YqyFtevg3CvTgH2Q7pb+7ngnCjOrv0YpWcwEPgBckl8oaQxwEjAW2BaYKmnXiOjjW9DqY8o98PCcNN02AP7nE+lJc2Zm9dYQJYuImBURT5RYNQ64OiJWRsQcYDawf22jq40nn4dLby/Mn34k7DWqbuGYma2nUUoWnRkB3J+bn58texNJ44HxACNHjuz7yHppzVr49QMw78U0f9+stAxgzEj3cDKzxlKzZCFpKrB1iVUTI+Km3u4/IiYDkwHa29u78Wie+rrxT3DB9W9ePngDOOcUGNhW+5jMzDpTs2QREYf34G3PA9vn5rfLlvV7054svfzMcTByy9rGYmZWTqNXQ90MXCnpu6QG7tHAn+sbUnXMyQ3hceo/wNBNYdRWhSfNmZk1koZIFpJOAH4IDAdulTQjIo6MiEclXQs8BqwBzmiGnlCr1sD8l9O0lBqzhwyqb0xmZl1piGQRETcAN3Sy7jzgvNpG1LeefQnWZa0q227hRGFmja8hus62mnwV1Kit6heHmVl3OVnUQX7I8Z1K9Q8zM2swThZ1MPfFwvQoJwsz6wecLOrAJQsz62+cLGps1Zo0siyknlBuszCz/sDJosaefSmNLguwzVD3hDKz/sHJosby7RU7ugrKzPoJJ4say7dXOFmYWX/hZFFjc50szKwfcrKosfVKFm7cNrN+wsmihvJjQoF7QplZ/+FkUUPPLcz1hNoCNhxc33jMzLqrIQYSbGYrV6ceUMtXwoxnCsvdXmFm/YmTRZW89Dr8793wypI0v25dKknMy91Xkef2CjPrT5wsquR7N8D/Pdz97cfu0HexmJlVm5NFFaxYBffNKr1OghFvhbduWli2907wnr1qE5uZWTU4WVTBtKdg1eo0vd0wmPC+ND18M9h5G9h4SP1iMzOrBieLKvjjo4Xp9+wFh+1Tt1DMzPqEu872UsT6VVDvGlO/WMzM+oqTRS89/ULqCQWwyRDYe8e6hmNm1icaIllI+idJj0paJ6k9t3yUpOWSZmSvH9czzlL++Fhh+p27w8C2+sViZtZXGqXNYibwAeCSEuuejoh9ahtO992XSxYHuQrKzJpUQySLiJgFIKneoVRk0TKYOTdNS3DAHnUNx8yszzRENVQZO0p6SNLvJB3c2UaSxkuaJmnawoULaxLY/Y/DukjTY0fC0E1qclgzs5qrWclC0lSg1IhIEyPipk7e9gIwMiJekfR24EZJYyNicfGGETEZmAzQ3t4e1Yq7K/kqKPeCMrNmVrNkERGH9+A9K4GV2fSDkp4GdgWmVTm8Hsk/InW/XeoXh5lZX2voaihJwyW1ZdM7AaOBZ7p+V+0sW1GYdhWUmTWzhkgWkk6QNB84ELhV0h3ZqkOAhyXNAK4DJkTEq3UK803yyWKTDesXh5lZX2uU3lA3ADeUWH49cH3tI+qefLLYyA8yMrMm1hAli/5o5WpYvTZNtw2AwRvUNx4zs77kZNFDxVVQ/ewWETOzijhZ9FA+WWzsKigza3JOFj20XrJw47aZNTknix5aL1n44UZm1uScLHrI1VBm1kqcLHpoqe+xMLMW0utkIaklO426GsrMWklFyULSmZI+mJv/CbBc0hOSdqt6dA3M1VBm1koqLVmcCSwEkHQI8CHgI8AM4IKqRtbg3BvKzFpJpcN9jADmZNPvB34ZEddKegT4fVUja3CuhjKzVlJpyWIxsGU2fQRwdza9Gmipr0xXQ5lZK6m0ZHEncKmk6cAuwG+y5WMplDhagntDmVkrqbRkcQbwR2A4cGJuuPD9gKuqGVije8PVUGbWQioqWWSPM/1cieXnVC2ifmKpq6HMrIVU2nV2TL6LrKQjJF0h6eyOJ9q1CveGMrNWUmk11OXAvgCStgduArYgVU/9Z3VDa2zuDWVmraTSZLE7MD2bPhF4ICKOAU4FTq5mYI0swsnCzFpLpcmiDViVTR8G3JZNPw1sVa2gGt3K1bB2XZoeNDC9zMyaWaXJYibwGUkHk5LF7dnyEcDL1QyskblUYWatptJk8RXgU8D/AVdFxCPZ8uOAP1cxroaW7wm1kZOFmbWASrvO3itpOPCWiHgtt+oS4I2eBiHpO6ThQ1aRqrROi4jXs3VnA58A1gJnRsQdPT1Otaz3/G0nCzNrARUPUR4Ra4E2Se+UNDhbNjciXupFHHcBe0bE3sCTwNmQuuoCJ5HuED8K+FEjdNF1NZSZtZpK77PYVNIvgZeA+0htFUj6saRJPQ0iIu6MiDXZ7P3Adtn0OODqiFgZEXOA2cD+PT1OtThZmFmrqbRk8T/AtqThPZbnlt8CnFClmE6nMObUCOC53Lr52bI3kTRe0jRJ0xYuXFilUEpzsjCzVlNpp8/jgBMiYoakyC2fBezU1RslTQW2LrFqYkTclG0zEVgDTKkwLiJiMjAZoL29Pcps3itOFmbWaipNFkOBV0os35TUAN2piDi8q/WSPg4cCxwWER1f9s8D2+c22y5bVldLnSzMrMVUWg31F1LpokPHl/qnSW0YPSLpKODLwHERke9VdTNwkqTBknYERtMAXXTdG8rMWk2lJYuvAndIGpu990vZ9P7AIb2I40JgMHCXJID7I2JCRDwq6VrgMVL11BlZb6y6cjWUmbWaSu+zuE/Su4CzSPdDHEYaK+rA3A16FYuIXbpYdx5wXk/33RecLMys1VQ8qlGWFD7WB7H0G04WZtZqejQEnqRtSc/iXq/NIyKml35Hc3GyMLNWU1GykLQvcAVpqHIVrQ7SqLRNb6kbuM2sxVRasphMuknuU8ACCr2hWoqfv21mrabSZDEG2DcinuyLYPoLV0OZWaup9D6LRyh9F3bL8FPyzKwVVZosvgp8W9LhkraStEX+1RcBNprlq2BdVvk2eAMY2BKtNGbW6iqthpqa/Xsn67dXiBZp4HapwsxaUaXJ4r19EkU/4qE+zKwVVZos5gDP5Qb6A0BpjI7tS7+lubhkYWatqNI2iznA8BLLt8jWNb18svDzt82sVVSaLDraJoptAqwosbzpLM098snVUGbWKrpVDSXpB9lkAP8tKT+MeBtp1NkZ1Q2tMS1bWZh2NZSZtYrutlnslf0rYA9gVW7dKtLIs+dXMa6G5TYLM2tF3UoWEfFeAEk/BT4fEYv7NKoGtixXDeVkYWatotLnWZzWV4H0F66GMrNWVDZZSLoZ+OeIWJxNdyoijutqfTNwNZSZtaLulCxeAfaW9KdsuqW5N5SZtaKyySIiTpO0FtimoxpK0q3AJyPihb4OsNG4GsrMWlF32yyKH3R0MLBhlWNpWHfPgO/fAK8vgzVrC8udLMysVVR6U16H4uTRK5K+I+lxSQ9LukHS5tnyUZKWS5qRvX5czeN21+V3wMuL108UAEM3qUc0Zma1191kEbz5zu1qPiXvLmDPiNgbeBI4O7fu6YjYJ3tNqOIxu+21pevPDxC8b38YuWU9ojEzq71KqqGukNRRYz8EuLToTu4e94aKiDtzs/cDJ/ZkP31l5erC9O3/maqf/BwLM2sl3U0WPy+av6LageScDlyTm99R0kPAYuA/IuL3pd4kaTwwHmDkyJFVCyYiPfCowyYbQltPK+/MzPqp7t7B3eub8SRNpfQjWSdGxE3ZNhOBNcCUbN0LwMiIeEXS24EbJY0tdQd5REwGJgO0t7dXrYps1ZqUMAAGDXSiMLPWVOnzLHosIg7var2kjwPHAod1PC8jIlYCK7PpByU9DewKTOvbaAtW5EoVgwfV6qhmZo2lIX4nSzoK+DJwXES8kVs+XFJbNr0TMBp4ppax5dsrhmxQyyObmTWOmpUsyrgQGAzclR66x/1Zz6dDgHMlrQbWARMi4tVaBpYvWQxxycLMWlRDJIuI2KWT5dcD19c4nPXkG7ddsjCzVtUQ1VCNzCULMzMni7LWa7NwsjCzFuVkUYZLFmZmThZlrXBvKDMzJ4tyfJ+FmZmTRVn5ZLGhk4WZtSgnizJWuOusmZmTRTn5NgtXQ5lZq3KyKMO9oczMnCzKcjWUmZmTRVkuWZiZOVmUtcJ3cJuZOVmUs9LVUGZmThblLHc1lJmZk0U5roYyM3OyKGulSxZmZk4W5bjrrJmZk0VZroYyM3OyKMv3WZiZOVl0KaJoiHJXQ5lZi3Ky6MLqtbAu0vTAtvQyM2tFDZMsJH1T0sOSZki6U9K22XJJ+oGk2dn6/WoVk59lYWaWNEyyAL4TEXtHxD7ALcDXs+VHA6Oz13jg4loF5KfkmZklDZMsImJxbnZjIKsAYhzwi0juBzaXtE0tYnK3WTOzZGC9A8iTdB7wUWAR8N5s8Qjgudxm87NlLxS9dzyp5MHIkSOrEo+7zZqZJTUtWUiaKmlmidc4gIiYGBHbA1OAz1ay74iYHBHtEdE+fPjwqsTrkoWZWVLTkkVEHN7NTacAtwHnAM8D2+fWbZct63O+x8LMLGmYNgtJo3Oz44DHs+mbgY9mvaIOABZFxAtv2kEfWOlqKDMzoLHaLL4laTdgHTAPmJAtvw04BpgNvAGcVquAPDy5mVnSMMkiIj7YyfIAzqhxOIDv3jYz69Aw1VCNyMOTm5klThZdyHed9R3cZtbKnCy64K6zZmaJk0UXlnu4DzMzwMmiS+46a2aWOFl0wdVQZmaJk0UXfAe3mVniZNEFDyRoZpY4WXTBJQszs8TJogtuszAzS5wsuuBqKDOzxMmiCx7uw8wscbLogquhzMwSJ4sueIhyM7PEyaITEb6D28ysg5NFJ9ashbXr0nTbABjYVt94zMzqycmiE+4JZWZW4GTRieUrC9N+loWZtToni07k2ys8PLmZtToni06426yZWUFDJAtJ35T0sKQZku6UtG22/FBJi7LlMyR9vVYxuc3CzKygIZIF8J2I2Dsi9gFuAfJJ4fcRsU/2OrdWAblkYWZW0BDJIiIW52Y3BqJesXTwiLNmZgUNkSwAJJ0n6TngFNYvWRwo6a+SfiNpbBfvHy9pmqRpCxcu7HU8ThZmZgU1SxaSpkqaWeI1DiAiJkbE9sAU4LPZ26YDO0TE24AfAjd2tv+ImBwR7RHRPnz48F7H6zYLM7OCgbU6UEQc3s1NpwC3Aefkq6ci4jZJP5I0LCJe7pMgc/Ili8FuszCzFtcQ1VCSRudmxwGPZ8u3lqRsen9SvK/UIiYPT25mVlCzkkUZ35K0G7AOmAdMyJafCHxG0hpgOXBSRNSk8Ts/4qzv4DazVtcQySIiPtjJ8guBC2scDlDUZuFqKDNrcQ1RDdWI1muzcMnCzFqck0Un/CwLM7MCJ4tO+A5uM7MCJ4tO+JGqZmYFThadcNdZM7MCJ4tO+A5uM7MCJ4tOuM3CzKygIe6zaBTfvwFWr03TL75WWO6ShZm1OieLnJvuX79E0cFjQ5lZq3M1VBkjt4Rhb6l3FGZm9eWSRc6Z42DtusL84A3g4LEwwCnVzFqck0XOCe+qdwRmZo3Jv5nNzKwsJwszMyvLycLMzMpysjAzs7KcLMzMrCwnCzMzK8vJwszMylJE1DuGqpO0EJjXi10MA16uUjj9QaudL/icW4XPuTI7RMTwUiuaMln0lqRpEdFe7zhqpdXOF3zOrcLnXD2uhjIzs7KcLMzMrCwni9Im1zuAGmu18wWfc6vwOVeJ2yzMzKwslyzMzKwsJwszMyvLySJH0lGSnpA0W9K/1zueviBpe0m/lfSYpEclfT5bvoWkuyQ9lf07tN6xVpOkNkkPSbolm99R0gPZtb5GUtM9aV3S5pKuk/S4pFmSDmzm6yzpi9nf9ExJV0ka0ozXWdLlkl6SNDO3rOR1VfKD7PwflrRfT4/rZJGR1AZcBBwNjAFOljSmvlH1iTXAv0bEGOAA4IzsPP8duDsiRgN3Z/PN5PPArNz8/wDfi4hdgNeAT9Qlqr71/4DbI2J34G2k82/K6yxpBHAm0B4RewJtwEk053X+GXBU0bLOruvRwOjsNR64uKcHdbIo2B+YHRHPRMQq4GpgXJ1jqrqIeCEipmfTS0hfICNI5/rzbLOfA8fXJcA+IGk74H3AZdm8gH8Arss2aarzBZC0GXAI8BOAiFgVEa/TxNeZ9OTPDSUNBDYCXqAJr3NE3Au8WrS4s+s6DvhFJPcDm0vapifHdbIoGAE8l5ufny1rWpJGAfsCDwBbRcQL2aq/AVvVK64+8H3gy0DHE9bfCrweEWuy+Wa81jsCC4GfZtVvl0namCa9zhHxPHA+8CwpSSwCHqT5r3OHzq5r1b7XnCxalKRNgOuBL0TE4vy6SP2pm6JPtaRjgZci4sF6x1JjA4H9gIsjYl9gGUVVTk12nYeSfkXvCGwLbMybq2paQl9dVyeLgueB7XPz22XLmo6kDUiJYkpE/Cpb/GJH8TT796V6xVdlBwHHSZpLqlr8B1Jd/uZZdQU057WeD8yPiAey+etIyaNZr/PhwJyIWBgRq4Ffka59s1/nDp1d16p9rzlZFPwFGJ31nhhEahy7uc4xVV1WX/8TYFZEfDe36mbgY9n0x4Cbah1bX4iIsyNiu4gYRbqm90TEKcBvgROzzZrmfDtExN+A5yTtli06DHiMJr3OpOqnAyRtlP2Nd5xvU1/nnM6u683AR7NeUQcAi3LVVRXxHdw5ko4h1W+3AZdHxHn1jaj6JL0b+D3wCIU6/K+S2i2uBUaShnf/UEQUN6L1a5IOBc6KiGMl7UQqaWwBPAT8c0SsrGN4VSdpH1Kj/iDgGeA00g/EprzOkr4BfJjU4+8h4JOk+vmmus6SrgIOJQ1F/iJwDnAjJa5rljgvJFXJvQGcFhHTenRcJwszMyvH1VBmZlaWk4WZmZXlZGFmZmU5WZiZWVlOFmZmVpaThVk/JWmupLPqHYe1BicLa2qStpL0vWzo5hXZ0M73SfpcNuRJw5M0KT8cdc47gB/VOh5rTQPLb2LWP2UDJf4RWAx8DXgYWA6MJd2w9QpwZR3jG5SNcNwjEbGwmvGYdcUlC2tmF5PuUm+PiKsj4rGImBMRt0TE8cBVkIbzljQ5K3UskfQ7Se0dO5H0cUlLJR2WPVhnmdIDpHbMH0zS+yU9mJVg5kg6L/+wnazaaFL28JrXgSnZ8m8pPXRrebbNtyUN6Tg26Q7dsZIie308t7+zcvsfKemG7ByWSPpVNjx7x/pJWfwnSXo62+ZGScOq+7FbM3KysKYk6a3AkcBFEbGs1DYREdlwCLeShoU4ljRk+73APUXj/g8GzgZOBw4ENgd+nDvekaQv/wtJJZfTSWMS/VfRYb8EPA60k4ZZgTQi7OnAHsC/kMawmpituwa4AHgC2CZ7XVPifAeQxgPaCnhv9toWuDE7xw6jSENinAD8Y3a+TTesjfWBiPDLr6Z7Ae8kDdN8QtHy+cDS7PVj0ii0S4ENi7abAXw5m/54tq/dcutPAVZSGDLnXuBrRfs4Ptt3xzZzgV93I/YJpAdxdcxPAmaW2G4uaawrgCOAtcCo3PqdSCWrw3P7WQFslttmYv5YfvnV2cttFtZqDiYNFDkZGAK8nfRUtYXr/wBnCLBzbn5lRDyRm19AGqBvKOmpZW8H9pf0ldw2A4ANga1JD+QBeNMgbpJOBL4A7AJsksXXVuF57QEsiIi5HQsi4hlJC0iPCZ6aLZ4XEYuKzmPLCo9lLcjJwprVbFJpYPf8woiYAyDpjWzRANLInQeX2Ef+oVBritZ1jMA5IPfvN4BflthPviF6vSqxbNjoq7P3fhF4HTiO9NS3asmPFrq6xDpXR1tZThbWlCLiFUl3Ap+V9MOIWNrJptNJ9fzrIuKZXhxyOrB7RMyu8H0HAc9HxDc7FkjaoWibVZQvacwCtpU0qqN0kQ3Dvi3puQ5mveJfFNbM/oX0N/6gpJMljZG0q6STgbeR6vinkrrX3iTp6OzhVwdK+oakUqWNzpwLfETSuZL2lLS7pBMlfbvM+54ERkg6RdJOkj4DnFy0zVxgB0n7SRomaXCJ/UwldQ2eIqk96801hZTE7qngPMxKcrKwppWVFPYFbge+SXr4zXRSj6QfkZ4/HsAxpC/US0m9jq4FdiPV53f3WHcA7yP1Qvpz9vp30hPcunrfr4HvkB669TCpofrrRZtdD9wG3E2q0ipOJmTnMS5b/9vs9Tfg+GydWa/44UdmZlaWSxZmZlaWk4WZmZXlZGFmZmU5WZiZWVlOFmZmVpaThZmZleVkYWZmZTlZmJlZWf8f0mneWWwLClgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_instance.plot_fitness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9dd9ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_array(start, end, total_length):\n",
    "    if end < start:\n",
    "        raise ValueError(\"The second number must be greater than or equal to the first number.\")\n",
    "    \n",
    "    if total_length <= 0:\n",
    "        raise ValueError(\"The total_length must be a positive integer.\")\n",
    "    \n",
    "    # Calculate the length of the portion with 0s\n",
    "    zero_length = min(end - start, total_length)\n",
    "    \n",
    "    # Create the array with 1s initially\n",
    "    result = [1] * total_length\n",
    "    \n",
    "    # Set the portion from start to end with 0s\n",
    "    if zero_length > 0:\n",
    "        result[start:start + zero_length] = [0] * zero_length\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "579b1632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "start_number = outlier_dims[0][0]\n",
    "end_number = outlier_dims[0][1]\n",
    "desired_length = 20\n",
    "\n",
    "result_array = generate_array(start_number, end_number, desired_length)\n",
    "result_array = np.array(result_array)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(1-result_array, 1-solution)\n",
    "recall = recall_score(1-result_array, 1-solution)\n",
    "f1 = f1_score(1-result_array, 1-solution)\n",
    "\n",
    "# Print the results\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9fbb1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9ac194fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 0.2857142857142857\n",
      "F1 Score: 0.4444444444444445\n",
      "Precision: 1.0\n",
      "Recall: 0.9285714285714286\n",
      "F1 Score: 0.962962962962963\n",
      "Precision: 1.0\n",
      "Recall: 0.2857142857142857\n",
      "F1 Score: 0.4444444444444445\n",
      "Precision: 1.0\n",
      "Recall: 0.21428571428571427\n",
      "F1 Score: 0.35294117647058826\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 0.14285714285714285\n",
      "F1 Score: 0.25\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 0.2857142857142857\n",
      "F1 Score: 0.4444444444444445\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-6ebbdf5074d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                               \u001b[0mnum_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                               \u001b[0mnum_generations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                               mutation_probability=0.1)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-cf43ee7ac9a6>\u001b[0m in \u001b[0;36mrun_genetic_on_sample\u001b[0;34m(inlier_samples, outlier_sample, rae_model, num_dims, num_generations, num_parents_mating, sol_per_pop, init_range_low, init_range_high, parent_selection_type, K_tournament, keep_parents, crossover_type, mutation_type, mutation_probability)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;31m#                        on_generation=on_generation,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                        gene_space = space)\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mga_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution_fitness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mga_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/pygad/pygad.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2071\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_generation_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_generation_fitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m                 \u001b[0;31m# Measuring the fitness of each chromosome in the population. Save the fitness in the last_generation_fitness attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2073\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_generation_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_pop_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m                 best_solution, best_solution_fitness, best_match_idx = self.best_solution(\n",
      "\u001b[0;32m~/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/pygad/pygad.py\u001b[0m in \u001b[0;36mcal_pop_fitness\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                         \u001b[0;31m# Check if batch processing is used. If not, then calculate this missing fitness value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness_batch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                             \u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupported_int_float_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-cf43ee7ac9a6>\u001b[0m in \u001b[0;36mfitness_func\u001b[0;34m(ga_instance, solution, solution_idx)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0min_candidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_remain\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_replace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_candidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0min_candidate_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;31m# called multiple times.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcall_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0meager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_clear_losses\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1564\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_flatten_layers\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   2853\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayers_or_containers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m       \u001b[0mseen_object_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mdeque\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_or_containers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m         \u001b[0mlayer_or_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, outlier_index in enumerate(outlier_inds):\n",
    "    \n",
    "    start_number = outlier_dims[i][0]\n",
    "    end_number = outlier_dims[i][1]\n",
    "    desired_length = 20\n",
    "\n",
    "    result_array = generate_array(start_number, end_number, desired_length)\n",
    "    true_labels = np.array(result_array)\n",
    "    \n",
    "    inlier_samples = dataset[:5, :]\n",
    "    outlier_sample = dataset[outlier_index, :]\n",
    "    \n",
    "    ga_instance, solution = run_genetic_on_sample(inlier_samples, \n",
    "                                              outlier_sample, \n",
    "                                              rae, \n",
    "                                              num_dims=20, \n",
    "                                              num_generations = 40, \n",
    "                                              mutation_probability=0.1)\n",
    "    \n",
    "    precision = precision_score(1-true_labels, 1-solution)\n",
    "    recall = recall_score(1-true_labels, 1-solution)\n",
    "    f1 = f1_score(1-true_labels, 1-solution)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "27a5547b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.72489976,  3.79988545,  4.88669797,  6.78653022,  4.47452789,\n",
       "        5.58330981,  5.44677174,  9.89295494,  2.74854279,  4.0567402 ,\n",
       "        7.45260837,  8.22710667,  3.45446456,  4.90834474,  0.408207  ,\n",
       "        0.93612343,  0.87881386,  0.8002054 ,  0.62412487, -0.31169939])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[outlier_inds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40ae4ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 14)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_dims[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
