{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82452ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pygad\n",
    "# import wandb\n",
    "import pandas as pd\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.python.client import device_lib\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9745d565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset_refined(n_samples=100000, n_outliers=100, dimensions=20):\n",
    "    # Generate inliers uniformly within a range\n",
    "    inliers = np.random.uniform(-1, 1, size=(n_samples - n_outliers, dimensions))\n",
    "\n",
    "    # Prepare to generate outliers\n",
    "    outlier_samples = []\n",
    "    outlier_indices = []\n",
    "    outlier_dims = []\n",
    "\n",
    "    # Define different clusters of outliers\n",
    "    cluster_definitions = [\n",
    "        (0, 7),    # First 7 dimensions\n",
    "        (5, 10),   # 5 dimensions in the middle\n",
    "        (3, 8),    # Another set of 5 dimensions, overlapping with the first\n",
    "        (1, 6),    # 5 dimensions starting from second\n",
    "        (6, 10),   # Last 4 dimensions\n",
    "        (0, 4),    # First 4 dimensions\n",
    "        (2, 7),    # 5 dimensions starting from third\n",
    "        (4, 9),    # 5 dimensions starting near the middle\n",
    "        (3, 6),    # 3 dimensions in the middle\n",
    "        (7, 10)    # Last 3 dimensions\n",
    "    ]\n",
    "\n",
    "    # Adjust if the number of dimensions is different\n",
    "    if dimensions != 10:\n",
    "        scaling_factor = dimensions // 10\n",
    "        cluster_definitions = [(start * scaling_factor, min(end * scaling_factor, dimensions)) for start, end in cluster_definitions]\n",
    "\n",
    "    # Generate outliers for each cluster\n",
    "    for start, end in cluster_definitions:\n",
    "        for _ in range(n_outliers // len(cluster_definitions)):\n",
    "            # Normal values for non-deviating dimensions\n",
    "            normal_dims = list(set(range(dimensions)) - set(range(start, end)))\n",
    "            outlier = np.random.uniform(-1, 1, dimensions)\n",
    "            # More extreme values for the deviating dimensions\n",
    "            outlier[start:end] = np.random.uniform(1, 10, end - start)\n",
    "            \n",
    "            outlier_samples.append(outlier)\n",
    "            outlier_indices.append(len(inliers) + len(outlier_samples) - 1)\n",
    "            outlier_dims.append((start, end))\n",
    "\n",
    "    # Combine inliers and outliers\n",
    "    dataset = np.vstack([inliers, np.array(outlier_samples)])\n",
    "\n",
    "    return dataset, outlier_indices, outlier_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec73d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_VAE(data,\n",
    "              latent_dim = 2,\n",
    "              hidden_layer_n = [20,18,16],\n",
    "              num_dims = 10,\n",
    "              kl_loss_factor = 0.01,\n",
    "              epochs = 100,\n",
    "              batch_size = 128\n",
    "              ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Training the VAE on the data\n",
    "    \"\"\"\n",
    "\n",
    "    class Sampling(layers.Layer):\n",
    "        \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "        def call(self, inputs):\n",
    "            z_mean, z_log_var = inputs\n",
    "            batch = tf.shape(z_mean)[0]\n",
    "            dim = tf.shape(z_mean)[1]\n",
    "            epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "            return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    latent_dim = latent_dim\n",
    "\n",
    "    encoder_inputs = keras.Input(shape=(num_dims,))\n",
    "    x = layers.Dense(num_dims, activation=\"sigmoid\")(encoder_inputs)\n",
    "    x = layers.Dense(hidden_layer_n[0], activation=\"sigmoid\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[1], activation=\"sigmoid\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[2], activation=\"sigmoid\")(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(hidden_layer_n[2], activation=\"sigmoid\")(latent_inputs)\n",
    "    x = layers.Dense(hidden_layer_n[1], activation=\"sigmoid\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[0], activation=\"sigmoid\")(x)\n",
    "    decoder_outputs = layers.Dense(num_dims, activation=\"linear\")(x)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "    class VAE(keras.Model):\n",
    "        def __init__(self, encoder, decoder, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "            self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "            self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "                name=\"reconstruction_loss\"\n",
    "            )\n",
    "            self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "        @property\n",
    "        def metrics(self):\n",
    "            return [\n",
    "                self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.kl_loss_tracker,\n",
    "            ]\n",
    "\n",
    "        def train_step(self, data):\n",
    "            with tf.GradientTape() as tape:\n",
    "                z_mean, z_log_var, z = self.encoder(data)\n",
    "                reconstruction = self.decoder(z)\n",
    "                reconstruction_loss = tf.keras.losses.MeanSquaredError()(data,reconstruction)\n",
    "                kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "                total_loss = reconstruction_loss + kl_loss_factor * kl_loss\n",
    "        \n",
    "            grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "            self.total_loss_tracker.update_state(total_loss)\n",
    "            self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "            self.kl_loss_tracker.update_state(kl_loss)\n",
    "            return {\n",
    "                \"loss\": self.total_loss_tracker.result(),\n",
    "                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "                \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            }\n",
    "    \n",
    "    creditdata = np.concatenate([data], axis=0)\n",
    "    creditdata = np.expand_dims(creditdata, -1).astype(\"float32\")\n",
    "\n",
    "    vae = VAE(encoder, decoder)\n",
    "    vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "    history = vae.fit(creditdata,epochs=epochs,batch_size=batch_size,verbose=0)\n",
    "\n",
    "    return vae, history\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_RAE(data,\n",
    "              latent_dim = 2,\n",
    "              hidden_layer_n = [20,18,16],\n",
    "              num_dims = 10,\n",
    "              z_loss_w = 0.01,\n",
    "              REG_loss_w = 0.01,\n",
    "              epochs = 100,\n",
    "              batch_size = 128\n",
    "              ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Training the RAE on the data\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    encoder_inputs = keras.Input(shape=(num_dims,))\n",
    "    x = layers.Dense(hidden_layer_n[0], activation=\"sigmoid\")(encoder_inputs)\n",
    "    x = layers.Dense(hidden_layer_n[1], activation=\"sigmoid\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[2], activation=\"sigmoid\")(x)\n",
    "    encoder_output = layers.Dense(latent_dim, activation=\"sigmoid\")(x)\n",
    "    encoder = keras.Model(encoder_inputs, encoder_output, name=\"encoder\")\n",
    "\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(hidden_layer_n[2], activation=\"sigmoid\")(latent_inputs)\n",
    "    x = layers.Dense(hidden_layer_n[1], activation=\"sigmoid\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[0], activation=\"sigmoid\")(x)\n",
    "    decoder_outputs = layers.Dense(num_dims, activation=\"linear\")(x)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "\n",
    "\n",
    "    class RAE(keras.Model):\n",
    "        def __init__(self, encoder, decoder, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "            self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "            self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "                name=\"reconstruction_loss\"\n",
    "            )\n",
    "            self.z_tracker = keras.metrics.Mean(name=\"z_loss\")\n",
    "            self.REG_tracker = keras.metrics.Mean(name=\"REG_loss\")\n",
    "\n",
    "        @property\n",
    "        def metrics(self):\n",
    "            return [\n",
    "                self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.z_tracker,\n",
    "                self.REG_tracker,\n",
    "            ]\n",
    "\n",
    "        def train_step(self, data):\n",
    "            with tf.GradientTape(persistent=True) as tape:\n",
    "                z = self.encoder(data)\n",
    "                reconstruction = self.decoder(z)\n",
    "\n",
    "                reconstruction_loss = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)(data,reconstruction)\n",
    "\n",
    "                z_loss = K.mean(K.square(z), axis=[1])\n",
    "        \n",
    "                REG_loss = K.mean(K.square(K.gradients(K.square(reconstruction), z)))\n",
    "\n",
    "\n",
    "                total_loss = reconstruction_loss +  z_loss_w * z_loss + REG_loss_w * REG_loss\n",
    "            \n",
    "                grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "                self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "                self.total_loss_tracker.update_state(total_loss)\n",
    "                self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "                self.z_tracker.update_state(z_loss)\n",
    "                self.REG_tracker.update_state(REG_loss)\n",
    "                del tape\n",
    "                return {\n",
    "                    \"loss\": self.total_loss_tracker.result(),\n",
    "                    \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "                    \"z_loss\": self.z_tracker.result(),\n",
    "                    \"REG_loss\": self.REG_tracker.result(),\n",
    "                }\n",
    "\n",
    "    tdata = np.concatenate([data], axis=0)\n",
    "    tdata = np.expand_dims(tdata, -1).astype(\"float32\")\n",
    "\n",
    "    rae = RAE(encoder, decoder)\n",
    "    rae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "    history = rae.fit(tdata,epochs=epochs,batch_size=batch_size,verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "    return rae, history "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a781b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, outlier_inds, outlier_dims = generate_dataset_refined(n_samples=10000, n_outliers=100, dimensions=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ae0061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
     ]
    }
   ],
   "source": [
    "rae, history = train_RAE(dataset,\n",
    "              latent_dim = 10,\n",
    "              hidden_layer_n = [64,32,16],\n",
    "              num_dims = 20,\n",
    "              z_loss_w = 0.01,\n",
    "              REG_loss_w = 0.01,\n",
    "              epochs = 100,\n",
    "              batch_size = 128\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f44839e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5444197654724121,\n",
       " 0.5040704011917114,\n",
       " 0.5043322443962097,\n",
       " 0.5043763518333435,\n",
       " 0.5042622089385986,\n",
       " 0.5042601823806763,\n",
       " 0.5043074488639832,\n",
       " 0.5043081641197205,\n",
       " 0.504589855670929,\n",
       " 0.5044249296188354,\n",
       " 0.5043990612030029,\n",
       " 0.5042928457260132,\n",
       " 0.50437992811203,\n",
       " 0.5045304298400879,\n",
       " 0.504183292388916,\n",
       " 0.5041775107383728,\n",
       " 0.5046468377113342,\n",
       " 0.5040521621704102,\n",
       " 0.5028225183486938,\n",
       " 0.49740472435951233,\n",
       " 0.4896623492240906,\n",
       " 0.48600414395332336,\n",
       " 0.48446372151374817,\n",
       " 0.4830969274044037,\n",
       " 0.480182945728302,\n",
       " 0.47248896956443787,\n",
       " 0.4624408185482025,\n",
       " 0.45395419001579285,\n",
       " 0.44280678033828735,\n",
       " 0.42835283279418945,\n",
       " 0.4156312048435211,\n",
       " 0.40661507844924927,\n",
       " 0.4014735221862793,\n",
       " 0.3984443247318268,\n",
       " 0.39599815011024475,\n",
       " 0.39398297667503357,\n",
       " 0.39235419034957886,\n",
       " 0.39042022824287415,\n",
       " 0.3885226845741272,\n",
       " 0.38640230894088745,\n",
       " 0.38430550694465637,\n",
       " 0.38214775919914246,\n",
       " 0.3803544044494629,\n",
       " 0.3782356381416321,\n",
       " 0.3765733540058136,\n",
       " 0.374873548746109,\n",
       " 0.3737649619579315,\n",
       " 0.37299013137817383,\n",
       " 0.3725617825984955,\n",
       " 0.37218475341796875,\n",
       " 0.3715426027774811,\n",
       " 0.3705909550189972,\n",
       " 0.37010905146598816,\n",
       " 0.36965590715408325,\n",
       " 0.36893272399902344,\n",
       " 0.36871424317359924,\n",
       " 0.3682609796524048,\n",
       " 0.36759111285209656,\n",
       " 0.36743929982185364,\n",
       " 0.3668556213378906,\n",
       " 0.3668633699417114,\n",
       " 0.3661525547504425,\n",
       " 0.3654404282569885,\n",
       " 0.3644504249095917,\n",
       " 0.36385536193847656,\n",
       " 0.36323291063308716,\n",
       " 0.3626492917537689,\n",
       " 0.3621745705604553,\n",
       " 0.3618306517601013,\n",
       " 0.36160385608673096,\n",
       " 0.3612116575241089,\n",
       " 0.3611634373664856,\n",
       " 0.3608205318450928,\n",
       " 0.36031192541122437,\n",
       " 0.3597935736179352,\n",
       " 0.35972633957862854,\n",
       " 0.3593820333480835,\n",
       " 0.35916852951049805,\n",
       " 0.35880541801452637,\n",
       " 0.3585319519042969,\n",
       " 0.3583844304084778,\n",
       " 0.35826969146728516,\n",
       " 0.3578443229198456,\n",
       " 0.35783836245536804,\n",
       " 0.35741126537323,\n",
       " 0.3571173846721649,\n",
       " 0.3567532002925873,\n",
       " 0.3564803898334503,\n",
       " 0.3562973737716675,\n",
       " 0.3560343384742737,\n",
       " 0.35572484135627747,\n",
       " 0.3553277254104614,\n",
       " 0.3552243411540985,\n",
       " 0.35488441586494446,\n",
       " 0.35451939702033997,\n",
       " 0.3542862832546234,\n",
       " 0.35399580001831055,\n",
       " 0.3536031246185303,\n",
       " 0.3532413840293884,\n",
       " 0.35277706384658813]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"reconstruction_loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea5d256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rae_detect_outliers(data,\n",
    "                        rae_model,\n",
    "                        num_dims,\n",
    "                        std_k\n",
    "                        ):\n",
    "\n",
    "    data_mean = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "            \n",
    "        sample = data[i,:].reshape([1,num_dims])\n",
    "        sample = sample.astype('float32')\n",
    "\n",
    "        z = rae_model.encoder(sample)\n",
    "        reconstruction = rae_model.decoder(z)\n",
    "\n",
    "        reconstruction_loss = tf.keras.losses.MeanSquaredError()(sample,reconstruction)\n",
    "        \n",
    "        data_mean.append(reconstruction_loss)\n",
    "    \n",
    "    data_mean = np.array(data_mean)\n",
    "    i_mean = np.mean(data_mean)\n",
    "    data_std = np.std(data_mean)\n",
    "\n",
    "    threshold = i_mean + std_k*data_std\n",
    "\n",
    "    classes = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "            \n",
    "        sample = data[i,:].reshape([1,num_dims])\n",
    "        sample = sample.astype('float32')\n",
    "\n",
    "        z = rae_model.encoder(sample)\n",
    "        reconstruction = rae_model.decoder(z)\n",
    "\n",
    "        reconstruction_loss = tf.keras.losses.MeanSquaredError()(sample,reconstruction)\n",
    "        \n",
    "        if reconstruction_loss > threshold:\n",
    "            \n",
    "            classes.append(0)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            classes.append(1)\n",
    "\n",
    "    classes = np.array(classes)\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8e0c428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = rae_detect_outliers(dataset, rae, num_dims=20, std_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ad75fca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9902"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0239a964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_genetic_on_sample(inlier_samples,\n",
    "                          outlier_sample,\n",
    "                          rae_model,\n",
    "                          num_dims,\n",
    "                          num_generations = 40,\n",
    "                          num_parents_mating = 2,\n",
    "                          sol_per_pop = 20,\n",
    "                          init_range_low = -2,\n",
    "                          init_range_high = 5,\n",
    "                          parent_selection_type = \"tournament\",\n",
    "                          K_tournament = 5,\n",
    "                          keep_parents = 1,\n",
    "                          crossover_type = \"single_point\",\n",
    "                          mutation_type = \"random\",\n",
    "                          mutation_probability = 0.5,\n",
    "                          outlier_w = 0.1,\n",
    "                          l2_w = 0.1\n",
    "                            ):\n",
    "    \n",
    "    def outlier_subspace_fitness(ga_instance, solution, solution_idx):\n",
    "        \n",
    "        \n",
    "        query_point = outlier_sample\n",
    "        query_point = query_point.reshape([1,num_dims])\n",
    "        \n",
    "#         print(query_point)\n",
    "        \n",
    "        abnormal_subspace = solution\n",
    "        normal_subspace = 1 - solution\n",
    "        \n",
    "        abnormal_array = query_point * abnormal_subspace\n",
    "        normal_array = query_point * normal_subspace\n",
    "        \n",
    "        outlier_aspect_average_amount = np.mean(abnormal_array, axis=1)\n",
    "        normal_aspect_average_amount = np.mean(normal_array, axis=1)\n",
    "        \n",
    "        outlier_aspect_average_array = abnormal_array + (normal_subspace * outlier_aspect_average_amount)\n",
    "        normal_aspect_average_array = normal_array + (abnormal_subspace * normal_aspect_average_amount)\n",
    "        \n",
    "        \n",
    "        z_normal = rae_model.encoder(normal_aspect_average_array)\n",
    "        normal_reconstruction = rae_model.decoder(z_normal)\n",
    "        normal_rec_loss = tf.keras.losses.MeanSquaredError()(normal_aspect_average_array,normal_reconstruction)\n",
    "        \n",
    "        z_abnormal = rae_model.encoder(outlier_aspect_average_array)\n",
    "        abnormal_reconstruction = rae_model.decoder(z_abnormal)\n",
    "        abnormal_rec_loss = tf.keras.losses.MeanSquaredError()(outlier_aspect_average_array,abnormal_reconstruction)\n",
    "        \n",
    "#         print(abnormal_rec_loss.numpy())\n",
    "        \n",
    "        fitness = abnormal_rec_loss.numpy() - normal_rec_loss.numpy()\n",
    "#         fitness = abnormal_rec_loss.numpy()\n",
    "        \n",
    "        return fitness\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def fitness_func(ga_instance, solution, solution_idx):\n",
    "\n",
    "        inliers = inlier_samples\n",
    "\n",
    "        avg_ins = np.mean(inliers, axis=0)\n",
    "        avg_ins = avg_ins.reshape([1,num_dims])\n",
    "\n",
    "        particle = outlier_sample\n",
    "        particle = particle.reshape([1,num_dims])\n",
    "\n",
    "        avg_in_rec = []\n",
    "        avg_in_z = []\n",
    "\n",
    "        for index in range(inliers.shape[0]):\n",
    "\n",
    "            candidate_inlier = inliers[index,:]\n",
    "            candidate_inlier = candidate_inlier.reshape([1,num_dims])\n",
    "\n",
    "            in_normal_subspace = solution\n",
    "            in_bad_subspace = 1 - solution        \n",
    "\n",
    "            in_remain = candidate_inlier * in_normal_subspace\n",
    "\n",
    "\n",
    "\n",
    "            in_replace = in_bad_subspace * avg_ins\n",
    "\n",
    "            in_candidate = in_remain + in_replace\n",
    "\n",
    "            z = rae_model.encoder(in_candidate)\n",
    "            in_candidate_rec = rae_model.decoder(z)\n",
    "\n",
    "\n",
    "            rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "            z_loss = K.mean(K.square(z), axis=[1])\n",
    "\n",
    "            avg_in_rec.append(rec_loss.numpy())\n",
    "            avg_in_z.append(z_loss.numpy())\n",
    "\n",
    "        avg_in_rec = np.array(avg_in_rec)\n",
    "        avg_in_rec = np.mean(avg_in_rec)\n",
    "        avg_in_z = np.array(avg_in_z)\n",
    "        avg_in_z = np.mean(avg_in_z)\n",
    "\n",
    "\n",
    "        out_normal_subspace = solution\n",
    "        out_bad_subspace = 1 - solution\n",
    "        \n",
    "        number_of_bad_genes = np.sum(out_bad_subspace)\n",
    "\n",
    "        out_remain = particle * out_normal_subspace\n",
    "\n",
    "\n",
    "\n",
    "        out_replace = avg_ins * out_bad_subspace\n",
    "\n",
    "        out_candidate = out_remain + out_replace\n",
    "\n",
    "\n",
    "        z = rae_model.encoder(out_candidate)\n",
    "        out_candidate_rec = rae_model.decoder(z)\n",
    "\n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "        outlier_z_loss = K.mean(K.square(z), axis=[1])\n",
    "        outlier_z_loss = outlier_z_loss.numpy()\n",
    "        rec_loss = rec_loss.numpy()\n",
    "        \n",
    "#         fitness = outlier_z_loss / avg_in_z\n",
    "#         fitness = outlier_z_loss / (avg_in_rec + 10*avg_in_z)\n",
    "        l2_regularization = l2_w * np.sum(np.square(1-solution))\n",
    "\n",
    "        # Penalty for over-identification of outliers\n",
    "        outlier_penalty = outlier_w * number_of_bad_genes\n",
    "\n",
    "        # Threshold for identifying outliers (you may need to adjust this)\n",
    "        outlier_threshold = 0.7\n",
    "\n",
    "        # Calculate the fitness value\n",
    "        fitness = (rec_loss / avg_in_rec) + l2_regularization + outlier_penalty\n",
    "#         fitness = rec_loss + l2_regularization + outlier_penalty\n",
    "\n",
    "        # Adjust fitness based on the threshold\n",
    "#         if fitness > outlier_threshold:\n",
    "#             fitness = -fitness\n",
    "#         else:\n",
    "#             # Add some positive value to promote good solutions\n",
    "#             fitness = -fitness + 0.1\n",
    "\n",
    "        return -fitness\n",
    "\n",
    "    fitness_function = fitness_func\n",
    "    num_generations = num_generations\n",
    "    num_parents_mating = num_parents_mating\n",
    "    sol_per_pop = sol_per_pop\n",
    "    num_genes = num_dims\n",
    "    init_range_low = init_range_low\n",
    "    init_range_high = init_range_high\n",
    "    parent_selection_type = parent_selection_type\n",
    "    K_tournament = K_tournament\n",
    "    keep_parents = keep_parents\n",
    "    space = [[0,1] for i in range(num_genes)]\n",
    "    crossover_type = crossover_type\n",
    "    mutation_type = mutation_type\n",
    "    mutation_probability = mutation_probability\n",
    "\n",
    "    ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       K_tournament = K_tournament,\n",
    "                       keep_parents=keep_parents,\n",
    "                    #    keep_elitism=5,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_probability=mutation_probability,\n",
    "#                        on_generation=on_generation,\n",
    "                       gene_space = space)\n",
    "    ga_instance.run()\n",
    "\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "\n",
    "    return ga_instance, solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a9ca6d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inlier_samples = dataset[:3, :]\n",
    "outlier_sample = dataset[outlier_inds[1], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "478130f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance, solution = run_genetic_on_sample(inlier_samples,\n",
    "                                              outlier_sample, \n",
    "                                              rae, \n",
    "                                              num_dims=20, \n",
    "                                              num_generations = 100, \n",
    "                                              mutation_probability=0.1,\n",
    "                                              sol_per_pop=20,\n",
    "                                              crossover_type=\"single_point\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6f604e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9.45886788  2.78515778  3.68532116  9.24414908  9.18685923  4.01205122\n",
      "  3.50350387  5.13256701  9.88499132  8.95072899  4.10967059  5.51709378\n",
      "  7.70607861  5.92116112 -0.89366365 -0.68128234  0.95260201 -0.31248075\n",
      "  0.22575025  0.70034011]\n",
      "[0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(outlier_sample)\n",
    "print(solution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "008f97ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.,\n",
       "        1., 1., 1.]),\n",
       " -22.176020431518552,\n",
       " 0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_instance.best_solution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6898385",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "53f9fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.45491008]\n",
      "[-0.00043672]\n",
      "[[9.45886788 2.78515778 3.68532116 9.24414908 9.18685923 4.01205122\n",
      "  3.50350387 5.13256701 9.88499132 8.95072899 4.10967059 5.51709378\n",
      "  7.70607861 5.92116112 4.45491008 4.45491008 4.45491008 4.45491008\n",
      "  4.45491008 4.45491008]]\n",
      "[[-4.36718125e-04 -4.36718125e-04 -4.36718125e-04 -4.36718125e-04\n",
      "  -4.36718125e-04 -4.36718125e-04 -4.36718125e-04 -4.36718125e-04\n",
      "  -4.36718125e-04 -4.36718125e-04 -4.36718125e-04 -4.36718125e-04\n",
      "  -4.36718125e-04 -4.36718125e-04 -8.93663653e-01 -6.81282339e-01\n",
      "   9.52602012e-01 -3.12480746e-01  2.25750251e-01  7.00340112e-01]]\n",
      "16.437168\n",
      "0.12857437\n",
      "16.308594\n"
     ]
    }
   ],
   "source": [
    "cand_solution = np.array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.])\n",
    "\n",
    "num_dims=20\n",
    "query_point = outlier_sample\n",
    "query_point = query_point.reshape([1,num_dims])\n",
    "\n",
    "#         print(query_point)\n",
    "\n",
    "abnormal_subspace = cand_solution\n",
    "normal_subspace = 1 - cand_solution\n",
    "\n",
    "abnormal_array = query_point * abnormal_subspace\n",
    "normal_array = query_point * normal_subspace\n",
    "\n",
    "outlier_aspect_average_amount = np.mean(abnormal_array, axis=1)\n",
    "normal_aspect_average_amount = np.mean(normal_array, axis=1)\n",
    "\n",
    "print(outlier_aspect_average_amount)\n",
    "print(normal_aspect_average_amount)\n",
    "\n",
    "outlier_aspect_average_array = abnormal_array + (normal_subspace * outlier_aspect_average_amount)\n",
    "normal_aspect_average_array = normal_array + (abnormal_subspace * normal_aspect_average_amount)\n",
    "\n",
    "print(outlier_aspect_average_array)\n",
    "print(normal_aspect_average_array)\n",
    "\n",
    "z_normal = rae.encoder(normal_aspect_average_array)\n",
    "normal_reconstruction = rae.decoder(z_normal)\n",
    "normal_rec_loss = tf.keras.losses.MeanSquaredError()(normal_aspect_average_array,normal_reconstruction)\n",
    "\n",
    "z_abnormal = rae.encoder(outlier_aspect_average_array)\n",
    "abnormal_reconstruction = rae.decoder(z_abnormal)\n",
    "abnormal_rec_loss = tf.keras.losses.MeanSquaredError()(outlier_aspect_average_array,abnormal_reconstruction)\n",
    "\n",
    "#         print(abnormal_rec_loss.numpy())\n",
    "\n",
    "fitness = abnormal_rec_loss.numpy() - normal_rec_loss.numpy()\n",
    "print(abnormal_rec_loss.numpy())\n",
    "print(normal_rec_loss.numpy())\n",
    "print(fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c4b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0a17598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def fitness_func_test(solution):\n",
    "\n",
    "    inliers = inlier_samples\n",
    "\n",
    "    avg_ins = np.mean(inliers, axis=0)\n",
    "    avg_ins = avg_ins.reshape([1,num_dims])\n",
    "\n",
    "    particle = outlier_sample\n",
    "    particle = particle.reshape([1,num_dims])\n",
    "\n",
    "    avg_in_rec = []\n",
    "    avg_in_z = []\n",
    "\n",
    "    for index in range(inliers.shape[0]):\n",
    "\n",
    "        candidate_inlier = inliers[index,:]\n",
    "        candidate_inlier = candidate_inlier.reshape([1,num_dims])\n",
    "\n",
    "        in_normal_subspace = solution\n",
    "        in_bad_subspace = 1 - solution        \n",
    "\n",
    "        in_remain = candidate_inlier * in_normal_subspace\n",
    "\n",
    "\n",
    "\n",
    "        in_replace = in_bad_subspace * avg_ins\n",
    "\n",
    "        in_candidate = in_remain + in_replace\n",
    "\n",
    "        z = rae.encoder(in_candidate)\n",
    "        in_candidate_rec = rae.decoder(z)\n",
    "\n",
    "\n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "        z_loss = K.mean(K.square(z), axis=[1])\n",
    "\n",
    "        avg_in_rec.append(rec_loss.numpy())\n",
    "        avg_in_z.append(z_loss.numpy())\n",
    "\n",
    "    avg_in_rec = np.array(avg_in_rec)\n",
    "    avg_in_rec = np.mean(avg_in_rec)\n",
    "    avg_in_z = np.array(avg_in_z)\n",
    "    avg_in_z = np.mean(avg_in_z)\n",
    "\n",
    "\n",
    "    out_normal_subspace = solution\n",
    "    out_bad_subspace = 1 - solution\n",
    "\n",
    "    number_of_bad_genes = np.sum(out_bad_subspace)\n",
    "\n",
    "    out_remain = particle * out_normal_subspace\n",
    "\n",
    "\n",
    "\n",
    "    out_replace = avg_ins * out_bad_subspace\n",
    "\n",
    "    out_candidate = out_remain + out_replace\n",
    "\n",
    "\n",
    "    z = rae.encoder(out_candidate)\n",
    "    out_candidate_rec = rae.decoder(z)\n",
    "\n",
    "    rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "    outlier_z_loss = K.mean(K.square(z), axis=[1])\n",
    "    outlier_z_loss = outlier_z_loss.numpy()\n",
    "    rec_loss = rec_loss.numpy()\n",
    "\n",
    "#         fitness = outlier_z_loss / avg_in_z\n",
    "#         fitness = outlier_z_loss / (avg_in_rec + 10*avg_in_z)\n",
    "    # Regularization term (L2)\n",
    "    l2_regularization = 0.1 * np.sum(np.square(1-solution))\n",
    "\n",
    "    # Penalty for over-identification of outliers\n",
    "    outlier_penalty = 0.1 * number_of_bad_genes\n",
    "\n",
    "    # Threshold for identifying outliers (you may need to adjust this)\n",
    "    outlier_threshold = 0.7\n",
    "\n",
    "    # Calculate the fitness value\n",
    "    fitness = (rec_loss / avg_in_rec) + l2_regularization + outlier_penalty\n",
    "\n",
    "    # Adjust fitness based on the threshold\n",
    "    if fitness > outlier_threshold:\n",
    "        fitness = -fitness\n",
    "    else:\n",
    "        # Add some positive value to promote good solutions\n",
    "        fitness = -fitness + 0.1\n",
    "\n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b32a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e118299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dims = 20\n",
    "cand_solution = np.array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de078570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-32.29293327331543\n",
      "-32.29293327331543\n"
     ]
    }
   ],
   "source": [
    "print(fitness_func_test(1-cand_solution))\n",
    "print(fitness_func_test(solution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e279b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       1., 1., 0.])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "de5ddc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ga_instance.plot_fitness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9dd9ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_array(start, end, total_length):\n",
    "    if end < start:\n",
    "        raise ValueError(\"The second number must be greater than or equal to the first number.\")\n",
    "    \n",
    "    if total_length <= 0:\n",
    "        raise ValueError(\"The total_length must be a positive integer.\")\n",
    "    \n",
    "    # Calculate the length of the portion with 0s\n",
    "    zero_length = min(end - start, total_length)\n",
    "    \n",
    "    # Create the array with 1s initially\n",
    "    result = [1] * total_length\n",
    "    \n",
    "    # Set the portion from start to end with 0s\n",
    "    if zero_length > 0:\n",
    "        result[start:start + zero_length] = [0] * zero_length\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "579b1632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "start_number = outlier_dims[0][0]\n",
    "end_number = outlier_dims[0][1]\n",
    "desired_length = 20\n",
    "\n",
    "result_array = generate_array(start_number, end_number, desired_length)\n",
    "result_array = np.array(result_array)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(1-result_array, 1-solution)\n",
    "recall = recall_score(1-result_array, 1-solution)\n",
    "f1 = f1_score(1-result_array, 1-solution)\n",
    "\n",
    "# Print the results\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9fbb1cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9ac194fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 0.2857142857142857\n",
      "F1 Score: 0.4444444444444445\n",
      "Precision: 1.0\n",
      "Recall: 0.9285714285714286\n",
      "F1 Score: 0.962962962962963\n",
      "Precision: 1.0\n",
      "Recall: 0.2857142857142857\n",
      "F1 Score: 0.4444444444444445\n",
      "Precision: 1.0\n",
      "Recall: 0.21428571428571427\n",
      "F1 Score: 0.35294117647058826\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 0.14285714285714285\n",
      "F1 Score: 0.25\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 0.2857142857142857\n",
      "F1 Score: 0.4444444444444445\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-74-6ebbdf5074d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                               \u001b[0mnum_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                               \u001b[0mnum_generations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                                               mutation_probability=0.1)\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrue_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msolution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-cf43ee7ac9a6>\u001b[0m in \u001b[0;36mrun_genetic_on_sample\u001b[0;34m(inlier_samples, outlier_sample, rae_model, num_dims, num_generations, num_parents_mating, sol_per_pop, init_range_low, init_range_high, parent_selection_type, K_tournament, keep_parents, crossover_type, mutation_type, mutation_probability)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;31m#                        on_generation=on_generation,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                        gene_space = space)\n\u001b[0;32m--> 178\u001b[0;31m     \u001b[0mga_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0msolution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution_fitness\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolution_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mga_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_solution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/pygad/pygad.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2071\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprevious_generation_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_generation_fitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m                 \u001b[0;31m# Measuring the fitness of each chromosome in the population. Save the fitness in the last_generation_fitness attribute.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2073\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_generation_fitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_pop_fitness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m                 best_solution, best_solution_fitness, best_match_idx = self.best_solution(\n",
      "\u001b[0;32m~/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/pygad/pygad.py\u001b[0m in \u001b[0;36mcal_pop_fitness\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                         \u001b[0;31m# Check if batch processing is used. If not, then calculate this missing fitness value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness_batch_size\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                             \u001b[0mfitness\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msol_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1670\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupported_int_float_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m                                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-cf43ee7ac9a6>\u001b[0m in \u001b[0;36mfitness_func\u001b[0;34m(ga_instance, solution, solution_idx)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0min_candidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_remain\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0min_replace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_candidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0min_candidate_rec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrae_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    957\u001b[0m     \u001b[0;31m# called multiple times.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcall_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 959\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_losses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[0meager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_clear_losses\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1564\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flatten_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_flatten_layers\u001b[0;34m(self, recursive, include_self)\u001b[0m\n\u001b[1;32m   2853\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayers_or_containers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m       \u001b[0mseen_object_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mdeque\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeque\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers_or_containers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m         \u001b[0mlayer_or_container\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, outlier_index in enumerate(outlier_inds):\n",
    "    \n",
    "    start_number = outlier_dims[i][0]\n",
    "    end_number = outlier_dims[i][1]\n",
    "    desired_length = 20\n",
    "\n",
    "    result_array = generate_array(start_number, end_number, desired_length)\n",
    "    true_labels = np.array(result_array)\n",
    "    \n",
    "    inlier_samples = dataset[:5, :]\n",
    "    outlier_sample = dataset[outlier_index, :]\n",
    "    \n",
    "    ga_instance, solution = run_genetic_on_sample(inlier_samples, \n",
    "                                              outlier_sample, \n",
    "                                              rae, \n",
    "                                              num_dims=20, \n",
    "                                              num_generations = 40, \n",
    "                                              mutation_probability=0.1)\n",
    "    \n",
    "    precision = precision_score(1-true_labels, 1-solution)\n",
    "    recall = recall_score(1-true_labels, 1-solution)\n",
    "    f1 = f1_score(1-true_labels, 1-solution)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "27a5547b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.72489976,  3.79988545,  4.88669797,  6.78653022,  4.47452789,\n",
       "        5.58330981,  5.44677174,  9.89295494,  2.74854279,  4.0567402 ,\n",
       "        7.45260837,  8.22710667,  3.45446456,  4.90834474,  0.408207  ,\n",
       "        0.93612343,  0.87881386,  0.8002054 ,  0.62412487, -0.31169939])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[outlier_inds[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40ae4ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 14)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df4af31c",
   "metadata": {},
   "source": [
    "# Real World Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5b4fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_world_csv_data_loader(name):\n",
    "\n",
    "    if name == \"10-speech_pca.csv\":\n",
    "\n",
    "        csv_file = './data/10-speech_pca.csv'\n",
    "        label_csv_files = ['./data_od_evaluation/speech_pca_gt_copod.csv', \n",
    "                           './data_od_evaluation/speech_pca_gt_hbos.csv',\n",
    "                           './data_od_evaluation/speech_pca_gt_iforest.csv']\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        gt_copod = pd.read_csv(label_csv_files[0])\n",
    "        gt_hbos = pd.read_csv(label_csv_files[1])\n",
    "        gt_iforest = pd.read_csv(label_csv_files[2])\n",
    "\n",
    "        last_column = data.iloc[:, -1].values\n",
    "        # last_column = np.where(last_column == 0, 0, 1)\n",
    "        labels = last_column\n",
    "        data = np.array(data)\n",
    "        GTs = [gt_copod, gt_hbos, gt_iforest]\n",
    "        data_n = data[:,:-1]\n",
    "    \n",
    "    \n",
    "    if name == \"09-satimage-2_pca.csv\":\n",
    "\n",
    "        csv_file = './data/09-satimage-2_pca.csv'\n",
    "        label_csv_files = ['./data_od_evaluation/satimage-2_pca_gt_copod.csv', \n",
    "                           './data_od_evaluation/satimage-2_pca_gt_hbos.csv',\n",
    "                           './data_od_evaluation/satimage-2_pca_gt_iforest.csv']\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        gt_copod = pd.read_csv(label_csv_files[0])\n",
    "        gt_hbos = pd.read_csv(label_csv_files[1])\n",
    "        gt_iforest = pd.read_csv(label_csv_files[2])\n",
    "\n",
    "        last_column = data.iloc[:, -1].values\n",
    "        # last_column = np.where(last_column == 0, 0, 1)\n",
    "        labels = last_column\n",
    "        data = np.array(data)\n",
    "        GTs = [gt_copod, gt_hbos, gt_iforest]\n",
    "        data_n = data[:,:-1]\n",
    "        \n",
    "        \n",
    "    if name == \"07-arrhythmia_pca.csv\":\n",
    "\n",
    "        csv_file = './data/07-arrhythmia_pca.csv'\n",
    "        label_csv_files = ['./data_od_evaluation/arrhythmia_pca_gt_copod.csv', \n",
    "                           './data_od_evaluation/arrhythmia_pca_gt_hbos.csv',\n",
    "                           './data_od_evaluation/arrhythmia_pca_gt_iforest.csv']\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        gt_copod = pd.read_csv(label_csv_files[0])\n",
    "        gt_hbos = pd.read_csv(label_csv_files[1])\n",
    "        gt_iforest = pd.read_csv(label_csv_files[2])\n",
    "\n",
    "        last_column = data.iloc[:, -1].values\n",
    "        # last_column = np.where(last_column == 0, 0, 1)\n",
    "        labels = last_column\n",
    "        data = np.array(data)\n",
    "        GTs = [gt_copod, gt_hbos, gt_iforest]\n",
    "        data_n = data[:,:-1]\n",
    "    \n",
    "    if name == \"02-wineQualityReds-od2.csv\":\n",
    "\n",
    "        csv_file = './data/02-wineQualityReds-od2.csv'\n",
    "        label_csv_files = ['./data_od_evaluation/wineQualityReds-od2_gt_copod.csv', \n",
    "                           './data_od_evaluation/wineQualityReds-od2_gt_hbos.csv',\n",
    "                           './data_od_evaluation/wineQualityReds-od2_gt_iforest.csv']\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        gt_copod = pd.read_csv(label_csv_files[0])\n",
    "        gt_hbos = pd.read_csv(label_csv_files[1])\n",
    "        gt_iforest = pd.read_csv(label_csv_files[2])\n",
    "\n",
    "        last_column = data.iloc[:, -1].values\n",
    "        # last_column = np.where(last_column == 0, 0, 1)\n",
    "        labels = last_column\n",
    "        data = np.array(data)\n",
    "        GTs = [gt_copod, gt_hbos, gt_iforest]\n",
    "        data_n = data[:,:-1]\n",
    "        \n",
    "    if name == \"03-wineQualityWhites-od2.csv\":\n",
    "\n",
    "        csv_file = './data/03-wineQualityWhites-od2.csv'\n",
    "        label_csv_files = ['./data_od_evaluation/wineQualityWhites-od2_gt_copod.csv', \n",
    "                           './data_od_evaluation/wineQualityWhites-od2_gt_hbos.csv',\n",
    "                           './data_od_evaluation/wineQualityWhites-od2_gt_iforest.csv']\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        gt_copod = pd.read_csv(label_csv_files[0])\n",
    "        gt_hbos = pd.read_csv(label_csv_files[1])\n",
    "        gt_iforest = pd.read_csv(label_csv_files[2])\n",
    "\n",
    "        last_column = data.iloc[:, -1].values\n",
    "        # last_column = np.where(last_column == 0, 0, 1)\n",
    "        labels = last_column\n",
    "        data = np.array(data)\n",
    "        GTs = [gt_copod, gt_hbos, gt_iforest]\n",
    "        data_n = data[:,:-1]\n",
    "    \n",
    "    if name == \"11-optdigits_pca.csv\":\n",
    "\n",
    "        csv_file = './data/11-optdigits_pca.csv'\n",
    "        label_csv_files = ['./data_od_evaluation/optdigits_pca_gt_copod.csv', \n",
    "                           './data_od_evaluation/optdigits_pca_gt_hbos.csv',\n",
    "                           './data_od_evaluation/optdigits_pca_gt_iforest.csv']\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        gt_copod = pd.read_csv(label_csv_files[0])\n",
    "        gt_hbos = pd.read_csv(label_csv_files[1])\n",
    "        gt_iforest = pd.read_csv(label_csv_files[2])\n",
    "\n",
    "        last_column = data.iloc[:, -1].values\n",
    "        # last_column = np.where(last_column == 0, 0, 1)\n",
    "        labels = last_column\n",
    "        data = np.array(data)\n",
    "        GTs = [gt_copod, gt_hbos, gt_iforest]\n",
    "        data_n = data[:,:-1]\n",
    "        \n",
    "    if name == \"08-wbc_pca.csv\":\n",
    "\n",
    "        csv_file = './data/08-wbc_pca.csv'\n",
    "        label_csv_files = ['./data_od_evaluation/wbc_pca_gt_copod.csv', \n",
    "                           './data_od_evaluation/wbc_pca_gt_hbos.csv',\n",
    "                           './data_od_evaluation/wbc_pca_gt_iforest.csv']\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        gt_copod = pd.read_csv(label_csv_files[0])\n",
    "        gt_hbos = pd.read_csv(label_csv_files[1])\n",
    "        gt_iforest = pd.read_csv(label_csv_files[2])\n",
    "\n",
    "        last_column = data.iloc[:, -1].values\n",
    "        # last_column = np.where(last_column == 0, 0, 1)\n",
    "        labels = last_column\n",
    "        data = np.array(data)\n",
    "        GTs = [gt_copod, gt_hbos, gt_iforest]\n",
    "        data_n = data[:,:-1]\n",
    "    \n",
    "    if name == \"01-vertebral.csv\":\n",
    "\n",
    "        csv_file = './data/01-vertebral.csv'\n",
    "        label_csv_files = ['./data_od_evaluation/vertebral_gt_copod.csv', \n",
    "                           './data_od_evaluation/vertebral_gt_hbos.csv',\n",
    "                           './data_od_evaluation/vertebral_gt_iforest.csv']\n",
    "        data = pd.read_csv(csv_file)\n",
    "\n",
    "        gt_copod = pd.read_csv(label_csv_files[0])\n",
    "        gt_hbos = pd.read_csv(label_csv_files[1])\n",
    "        gt_iforest = pd.read_csv(label_csv_files[2])\n",
    "\n",
    "        last_column = data.iloc[:, -1].values\n",
    "        # last_column = np.where(last_column == 0, 0, 1)\n",
    "        labels = last_column\n",
    "        data = np.array(data)\n",
    "        GTs = [gt_copod, gt_hbos, gt_iforest]\n",
    "        data_n = data[:,:-1]\n",
    "        \n",
    "    return data_n, labels, GTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f001bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 6)\n"
     ]
    }
   ],
   "source": [
    "data_n, labels, GTs = real_world_csv_data_loader(\"01-vertebral.csv\")\n",
    "print(data_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c17e2a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "rae, history = train_RAE(data_n,\n",
    "              latent_dim = 2,\n",
    "              hidden_layer_n = [8,6,4],\n",
    "              num_dims = data_n.shape[1],\n",
    "              z_loss_w = 0.01,\n",
    "              REG_loss_w = 0.01,\n",
    "              epochs = 10000,\n",
    "              batch_size = 128\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6fda53e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f010408af28>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"reconstruction_loss\"])\n",
    "# plt.plot(history.history[\"z_loss\"])\n",
    "# plt.plot(history.history[\"REG_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c0a975c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = rae_detect_outliers(data_n, rae, num_dims=data_n.shape[1], std_k=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dead949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "30.0\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(1-classes))\n",
    "print(np.sum(labels))\n",
    "predictions = 1-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0e92e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.08\n",
      "Recall: 0.13333333333333333\n",
      "F1 Score: 0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(labels, predictions)\n",
    "recall = recall_score(labels, predictions)\n",
    "f1 = f1_score(labels, predictions)\n",
    "\n",
    "# Print the results\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3101916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  5,   7,   9,  11,  17,  24,  26,  35,  36,  37,  40,  47,  49,\n",
       "         53,  54,  61,  71,  75,  76,  83,  85,  92,  95,  96, 104, 107,\n",
       "        111, 114, 115, 121, 135, 141, 142, 143, 162, 163, 167, 168, 180,\n",
       "        192, 197, 201, 202, 205, 206, 208, 215, 220, 227, 237]),)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc9aa686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222,\n",
       "       223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235,\n",
       "       236, 237, 238, 239])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_zero = np.where(labels != 0)\n",
    "non_zero[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d01f4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_sample = data_n[0,:]\n",
    "inlier_samples = data_n[62:64,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "777b6d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance, solution = run_genetic_on_sample(inlier_samples,\n",
    "                                              outlier_sample, \n",
    "                                              rae, \n",
    "                                              num_dims=data_n.shape[1], \n",
    "                                              num_generations = 100, \n",
    "                                              mutation_probability=0.1,\n",
    "                                              sol_per_pop=20,\n",
    "                                              crossover_type=\"uniform\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cc1ab604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "gt_0 = np.array(GTs[2])\n",
    "print(gt_0[0,1])\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d24f2fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, jaccard_score, auc, roc_curve, precision_recall_curve\n",
    "from sklearn.metrics import recall_score, f1_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10f963cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "0\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 0. 1. 1. 1.]\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.50\n",
      "AUPR: 0.83\n",
      "%%%%%%\n",
      "0\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "#######################################\n",
      "1\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 0. 1.]\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.50\n",
      "AUPR: 0.83\n",
      "%%%%%%\n",
      "1\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "1\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "#######################################\n",
      "2\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 0. 1.]\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.50\n",
      "AUPR: 0.83\n",
      "%%%%%%\n",
      "2\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "2\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "#######################################\n",
      "3\n",
      "[1. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 0. 1.]\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.62\n",
      "AUPR: 0.83\n",
      "%%%%%%\n",
      "3\n",
      "[1. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.75\n",
      "Recall: 0.60\n",
      "F1-Score: 0.67\n",
      "Jaccard Index: 0.50\n",
      "AUROC: 0.30\n",
      "AUPR: 0.84\n",
      "%%%%%%\n",
      "3\n",
      "[1. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 0. 1.]\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.62\n",
      "AUPR: 0.83\n",
      "#######################################\n",
      "4\n",
      "[0. 1. 1. 0. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.60\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.80\n",
      "AUPR: 0.97\n",
      "%%%%%%\n",
      "4\n",
      "[0. 1. 1. 0. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.60\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.80\n",
      "AUPR: 0.97\n",
      "%%%%%%\n",
      "4\n",
      "[0. 1. 1. 0. 0. 1.]\n",
      "[1. 0. 1. 1. 0. 1.]\n",
      "Precision: 0.67\n",
      "Recall: 0.50\n",
      "F1-Score: 0.57\n",
      "Jaccard Index: 0.40\n",
      "AUROC: 0.50\n",
      "AUPR: 0.75\n",
      "#######################################\n",
      "5\n",
      "[0. 0. 0. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 0.]\n",
      "Precision: 1.00\n",
      "Recall: 0.50\n",
      "F1-Score: 0.67\n",
      "Jaccard Index: 0.50\n",
      "AUROC: 0.75\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "5\n",
      "[0. 0. 0. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.40\n",
      "F1-Score: 0.57\n",
      "Jaccard Index: 0.40\n",
      "AUROC: 0.70\n",
      "AUPR: 0.95\n",
      "%%%%%%\n",
      "5\n",
      "[0. 0. 0. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.40\n",
      "F1-Score: 0.57\n",
      "Jaccard Index: 0.40\n",
      "AUROC: 0.70\n",
      "AUPR: 0.95\n",
      "#######################################\n",
      "6\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 1. 0.]\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.88\n",
      "AUPR: 0.83\n",
      "%%%%%%\n",
      "6\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "[1. 1. 0. 0. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.75\n",
      "F1-Score: 0.86\n",
      "Jaccard Index: 0.75\n",
      "AUROC: 0.88\n",
      "AUPR: 0.96\n",
      "%%%%%%\n",
      "6\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 1. 0. 1.]\n",
      "Precision: 0.33\n",
      "Recall: 0.33\n",
      "F1-Score: 0.33\n",
      "Jaccard Index: 0.20\n",
      "AUROC: 0.33\n",
      "AUPR: 0.50\n",
      "#######################################\n",
      "7\n",
      "[0. 0. 1. 1. 1. 1.]\n",
      "[0. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "Jaccard Index: 1.00\n",
      "AUROC: 1.00\n",
      "AUPR: 1.00\n",
      "%%%%%%\n",
      "7\n",
      "[0. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.80\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.90\n",
      "AUPR: 0.98\n",
      "%%%%%%\n",
      "7\n",
      "[0. 0. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 0.]\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.62\n",
      "AUPR: 0.83\n",
      "#######################################\n",
      "8\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 0. 1. 1. 1.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "8\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "8\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 0. 1. 1. 1.]\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.50\n",
      "AUPR: 0.83\n",
      "#######################################\n",
      "9\n",
      "[0. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 0.]\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.62\n",
      "AUPR: 0.83\n",
      "%%%%%%\n",
      "9\n",
      "[0. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.80\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.90\n",
      "AUPR: 0.98\n",
      "%%%%%%\n",
      "9\n",
      "[0. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.80\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.90\n",
      "AUPR: 0.98\n",
      "#######################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ali/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ali/anaconda3/envs/deeplab-pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 1.]\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n",
      "Jaccard Index: 0.00\n",
      "AUROC: 0.50\n",
      "AUPR: 0.67\n",
      "%%%%%%\n",
      "10\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n",
      "Jaccard Index: 0.00\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "10\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 1. 0. 1.]\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n",
      "Jaccard Index: 0.00\n",
      "AUROC: 0.50\n",
      "AUPR: 0.75\n",
      "#######################################\n",
      "11\n",
      "[0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.40\n",
      "AUPR: 0.88\n",
      "%%%%%%\n",
      "11\n",
      "[0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.40\n",
      "AUPR: 0.88\n",
      "%%%%%%\n",
      "11\n",
      "[0. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.40\n",
      "AUPR: 0.88\n",
      "#######################################\n",
      "12\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 0. 1.]\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.50\n",
      "AUPR: 0.83\n",
      "%%%%%%\n",
      "12\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "12\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.50\n",
      "AUPR: 0.83\n",
      "#######################################\n",
      "13\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.75\n",
      "AUPR: 0.90\n",
      "%%%%%%\n",
      "13\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "Jaccard Index: 1.00\n",
      "AUROC: 1.00\n",
      "AUPR: 1.00\n",
      "%%%%%%\n",
      "13\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.75\n",
      "AUPR: 0.90\n",
      "#######################################\n",
      "14\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 0. 0. 1. 0.]\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.88\n",
      "AUPR: 0.83\n",
      "%%%%%%\n",
      "14\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 0.67\n",
      "Recall: 0.40\n",
      "F1-Score: 0.50\n",
      "Jaccard Index: 0.33\n",
      "AUROC: 0.20\n",
      "AUPR: 0.78\n",
      "%%%%%%\n",
      "14\n",
      "[1. 1. 0. 0. 1. 0.]\n",
      "[0. 1. 0. 1. 1. 1.]\n",
      "Precision: 0.67\n",
      "Recall: 0.50\n",
      "F1-Score: 0.57\n",
      "Jaccard Index: 0.40\n",
      "AUROC: 0.50\n",
      "AUPR: 0.75\n",
      "#######################################\n",
      "15\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.75\n",
      "AUPR: 0.90\n",
      "%%%%%%\n",
      "15\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.40\n",
      "AUPR: 0.88\n",
      "%%%%%%\n",
      "15\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 0.]\n",
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.75\n",
      "AUPR: 0.90\n",
      "#######################################\n",
      "16\n",
      "[1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.40\n",
      "AUPR: 0.88\n",
      "%%%%%%\n",
      "16\n",
      "[1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.40\n",
      "AUPR: 0.88\n",
      "%%%%%%\n",
      "16\n",
      "[1. 1. 0. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0.]\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.40\n",
      "AUPR: 0.88\n",
      "#######################################\n",
      "17\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 0. 1. 0. 1.]\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-Score: 0.00\n",
      "Jaccard Index: 0.00\n",
      "AUROC: 0.38\n",
      "AUPR: 0.17\n",
      "%%%%%%\n",
      "17\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[0. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.25\n",
      "F1-Score: 0.40\n",
      "Jaccard Index: 0.25\n",
      "AUROC: 0.62\n",
      "AUPR: 0.88\n",
      "%%%%%%\n",
      "17\n",
      "[0. 0. 0. 0. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.20\n",
      "F1-Score: 0.33\n",
      "Jaccard Index: 0.20\n",
      "AUROC: 0.60\n",
      "AUPR: 0.93\n",
      "#######################################\n",
      "18\n",
      "[0. 0. 1. 0. 0. 1.]\n",
      "[0. 1. 1. 1. 0. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.50\n",
      "F1-Score: 0.67\n",
      "Jaccard Index: 0.50\n",
      "AUROC: 0.75\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "18\n",
      "[0. 0. 1. 0. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.40\n",
      "F1-Score: 0.57\n",
      "Jaccard Index: 0.40\n",
      "AUROC: 0.70\n",
      "AUPR: 0.95\n",
      "%%%%%%\n",
      "18\n",
      "[0. 0. 1. 0. 0. 1.]\n",
      "[0. 1. 0. 1. 1. 1.]\n",
      "Precision: 0.50\n",
      "Recall: 0.25\n",
      "F1-Score: 0.33\n",
      "Jaccard Index: 0.20\n",
      "AUROC: 0.38\n",
      "AUPR: 0.62\n",
      "#######################################\n",
      "19\n",
      "[0. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.62\n",
      "AUPR: 0.83\n",
      "%%%%%%\n",
      "19\n",
      "[0. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.75\n",
      "Recall: 0.60\n",
      "F1-Score: 0.67\n",
      "Jaccard Index: 0.50\n",
      "AUROC: 0.30\n",
      "AUPR: 0.84\n",
      "%%%%%%\n",
      "19\n",
      "[0. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.62\n",
      "AUPR: 0.83\n",
      "#######################################\n",
      "20\n",
      "[1. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 0.]\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "Jaccard Index: 1.00\n",
      "AUROC: 1.00\n",
      "AUPR: 1.00\n",
      "%%%%%%\n",
      "20\n",
      "[1. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.80\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.90\n",
      "AUPR: 0.98\n",
      "%%%%%%\n",
      "20\n",
      "[1. 0. 1. 1. 1. 0.]\n",
      "[1. 0. 1. 0. 1. 0.]\n",
      "Precision: 0.75\n",
      "Recall: 1.00\n",
      "F1-Score: 0.86\n",
      "Jaccard Index: 0.75\n",
      "AUROC: 0.83\n",
      "AUPR: 0.88\n",
      "#######################################\n",
      "21\n",
      "[1. 1. 0. 0. 1. 1.]\n",
      "[1. 1. 0. 0. 0. 1.]\n",
      "Precision: 0.75\n",
      "Recall: 1.00\n",
      "F1-Score: 0.86\n",
      "Jaccard Index: 0.75\n",
      "AUROC: 0.83\n",
      "AUPR: 0.88\n",
      "%%%%%%\n",
      "21\n",
      "[1. 1. 0. 0. 1. 1.]\n",
      "[1. 1. 0. 0. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "Jaccard Index: 1.00\n",
      "AUROC: 1.00\n",
      "AUPR: 1.00\n",
      "%%%%%%\n",
      "21\n",
      "[1. 1. 0. 0. 1. 1.]\n",
      "[1. 1. 0. 1. 0. 1.]\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.62\n",
      "AUPR: 0.83\n",
      "#######################################\n",
      "22\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 0.]\n",
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.75\n",
      "AUPR: 0.90\n",
      "%%%%%%\n",
      "22\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "Jaccard Index: 1.00\n",
      "AUROC: 1.00\n",
      "AUPR: 1.00\n",
      "%%%%%%\n",
      "22\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "[1. 0. 0. 0. 1. 1.]\n",
      "Precision: 0.60\n",
      "Recall: 1.00\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.67\n",
      "AUPR: 0.80\n",
      "#######################################\n",
      "23\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "Jaccard Index: 1.00\n",
      "AUROC: 1.00\n",
      "AUPR: 1.00\n",
      "%%%%%%\n",
      "23\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.40\n",
      "AUPR: 0.88\n",
      "%%%%%%\n",
      "23\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 0.]\n",
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.75\n",
      "AUPR: 0.90\n",
      "#######################################\n",
      "24\n",
      "[0. 0. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.60\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.80\n",
      "AUPR: 0.97\n",
      "%%%%%%\n",
      "24\n",
      "[0. 0. 1. 1. 0. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.60\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.80\n",
      "AUPR: 0.97\n",
      "%%%%%%\n",
      "24\n",
      "[0. 0. 1. 1. 0. 1.]\n",
      "[1. 0. 1. 1. 0. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.75\n",
      "F1-Score: 0.86\n",
      "Jaccard Index: 0.75\n",
      "AUROC: 0.88\n",
      "AUPR: 0.96\n",
      "#######################################\n",
      "25\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 1. 1. 0.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "25\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[0. 1. 1. 1. 1. 1.]\n",
      "Precision: 0.83\n",
      "Recall: 1.00\n",
      "F1-Score: 0.91\n",
      "Jaccard Index: 0.83\n",
      "AUROC: 0.50\n",
      "AUPR: 0.92\n",
      "%%%%%%\n",
      "25\n",
      "[1. 1. 1. 1. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 0.]\n",
      "Precision: 0.67\n",
      "Recall: 1.00\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.50\n",
      "AUPR: 0.83\n",
      "#######################################\n",
      "26\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.75\n",
      "AUPR: 0.90\n",
      "%%%%%%\n",
      "26\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n",
      "F1-Score: 1.00\n",
      "Jaccard Index: 1.00\n",
      "AUROC: 1.00\n",
      "AUPR: 1.00\n",
      "%%%%%%\n",
      "26\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.40\n",
      "AUPR: 0.88\n",
      "#######################################\n",
      "27\n",
      "[1. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 0. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.75\n",
      "F1-Score: 0.86\n",
      "Jaccard Index: 0.75\n",
      "AUROC: 0.88\n",
      "AUPR: 0.96\n",
      "%%%%%%\n",
      "27\n",
      "[1. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 1. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.60\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.80\n",
      "AUPR: 0.97\n",
      "%%%%%%\n",
      "27\n",
      "[1. 0. 1. 1. 0. 0.]\n",
      "[1. 0. 1. 1. 0. 1.]\n",
      "Precision: 1.00\n",
      "Recall: 0.75\n",
      "F1-Score: 0.86\n",
      "Jaccard Index: 0.75\n",
      "AUROC: 0.88\n",
      "AUPR: 0.96\n",
      "#######################################\n",
      "28\n",
      "[0. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 0.]\n",
      "Precision: 0.67\n",
      "Recall: 0.50\n",
      "F1-Score: 0.57\n",
      "Jaccard Index: 0.40\n",
      "AUROC: 0.50\n",
      "AUPR: 0.75\n",
      "%%%%%%\n",
      "28\n",
      "[0. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.67\n",
      "Recall: 0.40\n",
      "F1-Score: 0.50\n",
      "Jaccard Index: 0.33\n",
      "AUROC: 0.20\n",
      "AUPR: 0.78\n",
      "%%%%%%\n",
      "28\n",
      "[0. 0. 1. 1. 1. 0.]\n",
      "[1. 1. 1. 1. 1. 0.]\n",
      "Precision: 1.00\n",
      "Recall: 0.60\n",
      "F1-Score: 0.75\n",
      "Jaccard Index: 0.60\n",
      "AUROC: 0.80\n",
      "AUPR: 0.97\n",
      "#######################################\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 0. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 1.00\n",
      "F1-Score: 0.89\n",
      "Jaccard Index: 0.80\n",
      "AUROC: 0.75\n",
      "AUPR: 0.90\n",
      "%%%%%%\n",
      "29\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[1. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.80\n",
      "Recall: 0.80\n",
      "F1-Score: 0.80\n",
      "Jaccard Index: 0.67\n",
      "AUROC: 0.40\n",
      "AUPR: 0.88\n",
      "%%%%%%\n",
      "29\n",
      "[1. 1. 1. 0. 1. 1.]\n",
      "[0. 1. 1. 1. 0. 1.]\n",
      "Precision: 0.60\n",
      "Recall: 0.75\n",
      "F1-Score: 0.67\n",
      "Jaccard Index: 0.50\n",
      "AUROC: 0.38\n",
      "AUPR: 0.76\n",
      "#######################################\n"
     ]
    }
   ],
   "source": [
    "gt_0 = np.array(GTs[0])\n",
    "gt_1 = np.array(GTs[1])\n",
    "gt_2 = np.array(GTs[2])\n",
    "\n",
    "mean_0_f1 = []\n",
    "mean_0_recall = []\n",
    "mean_0_precision = []\n",
    "mean_0_jaccard = []\n",
    "mean_0_aupr = []\n",
    "mean_0_auroc = []\n",
    "\n",
    "mean_1_f1 = []\n",
    "mean_1_recall = []\n",
    "mean_1_precision = []\n",
    "mean_1_jaccard = []\n",
    "mean_1_aupr = []\n",
    "mean_1_auroc = []\n",
    "\n",
    "mean_2_f1 = []\n",
    "mean_2_recall = []\n",
    "mean_2_precision = []\n",
    "mean_2_jaccard = []\n",
    "mean_2_aupr = []\n",
    "mean_2_auroc = []\n",
    "\n",
    "non_zero = np.where(labels != 0)\n",
    "\n",
    "for i, out_index in enumerate(non_zero[0]):\n",
    "    \n",
    "    outlier_sample = data_n[out_index,:]\n",
    "    \n",
    "    random_numbers = [random.randint(0, 4000) for _ in range(3)]\n",
    "    inlier_samples = data_n[0:3,:]\n",
    "    \n",
    "    ga_instance, solution = run_genetic_on_sample(inlier_samples,\n",
    "                                                  outlier_sample, \n",
    "                                                  rae, \n",
    "                                                  num_dims=data_n.shape[1], \n",
    "                                                  num_generations = 100, \n",
    "                                                  mutation_probability=0.1,\n",
    "                                                  sol_per_pop=20,\n",
    "                                                  crossover_type=\"uniform\",\n",
    "                                                  l2_w = 0.01,\n",
    "                                                  outlier_w = 0.01)\n",
    "    \n",
    "    \n",
    "    #########################################################################################\n",
    "    label_0 = np.ones(data_n.shape[1])\n",
    "    index_str_0 = gt_0[i,1]\n",
    "    index_str_0 = index_str_0.strip('[]')\n",
    "    indices = index_str_0.split(',')\n",
    "    valid_indices_0 = [int(index.strip()) for index in indices]\n",
    "    label_0[valid_indices_0] =0\n",
    "#     solution = 1 - solution\n",
    "    # AUROC and AUPR calculation\n",
    "    fpr, tpr, _ = roc_curve(label_0, solution)\n",
    "    precision, recall, _ = precision_recall_curve(label_0, solution)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    aupr = auc(recall, precision)\n",
    "    # Precision calculation\n",
    "    precision = precision_score(label_0, solution)\n",
    "    # Jaccard index (Intersection over Union) calculation\n",
    "    jaccard_index = jaccard_score(label_0, solution)\n",
    "    # Recall calculation\n",
    "    recall = recall_score(label_0, solution)\n",
    "    # F1-score calculation\n",
    "    f1 = f1_score(label_0, solution)\n",
    "    # Print the results\n",
    "    mean_0_f1.append(f1)\n",
    "    mean_0_recall.append(recall)\n",
    "    mean_0_precision.append(precision)\n",
    "    mean_0_jaccard.append(jaccard_index)\n",
    "    mean_0_aupr.append(aupr)\n",
    "    mean_0_auroc.append(auroc)\n",
    "    print(i)\n",
    "    print(solution)\n",
    "    print(label_0)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    print(f\"Jaccard Index: {jaccard_index:.2f}\")\n",
    "    print(f\"AUROC: {auroc:.2f}\")\n",
    "    print(f\"AUPR: {aupr:.2f}\")\n",
    "    print(\"%%%%%%\")\n",
    "    #########################################################################################\n",
    "    label_1 = np.ones(data_n.shape[1])\n",
    "    index_str_1 = gt_1[i,1]\n",
    "    index_str_1 = index_str_1.strip('[]')\n",
    "    indices = index_str_1.split(',')\n",
    "    valid_indices_1 = [int(index.strip()) for index in indices]\n",
    "    label_1[valid_indices_1] =0\n",
    "    # AUROC and AUPR calculation\n",
    "    fpr, tpr, _ = roc_curve(label_1, solution)\n",
    "    precision, recall, _ = precision_recall_curve(label_1, solution)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    aupr = auc(recall, precision)\n",
    "    # Precision calculation\n",
    "    precision = precision_score(label_1, solution)\n",
    "    # Jaccard index (Intersection over Union) calculation\n",
    "    jaccard_index = jaccard_score(label_1, solution)\n",
    "    # Recall calculation\n",
    "    recall = recall_score(label_1, solution)\n",
    "    # F1-score calculation\n",
    "    f1 = f1_score(label_1, solution)\n",
    "    # Print the results\n",
    "    mean_1_f1.append(f1)\n",
    "    mean_1_recall.append(recall)\n",
    "    mean_1_precision.append(precision)\n",
    "    mean_1_jaccard.append(jaccard_index)\n",
    "    mean_1_aupr.append(aupr)\n",
    "    mean_1_auroc.append(auroc)\n",
    "    print(i)\n",
    "    print(solution)\n",
    "    print(label_1)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    print(f\"Jaccard Index: {jaccard_index:.2f}\")\n",
    "    print(f\"AUROC: {auroc:.2f}\")\n",
    "    print(f\"AUPR: {aupr:.2f}\")\n",
    "    print(\"%%%%%%\")\n",
    "    #########################################################################################\n",
    "    label_2 = np.ones(data_n.shape[1])\n",
    "    index_str_2 = gt_2[i,1]\n",
    "    index_str_2 = index_str_2.strip('[]')\n",
    "    indices = index_str_2.split(',')\n",
    "    valid_indices_2 = [int(index.strip()) for index in indices]\n",
    "    label_2[valid_indices_2] =0\n",
    "    # AUROC and AUPR calculation\n",
    "    fpr, tpr, _ = roc_curve(label_2, solution)\n",
    "    precision, recall, _ = precision_recall_curve(label_2, solution)\n",
    "    auroc = auc(fpr, tpr)\n",
    "    aupr = auc(recall, precision)\n",
    "    # Precision calculation\n",
    "    precision = precision_score(label_2, solution)\n",
    "    # Jaccard index (Intersection over Union) calculation\n",
    "    jaccard_index = jaccard_score(label_2, solution)\n",
    "    # Recall calculation\n",
    "    recall = recall_score(label_2, solution)\n",
    "    # F1-score calculation\n",
    "    f1 = f1_score(label_2, solution)\n",
    "    # Print the results\n",
    "    mean_2_f1.append(f1)\n",
    "    mean_2_recall.append(recall)\n",
    "    mean_2_precision.append(precision)\n",
    "    mean_2_jaccard.append(jaccard_index)\n",
    "    mean_2_aupr.append(aupr)\n",
    "    mean_2_auroc.append(auroc)\n",
    "    print(i)\n",
    "    print(solution)\n",
    "    print(label_2)\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    print(f\"Jaccard Index: {jaccard_index:.2f}\")\n",
    "    print(f\"AUROC: {auroc:.2f}\")\n",
    "    print(f\"AUPR: {aupr:.2f}\")\n",
    "    print(\"#######################################\")\n",
    "\n",
    "    \n",
    "mean_0_f1 = np.array(mean_0_f1)\n",
    "mean_0_recall = np.array(mean_0_recall)\n",
    "mean_0_precision = np.array(mean_0_precision)\n",
    "mean_0_jaccard = np.array(mean_0_jaccard)\n",
    "mean_0_aupr = np.array(mean_0_aupr)\n",
    "mean_0_auroc = np.array(mean_0_auroc)\n",
    "\n",
    "mean_1_f1 = np.array(mean_1_f1)\n",
    "mean_1_recall = np.array(mean_1_recall)\n",
    "mean_1_precision = np.array(mean_1_precision)\n",
    "mean_1_jaccard = np.array(mean_1_jaccard)\n",
    "mean_1_aupr = np.array(mean_1_aupr)\n",
    "mean_1_auroc = np.array(mean_1_auroc)\n",
    "\n",
    "mean_2_f1 = np.array(mean_2_f1)\n",
    "mean_2_recall = np.array(mean_2_recall)\n",
    "mean_2_precision = np.array(mean_2_precision)\n",
    "mean_2_jaccard = np.array(mean_2_jaccard)\n",
    "mean_2_aupr = np.array(mean_2_aupr)\n",
    "mean_2_auroc = np.array(mean_2_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8ef3397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7713588263588265\n",
      "0.81\n",
      "0.77\n",
      "0.6688888888888889\n",
      "0.862222222222222\n",
      "0.6786111111111112\n",
      "###################\n",
      "0.7665151515151517\n",
      "0.7333333333333335\n",
      "0.8555555555555556\n",
      "0.6611111111111111\n",
      "0.9194444444444443\n",
      "0.6166666666666667\n",
      "###################\n",
      "0.7178403078403081\n",
      "0.7411111111111113\n",
      "0.7472222222222222\n",
      "0.5950000000000001\n",
      "0.849722222222222\n",
      "0.5927777777777778\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(mean_0_f1))\n",
    "print(np.mean(mean_0_recall))\n",
    "print(np.mean(mean_0_precision))\n",
    "print(np.mean(mean_0_jaccard))\n",
    "print(np.mean(mean_0_aupr))\n",
    "print(np.mean(mean_0_auroc))\n",
    "print(\"###################\")\n",
    "\n",
    "print(np.mean(mean_1_f1))\n",
    "print(np.mean(mean_1_recall))\n",
    "print(np.mean(mean_1_precision))\n",
    "print(np.mean(mean_1_jaccard))\n",
    "print(np.mean(mean_1_aupr))\n",
    "print(np.mean(mean_1_auroc))\n",
    "print(\"###################\")\n",
    "\n",
    "print(np.mean(mean_2_f1))\n",
    "print(np.mean(mean_2_recall))\n",
    "print(np.mean(mean_2_precision))\n",
    "print(np.mean(mean_2_jaccard))\n",
    "print(np.mean(mean_2_aupr))\n",
    "print(np.mean(mean_2_auroc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1f8ce78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 1., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ef21dd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 0. 1. 1. 0. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "test = np.ones(data_n.shape[1])\n",
    "\n",
    "index_str = gt_0[0,1]\n",
    "\n",
    "index_str = index_str.strip('[]')\n",
    "indices = index_str.split(',')\n",
    "\n",
    "# Convert indices to integers\n",
    "valid_indices = [int(index.strip()) for index in indices]\n",
    "\n",
    "test[valid_indices] = 0\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f0e4baf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[1, 4]'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_0[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba83bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
