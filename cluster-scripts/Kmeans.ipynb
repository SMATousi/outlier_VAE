{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da0397de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genetic_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c294d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '../dataverse_files/mnist_06_combined.csv'\n",
    "data = pd.read_csv(csv_file)\n",
    "last_column = data.iloc[:, -1].values\n",
    "last_column = np.where(last_column == \"o\", 0, 1)\n",
    "tlabels = last_column\n",
    "data = np.array(data)\n",
    "data = data[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "859de5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7003, 784)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7b14b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def k_means_clustering(data, k, max_iterations=100, tolerance=1e-4):\n",
    "    # Initialize centroids randomly\n",
    "    centroids = data[np.random.choice(len(data), k, replace=False)]\n",
    "    \n",
    "    for _ in range(max_iterations):\n",
    "        # Assign each data point to the nearest centroid\n",
    "        distances = np.array([np.sum((data - centroid) ** 2, axis=1) for centroid in centroids])\n",
    "        labels = np.argmin(distances, axis=0)\n",
    "        # Update centroids\n",
    "        new_centroids = np.array([data[labels == i].mean(axis=0) for i in range(k)])\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(new_centroids - centroids) < tolerance:\n",
    "            break\n",
    "        \n",
    "        centroids = new_centroids\n",
    "    \n",
    "    return labels, centroids\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fecc3fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster labels: [1 1 1 ... 1 1 1]\n",
      "Centroids shape: (2, 784)\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate random data for testing\n",
    "    np.random.seed(42)\n",
    "#     data = np.random.rand(7003, 784)\n",
    "    \n",
    "    # Set the number of clusters (k)\n",
    "    k = 2\n",
    "    \n",
    "    # Perform K-means clustering\n",
    "    labels, centroids = k_means_clustering(data, k)\n",
    "    \n",
    "    # Print the results\n",
    "    print(\"Cluster labels:\", labels)\n",
    "    print(\"Centroids shape:\", centroids.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e752110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Percentage):\n",
      "[[0.52122266 0.47877734]\n",
      " [0.87       0.13      ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "# sklearn.metrics.confusion_matrix(lables, 1-classes, labels=None, sample_weight=None, normalize=None)\n",
    "true_labels = 1 - tlabels\n",
    "predicted_labels = 1 - labels\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Normalize the confusion matrix to get percentages\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Confusion Matrix (Percentage):\")\n",
    "print(cm_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "257d968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0039180229053646775\n",
      "Recall: 0.13\n",
      "F1 Score: 0.007606787595084846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = 1 - tlabels\n",
    "predicted_labels = 1 - labels\n",
    "\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98d56861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inliers count: 6995\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Example data generation\n",
    "# n_samples = 300\n",
    "# data, _ = make_blobs(n_samples=n_samples, centers=3, n_features=2, random_state=42)\n",
    "\n",
    "# Fit a Gaussian Mixture Model\n",
    "gmm = GaussianMixture(n_components=2)\n",
    "gmm.fit(data)\n",
    "\n",
    "# Predict probabilities\n",
    "probabilities = gmm.predict_proba(data)\n",
    "\n",
    "# Determine the maximum probability for each point\n",
    "max_probabilities = np.max(probabilities, axis=1)\n",
    "\n",
    "# Set a threshold for outliers\n",
    "threshold = 0.9999\n",
    "\n",
    "# Classify points as inliers (1) and outliers (0)\n",
    "labels = (max_probabilities > threshold).astype(int)\n",
    "\n",
    "# Print results\n",
    "print(\"Inliers count:\", np.sum(labels))\n",
    "# print(\"Outliers count:\", n_samples - np.sum(labels))\n",
    "\n",
    "true_labels = 1 - tlabels\n",
    "predicted_labels = 1 - labels\n",
    "\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2d11404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1 Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "true_labels = 1 - tlabels\n",
    "predicted_labels = 1- labels\n",
    "\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cd3998e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9944614317768027"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_probabilities.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "681f7d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "21580c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "638abd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Percentage):\n",
      "[[6895    8]\n",
      " [ 100    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "# sklearn.metrics.confusion_matrix(lables, 1-classes, labels=None, sample_weight=None, normalize=None)\n",
    "true_labels = 1 - tlabels\n",
    "predicted_labels = 1 - labels\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Normalize the confusion matrix to get percentages\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Confusion Matrix (Percentage):\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba071d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
