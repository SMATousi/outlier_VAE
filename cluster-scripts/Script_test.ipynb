{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b741f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genetic_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf4091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, lables = csv_data_loader(\"mnist-06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9d498c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7003, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1c673f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e7007c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_VAE(data,\n",
    "              latent_dim = 2,\n",
    "              hidden_layer_n = [20,18,16],\n",
    "              num_dims = 10,\n",
    "              kl_loss_factor = 0.01,\n",
    "              epochs = 100,\n",
    "              batch_size = 128\n",
    "              ):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Training the VAE on the data\n",
    "    \"\"\"\n",
    "\n",
    "    class Sampling(layers.Layer):\n",
    "        \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "        def call(self, inputs):\n",
    "            z_mean, z_log_var = inputs\n",
    "            batch = tf.shape(z_mean)[0]\n",
    "            dim = tf.shape(z_mean)[1]\n",
    "            epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "            return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    latent_dim = latent_dim\n",
    "\n",
    "    encoder_inputs = keras.Input(shape=(num_dims,))\n",
    "    x = layers.Dense(num_dims, activation=\"tanh\")(encoder_inputs)\n",
    "    x = layers.Dense(hidden_layer_n[0], activation=\"tanh\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[1], activation=\"tanh\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[2], activation=\"tanh\")(x)\n",
    "    z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "    z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "    z = Sampling()([z_mean, z_log_var])\n",
    "    encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "    latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(hidden_layer_n[2], activation=\"tanh\")(latent_inputs)\n",
    "    x = layers.Dense(hidden_layer_n[1], activation=\"tanh\")(x)\n",
    "    x = layers.Dense(hidden_layer_n[0], activation=\"tanh\")(x)\n",
    "    decoder_outputs = layers.Dense(num_dims, activation=\"linear\")(x)\n",
    "    decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "    class VAE(keras.Model):\n",
    "        def __init__(self, encoder, decoder, **kwargs):\n",
    "            super().__init__(**kwargs)\n",
    "            self.encoder = encoder\n",
    "            self.decoder = decoder\n",
    "            self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "            self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "                name=\"reconstruction_loss\"\n",
    "            )\n",
    "            self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "        @property\n",
    "        def metrics(self):\n",
    "            return [\n",
    "                self.total_loss_tracker,\n",
    "                self.reconstruction_loss_tracker,\n",
    "                self.kl_loss_tracker,\n",
    "            ]\n",
    "\n",
    "        def train_step(self, data):\n",
    "            with tf.GradientTape() as tape:\n",
    "                z_mean, z_log_var, z = self.encoder(data)\n",
    "                reconstruction = self.decoder(z)\n",
    "                reconstruction_loss = tf.keras.losses.MeanSquaredError()(data,reconstruction)\n",
    "                kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "                total_loss = reconstruction_loss + kl_loss_factor * kl_loss\n",
    "        \n",
    "            grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "            self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "            self.total_loss_tracker.update_state(total_loss)\n",
    "            self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "            self.kl_loss_tracker.update_state(kl_loss)\n",
    "            return {\n",
    "                \"loss\": self.total_loss_tracker.result(),\n",
    "                \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "                \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "            }\n",
    "    \n",
    "    creditdata = np.concatenate([data], axis=0)\n",
    "    creditdata = np.expand_dims(creditdata, -1).astype(\"float32\")\n",
    "\n",
    "    vae = VAE(encoder, decoder)\n",
    "    vae.compile(optimizer=tf.keras.optimizers.Adam())\n",
    "    history = vae.fit(creditdata,epochs=epochs,batch_size=batch_size,verbose=1)\n",
    "\n",
    "    return vae, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc4afc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 9311.9362 - reconstruction_loss: 8757.4277 - kl_loss: 43.7289\n",
      "Epoch 2/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 7294.4964 - reconstruction_loss: 6936.1016 - kl_loss: 41.8818\n",
      "Epoch 3/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 6026.2836 - reconstruction_loss: 5820.1357 - kl_loss: 28.5950\n",
      "Epoch 4/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 5250.8285 - reconstruction_loss: 5131.9893 - kl_loss: 16.2516\n",
      "Epoch 5/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4771.0007 - reconstruction_loss: 4712.3242 - kl_loss: 8.0658\n",
      "Epoch 6/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4509.0457 - reconstruction_loss: 4463.6050 - kl_loss: 5.5855\n",
      "Epoch 7/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4339.4677 - reconstruction_loss: 4321.1567 - kl_loss: 4.5457\n",
      "Epoch 8/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4257.6461 - reconstruction_loss: 4243.6548 - kl_loss: 3.6024\n",
      "Epoch 9/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4196.3226 - reconstruction_loss: 4202.6338 - kl_loss: 3.0448\n",
      "Epoch 10/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4193.0315 - reconstruction_loss: 4223.1489 - kl_loss: 6.2959\n",
      "Epoch 11/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4168.9002 - reconstruction_loss: 4172.2666 - kl_loss: 20.6452\n",
      "Epoch 12/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4175.6356 - reconstruction_loss: 4167.3066 - kl_loss: 16.3429\n",
      "Epoch 13/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4172.7395 - reconstruction_loss: 4165.9121 - kl_loss: 26.4710\n",
      "Epoch 14/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4172.7894 - reconstruction_loss: 4164.5532 - kl_loss: 25.4359\n",
      "Epoch 15/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4161.3364 - reconstruction_loss: 4164.3804 - kl_loss: 24.9084\n",
      "Epoch 16/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4169.2916 - reconstruction_loss: 4164.0425 - kl_loss: 24.5630\n",
      "Epoch 17/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4159.9198 - reconstruction_loss: 4164.4517 - kl_loss: 24.2563\n",
      "Epoch 18/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4159.7539 - reconstruction_loss: 4164.4819 - kl_loss: 24.0179\n",
      "Epoch 19/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4140.9979 - reconstruction_loss: 4163.2417 - kl_loss: 23.7674\n",
      "Epoch 20/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4144.4151 - reconstruction_loss: 4164.3359 - kl_loss: 23.4792\n",
      "Epoch 21/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4164.5953 - reconstruction_loss: 4163.8970 - kl_loss: 23.1834\n",
      "Epoch 22/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4163.9769 - reconstruction_loss: 4164.8403 - kl_loss: 22.8382\n",
      "Epoch 23/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4158.7048 - reconstruction_loss: 4163.8467 - kl_loss: 22.4212\n",
      "Epoch 24/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4180.4487 - reconstruction_loss: 4163.4873 - kl_loss: 21.8696\n",
      "Epoch 25/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4139.3023 - reconstruction_loss: 4163.6992 - kl_loss: 21.0657\n",
      "Epoch 26/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4156.8945 - reconstruction_loss: 4164.1675 - kl_loss: 20.1104\n",
      "Epoch 27/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4168.7129 - reconstruction_loss: 4163.7827 - kl_loss: 19.3269\n",
      "Epoch 28/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4153.1730 - reconstruction_loss: 4163.2607 - kl_loss: 18.7237\n",
      "Epoch 29/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4176.3235 - reconstruction_loss: 4164.6553 - kl_loss: 18.3631\n",
      "Epoch 30/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4151.5757 - reconstruction_loss: 4164.8984 - kl_loss: 18.0696\n",
      "Epoch 31/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4165.6376 - reconstruction_loss: 4164.6421 - kl_loss: 17.8116\n",
      "Epoch 32/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4159.0753 - reconstruction_loss: 4163.2520 - kl_loss: 17.5862\n",
      "Epoch 33/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4179.2471 - reconstruction_loss: 4163.2559 - kl_loss: 17.3779\n",
      "Epoch 34/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4157.3507 - reconstruction_loss: 4164.3936 - kl_loss: 17.1468\n",
      "Epoch 35/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4155.5785 - reconstruction_loss: 4164.2095 - kl_loss: 16.9407\n",
      "Epoch 36/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4149.8985 - reconstruction_loss: 4164.8208 - kl_loss: 16.7947\n",
      "Epoch 37/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4149.3818 - reconstruction_loss: 4164.9688 - kl_loss: 16.6665\n",
      "Epoch 38/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4161.3010 - reconstruction_loss: 4163.7856 - kl_loss: 16.5458\n",
      "Epoch 39/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4173.6158 - reconstruction_loss: 4164.2891 - kl_loss: 16.4271\n",
      "Epoch 40/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4162.9875 - reconstruction_loss: 4164.0903 - kl_loss: 16.2420\n",
      "Epoch 41/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4171.6068 - reconstruction_loss: 4164.9292 - kl_loss: 16.0262\n",
      "Epoch 42/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4169.5610 - reconstruction_loss: 4163.6919 - kl_loss: 15.9301\n",
      "Epoch 43/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4161.9486 - reconstruction_loss: 4164.3779 - kl_loss: 15.8331\n",
      "Epoch 44/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4179.2809 - reconstruction_loss: 4164.7852 - kl_loss: 15.7314\n",
      "Epoch 45/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4157.2524 - reconstruction_loss: 4163.0073 - kl_loss: 15.6196\n",
      "Epoch 46/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4178.7129 - reconstruction_loss: 4163.6416 - kl_loss: 15.4860\n",
      "Epoch 47/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4169.4839 - reconstruction_loss: 4164.6445 - kl_loss: 15.2743\n",
      "Epoch 48/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4169.9569 - reconstruction_loss: 4164.3271 - kl_loss: 14.6958\n",
      "Epoch 49/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4168.0313 - reconstruction_loss: 4164.0913 - kl_loss: 14.0054\n",
      "Epoch 50/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4140.0245 - reconstruction_loss: 4164.1577 - kl_loss: 13.4584\n",
      "Epoch 51/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4177.5768 - reconstruction_loss: 4163.9795 - kl_loss: 12.9859\n",
      "Epoch 52/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4163.9658 - reconstruction_loss: 4164.2749 - kl_loss: 12.7144\n",
      "Epoch 53/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4140.7153 - reconstruction_loss: 4164.7715 - kl_loss: 12.5469\n",
      "Epoch 54/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4149.9713 - reconstruction_loss: 4164.0874 - kl_loss: 12.4112\n",
      "Epoch 55/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4159.2556 - reconstruction_loss: 4164.3120 - kl_loss: 12.2809\n",
      "Epoch 56/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4151.4545 - reconstruction_loss: 4164.2456 - kl_loss: 12.1307\n",
      "Epoch 57/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4169.7147 - reconstruction_loss: 4164.9111 - kl_loss: 11.9662\n",
      "Epoch 58/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4174.2097 - reconstruction_loss: 4164.5181 - kl_loss: 11.8310\n",
      "Epoch 59/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4158.2777 - reconstruction_loss: 4164.4072 - kl_loss: 11.7191\n",
      "Epoch 60/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4175.1481 - reconstruction_loss: 4164.6777 - kl_loss: 11.5823\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 1s 10ms/step - loss: 4181.5886 - reconstruction_loss: 4164.6562 - kl_loss: 11.0057\n",
      "Epoch 62/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4164.9125 - reconstruction_loss: 4164.5786 - kl_loss: 10.5447\n",
      "Epoch 63/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4171.5131 - reconstruction_loss: 4164.5620 - kl_loss: 10.4503\n",
      "Epoch 64/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4166.4309 - reconstruction_loss: 4164.9985 - kl_loss: 10.3684\n",
      "Epoch 65/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4171.4784 - reconstruction_loss: 4163.9590 - kl_loss: 10.2888\n",
      "Epoch 66/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4169.5615 - reconstruction_loss: 4164.5288 - kl_loss: 10.1918\n",
      "Epoch 67/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4176.2942 - reconstruction_loss: 4164.0737 - kl_loss: 10.0255\n",
      "Epoch 68/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4179.8203 - reconstruction_loss: 4164.2563 - kl_loss: 9.8953\n",
      "Epoch 69/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4175.3536 - reconstruction_loss: 4165.3276 - kl_loss: 9.8069\n",
      "Epoch 70/100\n",
      "55/55 [==============================] - 1s 9ms/step - loss: 4167.3411 - reconstruction_loss: 4163.3320 - kl_loss: 9.7148\n",
      "Epoch 71/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4169.1348 - reconstruction_loss: 4164.7275 - kl_loss: 9.6145\n",
      "Epoch 72/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4164.1462 - reconstruction_loss: 4165.0986 - kl_loss: 9.4752\n",
      "Epoch 73/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4181.7975 - reconstruction_loss: 4164.6362 - kl_loss: 8.7328\n",
      "Epoch 74/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4173.5677 - reconstruction_loss: 4164.3989 - kl_loss: 8.4470\n",
      "Epoch 75/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4150.9329 - reconstruction_loss: 4164.6313 - kl_loss: 8.2658\n",
      "Epoch 76/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4160.1190 - reconstruction_loss: 4164.6343 - kl_loss: 8.0314\n",
      "Epoch 77/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4148.8013 - reconstruction_loss: 4164.9526 - kl_loss: 7.7687\n",
      "Epoch 78/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4170.5850 - reconstruction_loss: 4163.1147 - kl_loss: 7.6080\n",
      "Epoch 79/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4162.3363 - reconstruction_loss: 4165.3867 - kl_loss: 7.4661\n",
      "Epoch 80/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4164.1586 - reconstruction_loss: 4164.4932 - kl_loss: 7.3372\n",
      "Epoch 81/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4167.7275 - reconstruction_loss: 4165.3276 - kl_loss: 7.2059\n",
      "Epoch 82/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4135.9084 - reconstruction_loss: 4165.1968 - kl_loss: 7.0459\n",
      "Epoch 83/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4163.8189 - reconstruction_loss: 4165.0210 - kl_loss: 6.9586\n",
      "Epoch 84/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4164.5372 - reconstruction_loss: 4164.3711 - kl_loss: 6.5419\n",
      "Epoch 85/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4156.6036 - reconstruction_loss: 4163.1460 - kl_loss: 5.7847\n",
      "Epoch 86/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4153.6232 - reconstruction_loss: 4164.6465 - kl_loss: 6.6106\n",
      "Epoch 87/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4166.9102 - reconstruction_loss: 4163.9766 - kl_loss: 8.1814\n",
      "Epoch 88/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4174.8633 - reconstruction_loss: 4164.3765 - kl_loss: 7.7100\n",
      "Epoch 89/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4168.4403 - reconstruction_loss: 4164.6558 - kl_loss: 7.4311\n",
      "Epoch 90/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4162.2651 - reconstruction_loss: 4165.0615 - kl_loss: 7.1164\n",
      "Epoch 91/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4164.0161 - reconstruction_loss: 4164.6914 - kl_loss: 6.7743\n",
      "Epoch 92/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4161.4843 - reconstruction_loss: 4164.6807 - kl_loss: 6.2487\n",
      "Epoch 93/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4171.9995 - reconstruction_loss: 4164.9067 - kl_loss: 6.1330\n",
      "Epoch 94/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4158.7963 - reconstruction_loss: 4165.0967 - kl_loss: 6.0237\n",
      "Epoch 95/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4170.2635 - reconstruction_loss: 4163.6836 - kl_loss: 5.8160\n",
      "Epoch 96/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4148.4999 - reconstruction_loss: 4163.7275 - kl_loss: 5.5245\n",
      "Epoch 97/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4150.8755 - reconstruction_loss: 4164.9893 - kl_loss: 5.4260\n",
      "Epoch 98/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4157.5795 - reconstruction_loss: 4164.0913 - kl_loss: 5.3131\n",
      "Epoch 99/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4138.8013 - reconstruction_loss: 4164.6948 - kl_loss: 4.6665\n",
      "Epoch 100/100\n",
      "55/55 [==============================] - 1s 10ms/step - loss: 4164.6511 - reconstruction_loss: 4164.6694 - kl_loss: 4.0157\n"
     ]
    }
   ],
   "source": [
    "vae, history = train_VAE(data, num_dims=784, hidden_layer_n=[512, 256, 128] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ca318b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data[3, :].reshape([1, 784])\n",
    "\n",
    "z_mean, z_log_var, z = vae.encoder(sample.astype('float32'))\n",
    "reconstruction = vae.decoder(z)\n",
    "\n",
    "reconstruction_loss = tf.keras.losses.MeanSquaredError()(sample.astype('float32'),reconstruction)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c44934fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3634.8528"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72a4f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_detect_outliers(data,\n",
    "                        vae_model,\n",
    "                        num_dims\n",
    "                        ):\n",
    "\n",
    "    data_mean = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "            \n",
    "        sample = data[i,:].reshape([1,num_dims])\n",
    "        sample = sample.astype('float32')\n",
    "\n",
    "        z_mean, z_log_var, z = vae_model.encoder(sample)\n",
    "        reconstruction = vae_model.decoder(z)\n",
    "\n",
    "        reconstruction_loss = tf.keras.losses.MeanSquaredError()(sample,reconstruction)\n",
    "        \n",
    "        data_mean.append(reconstruction_loss)\n",
    "    \n",
    "    data_mean = np.array(data_mean)\n",
    "    i_mean = np.mean(data_mean)\n",
    "    i_std = np.std(data_mean)\n",
    "    \n",
    "\n",
    "    threshold = i_mean + 3*i_std\n",
    "\n",
    "    classes = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "            \n",
    "        sample = data[i,:].reshape([1,num_dims])\n",
    "        sample = sample.astype('float32')\n",
    "\n",
    "        z_mean, z_log_var, z = vae_model.encoder(sample)\n",
    "        reconstruction = vae_model.decoder(z)\n",
    "\n",
    "        reconstruction_loss = tf.keras.losses.MeanSquaredError()(sample,reconstruction)\n",
    "        \n",
    "        if reconstruction_loss > threshold:\n",
    "            \n",
    "            classes.append(1)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            classes.append(0)\n",
    "\n",
    "    classes = np.array(classes)\n",
    "\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "206ea131",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = vae_detect_outliers(data, vae, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "570a70c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "878392f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix (Percentage):\n",
      "[[0.99435028 0.00564972]\n",
      " [0.86       0.14      ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "# sklearn.metrics.confusion_matrix(lables, 1-classes, labels=None, sample_weight=None, normalize=None)\n",
    "true_labels = 1- lables\n",
    "predicted_labels = classes\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Normalize the confusion matrix to get percentages\n",
    "cm_percentage = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "print(\"Confusion Matrix (Percentage):\")\n",
    "print(cm_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "577e0552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6864,   39],\n",
       "       [  86,   14]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f88f3ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2641509433962264\n",
      "Recall: 0.14\n",
      "F1 Score: 0.1830065359477124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "true_labels = 1- lables\n",
    "predicted_labels = classes\n",
    "\n",
    "precision = precision_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "541c80f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-1da4059c1cbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "mat[:, 0] = mat[:, 0]/(mat[0, 0]+ mat[1, 0])\n",
    "mat[:, 1] = mat[:, 1]/(mat[0, 1]+ mat[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d8b350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26415094, 0.73584906])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22afaf0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
