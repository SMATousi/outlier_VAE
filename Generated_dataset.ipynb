{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62a5887e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 13:12:57.990336: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-17 13:12:58.054828: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-17 13:12:59.971421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-07-17 13:12:59.971475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-07-17 13:12:59.971477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 18100848624264015157\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 22564438016\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 645954799707263158\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-17 13:13:05.601549: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-17 13:13:05.651044: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-17 13:13:05.685100: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-17 13:13:05.685178: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-17 13:13:05.952932: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-17 13:13:05.953040: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-17 13:13:05.953087: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-07-17 13:13:05.953134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /device:GPU:0 with 21519 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pygad\n",
    "import wandb\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610dfebd",
   "metadata": {},
   "source": [
    "# Creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3687c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "num_dimensions = 30\n",
    "\n",
    "# Generate random samples\n",
    "raw_data = np.random.rand(num_samples, num_dimensions)\n",
    "\n",
    "outlier_indices_1 = [0,1,2,3,4,5,6]\n",
    "outlyin_amount_1 = 20\n",
    "outlier_indices_2 = [0,2,4,6,8,10,12]\n",
    "outlyin_amount_2 = 10\n",
    "outlier_indices_3 = [0,3,6,9,12,15,18]\n",
    "outlyin_amount_3 = 5\n",
    "outlier_indices_4 = [0,4,8,12,16,20,24]\n",
    "outlyin_amount_4 = 2\n",
    "outlier_indices_5 = [0,5,10,15,20,25,29]\n",
    "outlyin_amount_5 = 1.1\n",
    "outlier_indices_6 = [0,1,2,3,4,5,6]\n",
    "outlyin_amount_6 = [20,15,10,5,2,1.1,1.05]\n",
    "\n",
    "corrupted_data = raw_data\n",
    "\n",
    "corrupted_data[100:120, outlier_indices_1] = outlyin_amount_1\n",
    "corrupted_data[200:220, outlier_indices_2] = outlyin_amount_2\n",
    "corrupted_data[300:320, outlier_indices_3] = outlyin_amount_3\n",
    "corrupted_data[400:420, outlier_indices_4] = outlyin_amount_4\n",
    "corrupted_data[500:520, outlier_indices_5] = outlyin_amount_5\n",
    "corrupted_data[600:620, outlier_indices_6] = outlyin_amount_6\n",
    "\n",
    "for outlier_gene_index in range(corrupted_data.shape[1]+1):\n",
    "    corrupted_data[700+outlier_gene_index,:outlier_gene_index] = outlyin_amount_3\n",
    "    \n",
    "\n",
    "# print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44e5c977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20.        ,  0.94229997,  0.21340184,  0.29829028,  0.36824271,\n",
       "        0.92439828,  0.69054568,  0.08933888,  0.96252338,  0.28198551,\n",
       "        0.44563463,  0.98380738,  0.42611314,  0.66560582,  0.74637087,\n",
       "        0.87252321,  0.45021944,  0.09499342,  0.35756956,  0.57396956,\n",
       "        0.74110312,  0.66910544,  0.57901572,  0.32727592,  0.34571524,\n",
       "        0.78190065,  0.59662443,  0.57308834,  0.59554356,  0.75843753])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrupted_data[701]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb17a5a8",
   "metadata": {},
   "source": [
    "# Training the VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b1bd9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4740 - reconstruction_loss: 0.4416 - kl_loss: 2.4141\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.3771 - reconstruction_loss: 0.3849 - kl_loss: 2.4208\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3694 - reconstruction_loss: 0.3727 - kl_loss: 3.3855\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 0s 966us/step - loss: 0.3649 - reconstruction_loss: 0.3912 - kl_loss: 4.0123\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 0s 955us/step - loss: 0.3553 - reconstruction_loss: 0.3642 - kl_loss: 4.1471\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.3540 - reconstruction_loss: 0.3634 - kl_loss: 4.0594\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2952 - reconstruction_loss: 0.3631 - kl_loss: 3.8021\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3477 - reconstruction_loss: 0.3629 - kl_loss: 3.4265\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3480 - reconstruction_loss: 0.3628 - kl_loss: 2.9557\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3417 - reconstruction_loss: 0.3628 - kl_loss: 2.6061\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3654 - reconstruction_loss: 0.3627 - kl_loss: 2.4915\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3588 - reconstruction_loss: 0.3626 - kl_loss: 2.4081\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 0s 963us/step - loss: 0.3563 - reconstruction_loss: 0.3625 - kl_loss: 2.3653\n",
      "Epoch 14/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3510 - reconstruction_loss: 0.3625 - kl_loss: 2.3565\n",
      "Epoch 15/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3208 - reconstruction_loss: 0.3681 - kl_loss: 2.3097\n",
      "Epoch 16/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3008 - reconstruction_loss: 0.3624 - kl_loss: 2.3028\n",
      "Epoch 17/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3424 - reconstruction_loss: 0.3623 - kl_loss: 2.2927\n",
      "Epoch 18/100\n",
      "157/157 [==============================] - 1s 3ms/step - loss: 0.4294 - reconstruction_loss: 0.3624 - kl_loss: 2.2788\n",
      "Epoch 19/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3481 - reconstruction_loss: 0.3622 - kl_loss: 2.2807\n",
      "Epoch 20/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3650 - reconstruction_loss: 0.3622 - kl_loss: 2.2734\n",
      "Epoch 21/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3231 - reconstruction_loss: 0.3621 - kl_loss: 2.2414\n",
      "Epoch 22/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3612 - reconstruction_loss: 0.3686 - kl_loss: 2.2775\n",
      "Epoch 23/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3676 - reconstruction_loss: 0.3620 - kl_loss: 2.2688\n",
      "Epoch 24/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3875 - reconstruction_loss: 0.3620 - kl_loss: 2.2517\n",
      "Epoch 25/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3558 - reconstruction_loss: 0.3620 - kl_loss: 2.2462\n",
      "Epoch 26/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3643 - reconstruction_loss: 0.3620 - kl_loss: 2.2353\n",
      "Epoch 27/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3017 - reconstruction_loss: 0.3630 - kl_loss: 2.2400\n",
      "Epoch 28/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4100 - reconstruction_loss: 0.3618 - kl_loss: 2.2571\n",
      "Epoch 29/100\n",
      "157/157 [==============================] - 0s 964us/step - loss: 0.3481 - reconstruction_loss: 0.3618 - kl_loss: 2.2504\n",
      "Epoch 30/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3836 - reconstruction_loss: 0.3619 - kl_loss: 2.2694\n",
      "Epoch 31/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.4153 - reconstruction_loss: 0.3618 - kl_loss: 2.2416\n",
      "Epoch 32/100\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3811 - reconstruction_loss: 0.3617 - kl_loss: 2.2436\n",
      "Epoch 33/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3287 - reconstruction_loss: 0.3616 - kl_loss: 2.2666\n",
      "Epoch 34/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3644 - reconstruction_loss: 0.3619 - kl_loss: 2.2503\n",
      "Epoch 35/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3497 - reconstruction_loss: 0.3626 - kl_loss: 2.2732\n",
      "Epoch 36/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3477 - reconstruction_loss: 0.3615 - kl_loss: 2.2987\n",
      "Epoch 37/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2909 - reconstruction_loss: 0.3614 - kl_loss: 2.2616\n",
      "Epoch 38/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3484 - reconstruction_loss: 0.3614 - kl_loss: 2.2974\n",
      "Epoch 39/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3407 - reconstruction_loss: 0.3691 - kl_loss: 2.2972\n",
      "Epoch 40/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3807 - reconstruction_loss: 0.3613 - kl_loss: 2.3095\n",
      "Epoch 41/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3621 - reconstruction_loss: 0.3613 - kl_loss: 2.2899\n",
      "Epoch 42/100\n",
      "157/157 [==============================] - 0s 949us/step - loss: 0.3229 - reconstruction_loss: 0.3677 - kl_loss: 2.3057\n",
      "Epoch 43/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4251 - reconstruction_loss: 0.3611 - kl_loss: 2.3212\n",
      "Epoch 44/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3781 - reconstruction_loss: 0.3654 - kl_loss: 2.3446\n",
      "Epoch 45/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3538 - reconstruction_loss: 0.3610 - kl_loss: 2.3062\n",
      "Epoch 46/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3349 - reconstruction_loss: 0.3611 - kl_loss: 2.3110\n",
      "Epoch 47/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3682 - reconstruction_loss: 0.3610 - kl_loss: 2.3146\n",
      "Epoch 48/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3421 - reconstruction_loss: 0.3611 - kl_loss: 2.3097\n",
      "Epoch 49/100\n",
      "157/157 [==============================] - 0s 978us/step - loss: 0.3675 - reconstruction_loss: 0.3609 - kl_loss: 2.3322\n",
      "Epoch 50/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3793 - reconstruction_loss: 0.3609 - kl_loss: 2.3336\n",
      "Epoch 51/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4044 - reconstruction_loss: 0.3609 - kl_loss: 2.3124\n",
      "Epoch 52/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3434 - reconstruction_loss: 0.3610 - kl_loss: 2.3386\n",
      "Epoch 53/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3156 - reconstruction_loss: 0.3608 - kl_loss: 2.3140\n",
      "Epoch 54/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3397 - reconstruction_loss: 0.3608 - kl_loss: 2.3080\n",
      "Epoch 55/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3481 - reconstruction_loss: 0.3608 - kl_loss: 2.3330\n",
      "Epoch 56/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3369 - reconstruction_loss: 0.3608 - kl_loss: 2.3498\n",
      "Epoch 57/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3177 - reconstruction_loss: 0.3607 - kl_loss: 2.3657\n",
      "Epoch 58/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.4076 - reconstruction_loss: 0.3607 - kl_loss: 2.3597\n",
      "Epoch 59/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3503 - reconstruction_loss: 0.3606 - kl_loss: 2.3513\n",
      "Epoch 60/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3173 - reconstruction_loss: 0.3606 - kl_loss: 2.3538\n",
      "Epoch 61/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3549 - reconstruction_loss: 0.3606 - kl_loss: 2.3789\n",
      "Epoch 62/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3371 - reconstruction_loss: 0.3605 - kl_loss: 2.3813\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3555 - reconstruction_loss: 0.3604 - kl_loss: 2.3917\n",
      "Epoch 64/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3072 - reconstruction_loss: 0.3604 - kl_loss: 2.3911\n",
      "Epoch 65/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4284 - reconstruction_loss: 0.3615 - kl_loss: 2.4103\n",
      "Epoch 66/100\n",
      "157/157 [==============================] - 0s 930us/step - loss: 0.3861 - reconstruction_loss: 0.3604 - kl_loss: 2.4193\n",
      "Epoch 67/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3717 - reconstruction_loss: 0.3604 - kl_loss: 2.4368\n",
      "Epoch 68/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3506 - reconstruction_loss: 0.3668 - kl_loss: 2.4478\n",
      "Epoch 69/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3807 - reconstruction_loss: 0.3602 - kl_loss: 2.4720\n",
      "Epoch 70/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3933 - reconstruction_loss: 0.3601 - kl_loss: 2.4975\n",
      "Epoch 71/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3845 - reconstruction_loss: 0.3600 - kl_loss: 2.4940\n",
      "Epoch 72/100\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3540 - reconstruction_loss: 0.3601 - kl_loss: 2.4960\n",
      "Epoch 73/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3989 - reconstruction_loss: 0.3601 - kl_loss: 2.5271\n",
      "Epoch 74/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3459 - reconstruction_loss: 0.3599 - kl_loss: 2.5208\n",
      "Epoch 75/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3479 - reconstruction_loss: 0.3599 - kl_loss: 2.5386\n",
      "Epoch 76/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4031 - reconstruction_loss: 0.3599 - kl_loss: 2.5521\n",
      "Epoch 77/100\n",
      "157/157 [==============================] - 0s 940us/step - loss: 0.3637 - reconstruction_loss: 0.3598 - kl_loss: 2.5431\n",
      "Epoch 78/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3605 - reconstruction_loss: 0.3598 - kl_loss: 2.6076\n",
      "Epoch 79/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3623 - reconstruction_loss: 0.3597 - kl_loss: 2.6151\n",
      "Epoch 80/100\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.3782 - reconstruction_loss: 0.3598 - kl_loss: 2.6066\n",
      "Epoch 81/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4064 - reconstruction_loss: 0.3597 - kl_loss: 2.6112\n",
      "Epoch 82/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3125 - reconstruction_loss: 0.3596 - kl_loss: 2.6365\n",
      "Epoch 83/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3436 - reconstruction_loss: 0.3653 - kl_loss: 2.6273\n",
      "Epoch 84/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3581 - reconstruction_loss: 0.3595 - kl_loss: 2.6818\n",
      "Epoch 85/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.2726 - reconstruction_loss: 0.3595 - kl_loss: 2.6525\n",
      "Epoch 86/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3449 - reconstruction_loss: 0.3595 - kl_loss: 2.6678\n",
      "Epoch 87/100\n",
      "157/157 [==============================] - 1s 5ms/step - loss: 0.3755 - reconstruction_loss: 0.3651 - kl_loss: 2.6886\n",
      "Epoch 88/100\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3708 - reconstruction_loss: 0.3594 - kl_loss: 2.6900\n",
      "Epoch 89/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.3508 - reconstruction_loss: 0.3594 - kl_loss: 2.6971\n",
      "Epoch 90/100\n",
      "157/157 [==============================] - 0s 963us/step - loss: 0.3588 - reconstruction_loss: 0.3593 - kl_loss: 2.7213\n",
      "Epoch 91/100\n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.3545 - reconstruction_loss: 0.3593 - kl_loss: 2.7153\n",
      "Epoch 92/100\n",
      "157/157 [==============================] - 0s 1ms/step - loss: 0.4080 - reconstruction_loss: 0.3597 - kl_loss: 2.7368\n",
      "Epoch 93/100\n",
      " 81/157 [==============>...............] - ETA: 0s - loss: 0.3374 - reconstruction_loss: 0.3288 - kl_loss: 2.7717"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_85607/2997793900.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m \u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreditdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m    134\u001b[0m     return concrete_function._call_flat(\n\u001b[0;32m--> 135\u001b[0;31m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    381\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.conda/envs/mac-deep/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 53\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(30,))\n",
    "# x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "# x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# x = layers.Flatten()(x)\n",
    "x = layers.Dense(30, activation=\"tanh\")(encoder_inputs)\n",
    "x = layers.Dense(20, activation=\"tanh\")(x)\n",
    "x = layers.Dense(18, activation=\"tanh\")(x)\n",
    "x = layers.Dense(16, activation=\"tanh\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "# x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "# x = layers.Reshape((7, 7, 64))(x)\n",
    "# x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "x = layers.Dense(16, activation=\"tanh\")(latent_inputs)\n",
    "x = layers.Dense(18, activation=\"tanh\")(x)\n",
    "x = layers.Dense(20, activation=\"tanh\")(x)\n",
    "decoder_outputs = layers.Dense(30, activation=\"tanh\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n",
    "\n",
    "\n",
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "#             reconstruction_loss = tf.reduce_mean(\n",
    "#                 tf.reduce_sum(\n",
    "#                     keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "#                 )\n",
    "#             )\n",
    "            reconstruction_loss = tf.keras.losses.MeanSquaredError()(data,reconstruction)\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + 0.001*kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n",
    "\n",
    "creditdata = np.concatenate([corrupted_data], axis=0)\n",
    "creditdata = np.expand_dims(creditdata, -1).astype(\"float32\")\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=tf.keras.optimizers.legacy.Adam())\n",
    "vae.fit(creditdata, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5e68be",
   "metadata": {},
   "source": [
    "The error calculation for setting the threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dae1ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inliers = corrupted_data[5:80,:]\n",
    "mean_data = np.mean(corrupted_data, axis=0)\n",
    "outlier1 = corrupted_data[101,:]\n",
    "\n",
    "\n",
    "\n",
    "# #------------------ replacing the genes here ---------------------\n",
    "\n",
    "# inliers[:,1] = mean_data[1]\n",
    "\n",
    "# outlier1[1] = mean_data[1]\n",
    "\n",
    "# # ----------------------------------------------------------------\n",
    "\n",
    "ouliers_mean_error = []\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    mean_mean = []\n",
    "    \n",
    "    for step in range(10):\n",
    "        \n",
    "        outlier1 = corrupted_data[100 + i,:]\n",
    "        \n",
    "        outlier1[10] = mean_data[10]\n",
    "\n",
    "        outlier1 = outlier1.reshape([1,30])\n",
    "\n",
    "        z_mean, z_log_var, z = vae.encoder(outlier1)\n",
    "        reconstruction = vae.decoder(z)\n",
    "\n",
    "        reconstruction_loss = tf.keras.losses.MeanSquaredError()(outlier1,reconstruction)\n",
    "\n",
    "#         print(reconstruction_loss.numpy())\n",
    "\n",
    "        mean_mean.append(reconstruction_loss.numpy())\n",
    "\n",
    "#     print(\"MEAN_MEAN = \", i, np.mean(np.array(mean_mean)))\n",
    "#     print(\"std_MEAN = \", i, np.std(np.array(mean_mean)))\n",
    "    \n",
    "    ouliers_mean_error.append(np.mean(np.array(mean_mean)))\n",
    "\n",
    "print(ouliers_mean_error)\n",
    "print(np.mean(np.array(ouliers_mean_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa89ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mean = []\n",
    "\n",
    "for step in range(10):\n",
    "\n",
    "    mean_ins_error = []\n",
    "\n",
    "    for index in range(inliers.shape[0]):\n",
    "\n",
    "        cand = inliers[index,:]\n",
    "\n",
    "        cand = cand.reshape([1,30])\n",
    "\n",
    "        mean_data = mean_data.reshape([1,30])\n",
    "\n",
    "        z_mean, z_log_var, z = vae.encoder(cand)\n",
    "        reconstruction = vae.decoder(z)\n",
    "\n",
    "        reconstruction_loss = tf.keras.losses.MeanSquaredError()(cand,reconstruction)\n",
    "\n",
    "        mean_ins_error.append(reconstruction_loss.numpy())\n",
    "\n",
    "    #     print(\"MEAN\", index, \" = \", reconstruction_loss.numpy())\n",
    "\n",
    "    mean_ins_error = np.array(mean_ins_error)\n",
    "    print(\"mean = \", np.mean(mean_ins_error))\n",
    "    \n",
    "    mean_mean.append(np.mean(mean_ins_error))\n",
    "    \n",
    "\n",
    "print(\"MEAN_MEAN = \", np.mean(np.array(mean_mean)))\n",
    "print(\"std_MEAN = \", np.std(np.array(mean_mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6caf27",
   "metadata": {},
   "source": [
    "Setting the threshold and trying to detect the outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226b7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item_no in range(corrupted_data.shape[0]):\n",
    "    \n",
    "    candidate_sample = corrupted_data[item_no,:]\n",
    "    candidate_sample = candidate_sample.reshape([1,30])\n",
    "    \n",
    "    z_mean, z_log_var, z = vae.encoder(candidate_sample)\n",
    "    reconstruction = vae.decoder(z)\n",
    "\n",
    "    reconstruction_loss = tf.keras.losses.MeanSquaredError()(candidate_sample,reconstruction)\n",
    "    \n",
    "    if reconstruction_loss.numpy() > 1:\n",
    "        \n",
    "        print(\"An Outlier Detected on sample No. \", item_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e52049",
   "metadata": {},
   "source": [
    "# Genetic Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func_avg(ga_instance, solution, solution_idx):\n",
    "    \n",
    "    inliers = corrupted_data[10:13,:]\n",
    "    \n",
    "    avg_ins = np.mean(inliers, axis=0)\n",
    "    avg_ins = avg_ins.reshape([1,30])\n",
    "    \n",
    "    particle = corrupted_data[701,:]\n",
    "    particle = particle.reshape([1,30])\n",
    "    \n",
    "#     abn_subspace = solution * val_features[6728,:]\n",
    "    \n",
    "#     abn_subspace = abn_subspace.reshape([1,30])\n",
    "\n",
    "    avg_in_rec = []\n",
    "    \n",
    "    for index in range(inliers.shape[0]):\n",
    "        \n",
    "        candidate_inlier = inliers[index,:]\n",
    "        candidate_inlier = candidate_inlier.reshape([1,30])\n",
    "        \n",
    "        in_remain = candidate_inlier * solution\n",
    "        \n",
    "        in_normal_subspace = 1 - solution\n",
    "        \n",
    "        in_replace = in_normal_subspace * avg_ins\n",
    "        \n",
    "        in_candidate = in_remain + in_replace\n",
    "        \n",
    "        z_mean, z_log_var, z = vae.encoder(in_candidate)\n",
    "        in_candidate_rec = vae.decoder(z)\n",
    "        \n",
    "        \n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "        \n",
    "        avg_in_rec.append(rec_loss.numpy())\n",
    "    \n",
    "    avg_in_rec = np.array(avg_in_rec)\n",
    "    avg_in_rec = np.mean(avg_in_rec)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "#     z_mean, z_log_var, z = vae.encoder(particle)\n",
    "#     reconstruction_1 = vae.decoder(z)\n",
    "    \n",
    "    out_remain = particle * solution\n",
    "    \n",
    "    out_normal_subspace = 1 - solution\n",
    "    \n",
    "    out_replace = avg_ins * out_normal_subspace\n",
    "    \n",
    "    out_candidate = out_remain + out_replace\n",
    "    \n",
    "    \n",
    "    z_mean, z_log_var, z = vae.encoder(out_candidate)\n",
    "    out_candidate_rec = vae.decoder(z)\n",
    "    \n",
    "    rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "    rec_loss = rec_loss.numpy()\n",
    "    \n",
    "    fitness = rec_loss / avg_in_rec\n",
    "    \n",
    "    return fitness\n",
    "\n",
    "\n",
    "def fitness_func_avg_with_penalty(ga_instance, solution, solution_idx):\n",
    "    \n",
    "    inliers = corrupted_data[10:13,:]\n",
    "    \n",
    "    avg_ins = np.mean(inliers, axis=0)\n",
    "    avg_ins = avg_ins.reshape([1,30])\n",
    "    \n",
    "    particle = corrupted_data[201,:]\n",
    "    particle = particle.reshape([1,30])\n",
    "    \n",
    "#     abn_subspace = solution * val_features[6728,:]\n",
    "    \n",
    "#     abn_subspace = abn_subspace.reshape([1,30])\n",
    "\n",
    "    avg_in_rec = []\n",
    "    \n",
    "    for index in range(inliers.shape[0]):\n",
    "        \n",
    "        candidate_inlier = inliers[index,:]\n",
    "        candidate_inlier = candidate_inlier.reshape([1,30])\n",
    "        \n",
    "        in_remain = candidate_inlier * solution\n",
    "        \n",
    "        in_normal_subspace = 1 - solution\n",
    "        \n",
    "        in_replace = in_normal_subspace * avg_ins\n",
    "        \n",
    "        in_candidate = in_remain + in_replace\n",
    "        \n",
    "        z_mean, z_log_var, z = vae.encoder(in_candidate)\n",
    "        in_candidate_rec = vae.decoder(z)\n",
    "        \n",
    "        \n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "        \n",
    "        avg_in_rec.append(rec_loss.numpy())\n",
    "    \n",
    "    avg_in_rec = np.array(avg_in_rec)\n",
    "    avg_in_rec = np.mean(avg_in_rec)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "#     z_mean, z_log_var, z = vae.encoder(particle)\n",
    "#     reconstruction_1 = vae.decoder(z)\n",
    "    \n",
    "    out_remain = particle * solution\n",
    "    \n",
    "    out_normal_subspace = 1 - solution\n",
    "    \n",
    "    out_replace = avg_ins * out_normal_subspace\n",
    "    \n",
    "    out_candidate = out_remain + out_replace\n",
    "    \n",
    "    \n",
    "    z_mean, z_log_var, z = vae.encoder(out_candidate)\n",
    "    out_candidate_rec = vae.decoder(z)\n",
    "    \n",
    "    rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "    rec_loss = rec_loss.numpy()\n",
    "    \n",
    "    fitness = rec_loss / avg_in_rec\n",
    "    \n",
    "    # adding the penalty here!\n",
    "    \n",
    "    num_ones = np.count_nonzero(solution == 1)\n",
    "    \n",
    "    penalty_rate = 1.0/corrupted_data.shape[1]\n",
    "    \n",
    "    fitness = fitness - num_ones * penalty_rate * fitness\n",
    "    \n",
    "    return fitness\n",
    "\n",
    "def on_generation(ga):\n",
    "    print(\"Generation\", ga.generations_completed)\n",
    "    \n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    \n",
    "    print(solution_fitness)\n",
    "\n",
    "\n",
    "fitness_function = fitness_func_avg_with_penalty\n",
    "\n",
    "num_generations = 20\n",
    "num_parents_mating = 4\n",
    "\n",
    "sol_per_pop = 100\n",
    "num_genes = corrupted_data.shape[1]\n",
    "\n",
    "init_range_low = -2\n",
    "init_range_high = 5\n",
    "\n",
    "parent_selection_type = \"sss\"\n",
    "keep_parents = 1\n",
    "\n",
    "space = [[0,1] for i in range(num_genes)]\n",
    "\n",
    "crossover_type = \"single_point\"\n",
    "\n",
    "mutation_type = \"random\"\n",
    "mutation_percent_genes = 10\n",
    "\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_parents=keep_parents,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_percent_genes=mutation_percent_genes,\n",
    "                       on_generation=on_generation,\n",
    "                       gene_space = space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f03a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ga_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec762d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62372427",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance.plot_fitness()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f89ac",
   "metadata": {},
   "source": [
    "# For loop for Genetic Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85d2e125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:g6dnliu8) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>GA - 1/solution_fitness</td><td>▁▅▅▅▅▆▆▆▆▆▇▆▆█▇█████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GA - 1/solution_fitness</td><td>18.67299</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">classic-meadow-2</strong> at: <a href='https://wandb.ai/tousi-team/VAE_Outlier_GA_Without_Penalty_1/runs/g6dnliu8' target=\"_blank\">https://wandb.ai/tousi-team/VAE_Outlier_GA_Without_Penalty_1/runs/g6dnliu8</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230628_170134-g6dnliu8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:g6dnliu8). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad5cbc5d69747b583703d2b502799b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01667172440017263, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/macula/SMATousi/VAE_outlier/outlier_VAE/wandb/run-20230629_104134-7fbms0mp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tousi-team/VAE_Outlier_GA_Without_Penalty_1/runs/7fbms0mp' target=\"_blank\">fearless-planet-3</a></strong> to <a href='https://wandb.ai/tousi-team/VAE_Outlier_GA_Without_Penalty_1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tousi-team/VAE_Outlier_GA_Without_Penalty_1' target=\"_blank\">https://wandb.ai/tousi-team/VAE_Outlier_GA_Without_Penalty_1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tousi-team/VAE_Outlier_GA_Without_Penalty_1/runs/7fbms0mp' target=\"_blank\">https://wandb.ai/tousi-team/VAE_Outlier_GA_Without_Penalty_1/runs/7fbms0mp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1\n",
      "17.085009\n",
      "Generation 2\n",
      "19.350494\n",
      "Generation 3\n",
      "19.249483\n",
      "Generation 4\n",
      "19.24446\n",
      "Generation 5\n",
      "19.30465\n",
      "Generation 6\n",
      "19.664877\n",
      "Generation 7\n",
      "19.76774\n",
      "Generation 8\n",
      "19.82989\n",
      "Generation 9\n",
      "19.82989\n",
      "Generation 10\n",
      "19.82989\n",
      "Generation 11\n",
      "19.97928\n",
      "Generation 12\n",
      "20.00483\n",
      "Generation 13\n",
      "20.059074\n",
      "Generation 14\n",
      "20.205612\n",
      "Generation 15\n",
      "20.205612\n",
      "Generation 16\n",
      "20.205612\n",
      "Generation 17\n",
      "20.205612\n",
      "Generation 18\n",
      "20.205612\n",
      "Generation 19\n",
      "20.205612\n",
      "Generation 20\n",
      "20.205612\n",
      "Generation 21\n",
      "20.205612\n",
      "Generation 22\n",
      "20.205612\n",
      "Generation 23\n",
      "20.205612\n",
      "Generation 24\n",
      "20.205612\n",
      "Generation 25\n",
      "20.205612\n",
      "Generation 26\n",
      "20.205612\n",
      "Generation 27\n",
      "20.205612\n",
      "Generation 28\n",
      "20.205612\n",
      "Generation 29\n",
      "20.42573\n",
      "Generation 30\n",
      "20.439665\n",
      "Generation 31\n",
      "20.380795\n",
      "Generation 32\n",
      "20.380795\n",
      "Generation 33\n",
      "20.380795\n",
      "Generation 34\n",
      "20.380795\n",
      "Generation 35\n",
      "20.380795\n",
      "Generation 36\n",
      "20.380795\n",
      "Generation 37\n",
      "20.510656\n",
      "Generation 38\n",
      "20.710499\n",
      "Generation 39\n",
      "20.710499\n",
      "Generation 40\n",
      "20.710499\n",
      "##########  End of the  1  epoch ##########\n",
      "Parameters of the best solution : [1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1.]\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3054515/283569517.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTP\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTP\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mFN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0mF1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "best_solutions = []\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"VAE_Outlier_GA_Without_Penalty_1\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "#     \"epochs\": 20,\n",
    "#     }\n",
    ")\n",
    "\n",
    "for out_indexing in range(1,corrupted_data.shape[1]+1):\n",
    "    \n",
    "    def fitness_func_avg(ga_instance, solution, solution_idx):\n",
    "\n",
    "        inliers = corrupted_data[10:13,:]\n",
    "\n",
    "        avg_ins = np.mean(inliers, axis=0)\n",
    "        avg_ins = avg_ins.reshape([1,30])\n",
    "\n",
    "        particle = corrupted_data[700+out_indexing,:]\n",
    "        particle = particle.reshape([1,30])\n",
    "\n",
    "    #     abn_subspace = solution * val_features[6728,:]\n",
    "\n",
    "    #     abn_subspace = abn_subspace.reshape([1,30])\n",
    "\n",
    "        avg_in_rec = []\n",
    "\n",
    "        for index in range(inliers.shape[0]):\n",
    "\n",
    "            candidate_inlier = inliers[index,:]\n",
    "            candidate_inlier = candidate_inlier.reshape([1,30])\n",
    "\n",
    "            in_remain = candidate_inlier * solution\n",
    "\n",
    "            in_normal_subspace = 1 - solution\n",
    "\n",
    "            in_replace = in_normal_subspace * avg_ins\n",
    "\n",
    "            in_candidate = in_remain + in_replace\n",
    "\n",
    "            z_mean, z_log_var, z = vae.encoder(in_candidate)\n",
    "            in_candidate_rec = vae.decoder(z)\n",
    "\n",
    "\n",
    "            rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "\n",
    "            avg_in_rec.append(rec_loss.numpy())\n",
    "\n",
    "        avg_in_rec = np.array(avg_in_rec)\n",
    "        avg_in_rec = np.mean(avg_in_rec)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     z_mean, z_log_var, z = vae.encoder(particle)\n",
    "    #     reconstruction_1 = vae.decoder(z)\n",
    "\n",
    "        out_remain = particle * solution\n",
    "\n",
    "        out_normal_subspace = 1 - solution\n",
    "\n",
    "        out_replace = avg_ins * out_normal_subspace\n",
    "\n",
    "        out_candidate = out_remain + out_replace\n",
    "\n",
    "\n",
    "        z_mean, z_log_var, z = vae.encoder(out_candidate)\n",
    "        out_candidate_rec = vae.decoder(z)\n",
    "\n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "        rec_loss = rec_loss.numpy()\n",
    "\n",
    "        fitness = rec_loss / avg_in_rec\n",
    "\n",
    "        return fitness\n",
    "    \n",
    "    def fitness_func_avg_with_penalty(ga_instance, solution, solution_idx):\n",
    "    \n",
    "        inliers = corrupted_data[10:13,:]\n",
    "\n",
    "        avg_ins = np.mean(inliers, axis=0)\n",
    "        avg_ins = avg_ins.reshape([1,30])\n",
    "\n",
    "        particle = corrupted_data[700+out_indexing,:]\n",
    "        particle = particle.reshape([1,30])\n",
    "\n",
    "    #     abn_subspace = solution * val_features[6728,:]\n",
    "\n",
    "    #     abn_subspace = abn_subspace.reshape([1,30])\n",
    "\n",
    "        avg_in_rec = []\n",
    "\n",
    "        for index in range(inliers.shape[0]):\n",
    "\n",
    "            candidate_inlier = inliers[index,:]\n",
    "            candidate_inlier = candidate_inlier.reshape([1,30])\n",
    "\n",
    "            in_remain = candidate_inlier * solution\n",
    "\n",
    "            in_normal_subspace = 1 - solution\n",
    "\n",
    "            in_replace = in_normal_subspace * avg_ins\n",
    "\n",
    "            in_candidate = in_remain + in_replace\n",
    "\n",
    "            z_mean, z_log_var, z = vae.encoder(in_candidate)\n",
    "            in_candidate_rec = vae.decoder(z)\n",
    "\n",
    "\n",
    "            rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "\n",
    "            avg_in_rec.append(rec_loss.numpy())\n",
    "\n",
    "        avg_in_rec = np.array(avg_in_rec)\n",
    "        avg_in_rec = np.mean(avg_in_rec)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #     z_mean, z_log_var, z = vae.encoder(particle)\n",
    "    #     reconstruction_1 = vae.decoder(z)\n",
    "\n",
    "        out_remain = particle * solution\n",
    "\n",
    "        out_normal_subspace = 1 - solution\n",
    "\n",
    "        out_replace = avg_ins * out_normal_subspace\n",
    "\n",
    "        out_candidate = out_remain + out_replace\n",
    "\n",
    "\n",
    "        z_mean, z_log_var, z = vae.encoder(out_candidate)\n",
    "        out_candidate_rec = vae.decoder(z)\n",
    "\n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "        rec_loss = rec_loss.numpy()\n",
    "\n",
    "        # adding the penalty here!\n",
    "\n",
    "        num_ones = np.count_nonzero(solution == 1)\n",
    "\n",
    "        penalty_rate = 1.0 / corrupted_data.shape[1]\n",
    "        \n",
    "        regul_param = 10\n",
    "        \n",
    "        penalty_rate = penalty_rate / regul_param\n",
    "        \n",
    "        fitness = rec_loss / (avg_in_rec + (num_ones * penalty_rate * avg_in_rec))\n",
    "\n",
    "#         fitness = fitness - num_ones * penalty_rate * fitness\n",
    "\n",
    "        return fitness\n",
    "\n",
    "    def on_generation(ga):\n",
    "        print(\"Generation\", ga.generations_completed)\n",
    "\n",
    "        solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "        \n",
    "        wandb.log({\"GA - \" + str(out_indexing) + \"/solution_fitness\": solution_fitness})\n",
    "\n",
    "        print(solution_fitness)\n",
    "\n",
    "\n",
    "    fitness_function = fitness_func_avg\n",
    "\n",
    "    num_generations = 40\n",
    "    num_parents_mating = 4\n",
    "\n",
    "    sol_per_pop = 100\n",
    "    num_genes = corrupted_data.shape[1]\n",
    "\n",
    "    init_range_low = -2\n",
    "    init_range_high = 5\n",
    "\n",
    "    parent_selection_type = \"sss\"\n",
    "    keep_parents = 1\n",
    "\n",
    "    space = [[0,1] for i in range(num_genes)]\n",
    "\n",
    "    crossover_type = \"single_point\"\n",
    "\n",
    "    mutation_type = \"random\"\n",
    "    mutation_percent_genes = 15\n",
    "\n",
    "    ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                           num_parents_mating=num_parents_mating,\n",
    "                           fitness_func=fitness_function,\n",
    "                           sol_per_pop=sol_per_pop,\n",
    "                           num_genes=num_genes,\n",
    "                           init_range_low=init_range_low,\n",
    "                           init_range_high=init_range_high,\n",
    "                           parent_selection_type=parent_selection_type,\n",
    "#                            keep_parents=keep_parents,\n",
    "                           keep_elitism=2,\n",
    "                           crossover_type=crossover_type,\n",
    "                           mutation_type=mutation_type,\n",
    "                           mutation_percent_genes=mutation_percent_genes,\n",
    "                           on_generation=on_generation,\n",
    "                           gene_space = space)\n",
    "\n",
    "    ga_instance.run()\n",
    "\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    print(\"##########  End of the \", out_indexing, \" epoch ##########\")\n",
    "    print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "\n",
    "    best_solutions.append(solution)\n",
    "    \n",
    "    sample = corrupted_data[700+out_indexing,:]\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    for gene_no in range(30):\n",
    "        \n",
    "        if ((sample[gene_no] == 20) and (solution[gene_no] == 1)):\n",
    "            \n",
    "            TP = TP + 1\n",
    "        \n",
    "        elif (sample[gene_no] != 20) and (solution[gene_no] == 1):\n",
    "            \n",
    "            FP = FP + 1\n",
    "            \n",
    "        elif (sample[gene_no] != 20) and (solution[gene_no] == 0):\n",
    "            \n",
    "            TN = TN + 1\n",
    "            \n",
    "        elif (sample[gene_no] == 20) and (solution[gene_no] == 0):\n",
    "            \n",
    "            FN = FN + 1\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    F1 = 2 * (precision * recall)/(precision + recall)\n",
    "    \n",
    "    MCC = (TP * TN - FP * FN) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    \n",
    "    wandb.log({\"Metrics/precision\": precision, \n",
    "               \"Metrics/recall\": recall,\n",
    "               \"Metrics/F1\": F1,\n",
    "               \"Metrics/MCC\": MCC,\n",
    "               \"Metrics/num\": out_indexing})\n",
    "    \n",
    "best_solutions = np.array(best_solutions)\n",
    "np.save('best_solutions.npy', best_solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc3c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_data[700+0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09600b11",
   "metadata": {},
   "source": [
    "# Measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c7303",
   "metadata": {},
   "source": [
    "F1 calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccf80f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP = 3\n",
    "FP = 1\n",
    "TN = 22\n",
    "FN = 4\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "F1 = 2 * (precision * recall)/(precision + recall)\n",
    "\n",
    "MCC = (TP * TN - FP * FN) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "\n",
    "print(\"Precision = \", precision)\n",
    "print(\"recall = \", recall)\n",
    "print(\"F1 = \", F1)\n",
    "print(\"MCC = \", MCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c57685",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(corrupted_data.shape[1]):\n",
    "    print(\"^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\")\n",
    "    print(best_solutions[index,:])\n",
    "    print(corrupted_data[700+index,:])\n",
    "    print(\"######################################3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da3a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_data[701,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e595e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "precs = []\n",
    "recalls = []\n",
    "F1s = []\n",
    "mccs = []\n",
    "\n",
    "\n",
    "for sample_no in range(1,corrupted_data.shape[1]):\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    \n",
    "    sample = corrupted_data[700+sample_no,:]\n",
    "    sol = best_solutions[sample_no,:]\n",
    "    \n",
    "    for gene_no in range(30):\n",
    "        \n",
    "        if ((sample[gene_no] == 20) and (sol[gene_no] == 1)):\n",
    "            \n",
    "            TP = TP + 1\n",
    "        \n",
    "        elif (sample[gene_no] != 20) and (sol[gene_no] == 1):\n",
    "            \n",
    "            FP = FP + 1\n",
    "            \n",
    "        elif (sample[gene_no] != 20) and (sol[gene_no] == 0):\n",
    "            \n",
    "            TN = TN + 1\n",
    "            \n",
    "        elif (sample[gene_no] == 20) and (sol[gene_no] == 0):\n",
    "            \n",
    "            FN = FN + 1\n",
    "    \n",
    "    \n",
    "\n",
    "    precision = TP / (TP + FP)\n",
    "\n",
    "    recall = TP / (TP + FN)\n",
    "\n",
    "    F1 = 2 * (precision * recall)/(precision + recall)\n",
    "    \n",
    "    MCC = (TP * TN - FP * FN) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "\n",
    "    print(\"###################################################3\")\n",
    "    print(sol)\n",
    "    print(sample)\n",
    "    print(\"Numbers = \", TP, FP, TN, FN)\n",
    "    print(\"Precision = \", precision)\n",
    "    print(\"recall = \", recall)\n",
    "    print(\"F1 = \", F1)\n",
    "    print(\"MCC = \", MCC)\n",
    "    \n",
    "    precs.append(precision)\n",
    "    recalls.append(recall)\n",
    "    F1s.append(F1)\n",
    "    mccs.append(MCC)\n",
    "\n",
    "\n",
    "precs = np.array(precs)\n",
    "recalls = np.array(recalls)\n",
    "F1s = np.array(F1s)\n",
    "mccs = np.array(mccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9147a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6817ca60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# precs = np.array(precs)\n",
    "# recalls = np.array(recalls)\n",
    "# F1s = np.array(F1s)\n",
    "# mccs = np.array(mccs)\n",
    "\n",
    "plt.title(\"Matthews correlation coefficient (MCC)\")\n",
    "plt.plot(mccs)\n",
    "plt.xlabel(\"Number of outlying genes\")\n",
    "plt.savefig(\"MCC.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925ca5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Precision\")\n",
    "plt.plot(precs)\n",
    "plt.xlabel(\"Number of outlying genes\")\n",
    "plt.savefig(\"Precision.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Recall\")\n",
    "plt.plot(recalls)\n",
    "plt.xlabel(\"Number of outlying genes\")\n",
    "plt.savefig(\"Recall.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127d3ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"F1\")\n",
    "plt.plot(F1s)\n",
    "plt.xlabel(\"Number of outlying genes\")\n",
    "plt.savefig(\"F1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8019fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
