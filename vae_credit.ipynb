{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e91d009a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 12:53:08.683626: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 12:53:08.798266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-05-30 12:53:08.798288: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-30 12:53:09.378152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-05-30 12:53:09.378222: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-05-30 12:53:09.378230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51199e21",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3759355595580470294\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 12:53:13.472609: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-30 12:53:13.608382: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 12:53:13.608936: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-05-30 12:53:13.609050: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-05-30 12:53:13.609142: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-05-30 12:53:13.609230: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-05-30 12:53:13.609318: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-05-30 12:53:13.609405: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-05-30 12:53:13.609492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-05-30 12:53:13.609647: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "651470eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3516357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 10:33:57.707973: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 28, 28, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 14, 14, 32)   320         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 7, 7, 64)     18496       ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 3136)         0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           50192       ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " z_mean (Dense)                 (None, 2)            34          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " z_log_var (Dense)              (None, 2)            34          ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " sampling (Sampling)            (None, 2)            0           ['z_mean[0][0]',                 \n",
      "                                                                  'z_log_var[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 69,076\n",
      "Trainable params: 69,076\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "encoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0eb6afd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2)]               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3136)              9408      \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 14, 14, 64)       36928     \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 28, 28, 32)       18464     \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 28, 28, 1)        289       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,089\n",
      "Trainable params: 65,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 64))(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37049328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "                )\n",
    "            )\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90e22a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "Epoch 1/2\n",
      "547/547 [==============================] - 66s 115ms/step - loss: 248.3755 - reconstruction_loss: 205.1570 - kl_loss: 3.4305\n",
      "Epoch 2/2\n",
      "547/547 [==============================] - 69s 126ms/step - loss: 178.6454 - reconstruction_loss: 167.3625 - kl_loss: 5.1407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb91645a450>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(mnist_digits, epochs=2, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a421872f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEADER: \"Time\",\"V1\",\"V2\",\"V3\",\"V4\",\"V5\",\"V6\",\"V7\",\"V8\",\"V9\",\"V10\",\"V11\",\"V12\",\"V13\",\"V14\",\"V15\",\"V16\",\"V17\",\"V18\",\"V19\",\"V20\",\"V21\",\"V22\",\"V23\",\"V24\",\"V25\",\"V26\",\"V27\",\"V28\",\"Amount\",\"Class\"\n",
      "EXAMPLE FEATURES: [0.0, -1.3598071336738, -0.0727811733098497, 2.53634673796914, 1.37815522427443, -0.338320769942518, 0.462387777762292, 0.239598554061257, 0.0986979012610507, 0.363786969611213, 0.0907941719789316, -0.551599533260813, -0.617800855762348, -0.991389847235408, -0.311169353699879, 1.46817697209427, -0.470400525259478, 0.207971241929242, 0.0257905801985591, 0.403992960255733, 0.251412098239705, -0.018306777944153, 0.277837575558899, -0.110473910188767, 0.0669280749146731, 0.128539358273528, -0.189114843888824, 0.133558376740387, -0.0210530534538215, 149.62]\n",
      "features.shape: (284807, 30)\n",
      "targets.shape: (284807, 1)\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Get the real data from https://www.kaggle.com/mlg-ulb/creditcardfraud/\n",
    "fname = \"/home/macula/SMATousi/VAE_outlier/archive/creditcard.csv\"\n",
    "\n",
    "all_features = []\n",
    "all_targets = []\n",
    "with open(fname) as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i == 0:\n",
    "            print(\"HEADER:\", line.strip())\n",
    "            continue  # Skip header\n",
    "        fields = line.strip().split(\",\")\n",
    "        all_features.append([float(v.replace('\"', \"\")) for v in fields[:-1]])\n",
    "        all_targets.append([int(fields[-1].replace('\"', \"\"))])\n",
    "        if i == 1:\n",
    "            print(\"EXAMPLE FEATURES:\", all_features[-1])\n",
    "\n",
    "features = np.array(all_features, dtype=\"float32\")\n",
    "targets = np.array(all_targets, dtype=\"uint8\")\n",
    "print(\"features.shape:\", features.shape)\n",
    "print(\"targets.shape:\", targets.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676f201a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 227846\n",
      "Number of validation samples: 56961\n"
     ]
    }
   ],
   "source": [
    "num_val_samples = int(len(features) * 0.2)\n",
    "train_features = features[:-num_val_samples]\n",
    "train_targets = targets[:-num_val_samples]\n",
    "val_features = features[-num_val_samples:]\n",
    "val_targets = targets[-num_val_samples:]\n",
    "\n",
    "print(\"Number of training samples:\", len(train_features))\n",
    "print(\"Number of validation samples:\", len(val_features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b91d1a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive samples in training data: 417 (0.18% of total)\n"
     ]
    }
   ],
   "source": [
    "counts = np.bincount(train_targets[:, 0])\n",
    "print(\n",
    "    \"Number of positive samples in training data: {} ({:.2f}% of total)\".format(\n",
    "        counts[1], 100 * float(counts[1]) / len(train_targets)\n",
    "    )\n",
    ")\n",
    "\n",
    "weight_for_0 = 1.0 / counts[0]\n",
    "weight_for_1 = 1.0 / counts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "270cc1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_features, axis=0)\n",
    "train_features -= mean\n",
    "val_features -= mean\n",
    "std = np.std(train_features, axis=0)\n",
    "train_features /= std\n",
    "val_features /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17e5ed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 12:53:40.370089: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-05-30 12:53:40.370667: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "class Sampling(layers.Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(30,))\n",
    "# x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "# x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# x = layers.Flatten()(x)\n",
    "x = layers.Dense(30, activation=\"tanh\")(encoder_inputs)\n",
    "x = layers.Dense(20, activation=\"tanh\")(x)\n",
    "x = layers.Dense(18, activation=\"tanh\")(x)\n",
    "x = layers.Dense(16, activation=\"tanh\")(x)\n",
    "z_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "encoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "\n",
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "# x = layers.Dense(7 * 7 * 64, activation=\"relu\")(latent_inputs)\n",
    "# x = layers.Reshape((7, 7, 64))(x)\n",
    "# x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "# decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "x = layers.Dense(16, activation=\"tanh\")(latent_inputs)\n",
    "x = layers.Dense(18, activation=\"tanh\")(x)\n",
    "x = layers.Dense(20, activation=\"tanh\")(x)\n",
    "decoder_outputs = layers.Dense(30, activation=\"tanh\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8459cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "            self.kl_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_mean, z_log_var, z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "#             reconstruction_loss = tf.reduce_mean(\n",
    "#                 tf.reduce_sum(\n",
    "#                     keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)\n",
    "#                 )\n",
    "#             )\n",
    "            reconstruction_loss = tf.keras.losses.MeanSquaredError()(data,reconstruction)\n",
    "            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n",
    "            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n",
    "            total_loss = reconstruction_loss + kl_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        self.kl_loss_tracker.update_state(kl_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d68e9af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2226/2226 [==============================] - 4s 1ms/step - loss: 1.0310 - reconstruction_loss: 1.0054 - kl_loss: 0.0035\n",
      "Epoch 2/10\n",
      "2226/2226 [==============================] - 2s 1ms/step - loss: 1.0149 - reconstruction_loss: 1.0047 - kl_loss: 2.8087e-05\n",
      "Epoch 3/10\n",
      "2226/2226 [==============================] - 3s 1ms/step - loss: 0.9983 - reconstruction_loss: 1.0048 - kl_loss: 7.8637e-06\n",
      "Epoch 4/10\n",
      "2226/2226 [==============================] - 3s 1ms/step - loss: 0.9902 - reconstruction_loss: 1.0045 - kl_loss: 3.5634e-06\n",
      "Epoch 5/10\n",
      "2226/2226 [==============================] - 3s 1ms/step - loss: 0.9902 - reconstruction_loss: 1.0044 - kl_loss: 2.1467e-06\n",
      "Epoch 6/10\n",
      "2226/2226 [==============================] - 3s 1ms/step - loss: 0.9975 - reconstruction_loss: 1.0044 - kl_loss: 1.5636e-06\n",
      "Epoch 7/10\n",
      "2226/2226 [==============================] - 3s 1ms/step - loss: 0.9956 - reconstruction_loss: 1.0043 - kl_loss: 1.2261e-06\n",
      "Epoch 8/10\n",
      "2226/2226 [==============================] - 3s 1ms/step - loss: 1.0107 - reconstruction_loss: 1.0043 - kl_loss: 8.2702e-07\n",
      "Epoch 9/10\n",
      "2226/2226 [==============================] - 3s 1ms/step - loss: 1.0029 - reconstruction_loss: 1.0044 - kl_loss: 7.6706e-07\n",
      "Epoch 10/10\n",
      "2226/2226 [==============================] - 3s 1ms/step - loss: 0.9945 - reconstruction_loss: 1.0044 - kl_loss: 7.9487e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9d1421ed10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "creditdata = np.concatenate([train_features, val_features], axis=0)\n",
    "creditdata = np.expand_dims(creditdata, -1).astype(\"float32\")\n",
    "\n",
    "vae = VAE(encoder, decoder)\n",
    "vae.compile(optimizer=keras.optimizers.Adam())\n",
    "vae.fit(creditdata, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "565eba6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'python' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_412818/1510789129.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'python' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1406bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = train_features[1,:]\n",
    "\n",
    "test = test.reshape([1,30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d3f7b611",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_mean, z_log_var, z = vae.encoder(test)\n",
    "reconstruction = vae.decoder(z)\n",
    "\n",
    "reconstruction_loss = tf.keras.losses.MeanSquaredError()(test,reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8cc1db9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41741496"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_loss.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "18959388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41229054,  0.02760492,  0.00990844, -0.13348393, -0.03093056,\n",
       "         0.04025487, -0.02018991,  0.01525421, -0.0075708 ,  0.0047708 ,\n",
       "         0.01919036, -0.07557505,  0.04402744, -0.0281549 , -0.02722586,\n",
       "        -0.04202577,  0.0039289 , -0.01101142,  0.02211242,  0.00563244,\n",
       "        -0.01162461,  0.01399416,  0.0240715 ,  0.01843469, -0.0130402 ,\n",
       "        -0.07930604, -0.01005057, -0.0105467 ,  0.00252189, -0.00742954]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "321b2d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.0008564 ,  0.64784056,  0.16869006, -0.01075485,  0.28652602,\n",
       "         0.09012804, -0.08543706, -0.04230526,  0.0670673 , -0.2293523 ,\n",
       "        -0.15108545,  1.4866744 ,  1.0515386 ,  0.4633228 , -0.18291788,\n",
       "         0.62796277,  0.5300628 , -0.14867269, -0.1904353 , -0.16889915,\n",
       "        -0.10145202, -0.29439253, -0.8689419 ,  0.17637353, -0.56267697,\n",
       "         0.25427756,  0.25284111, -0.0230066 ,  0.03819847, -0.3517778 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c1b318f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rec Loss =  7.5094476  -------- Label =  [1]  Case No.  1866\n",
      "Rec Loss =  3.3196588  -------- Label =  [1]  Case No.  1884\n",
      "Rec Loss =  10.030133  -------- Label =  [1]  Case No.  2230\n",
      "Rec Loss =  6.4608707  -------- Label =  [1]  Case No.  2630\n",
      "Rec Loss =  5.0940776  -------- Label =  [1]  Case No.  4132\n",
      "Rec Loss =  5.3070607  -------- Label =  [1]  Case No.  5412\n",
      "Rec Loss =  12.009609  -------- Label =  [1]  Case No.  6728\n",
      "Rec Loss =  5.2277074  -------- Label =  [1]  Case No.  6786\n",
      "Rec Loss =  5.2294545  -------- Label =  [1]  Case No.  6787\n",
      "Rec Loss =  6.815138  -------- Label =  [1]  Case No.  6859\n",
      "Rec Loss =  8.662293  -------- Label =  [1]  Case No.  7770\n",
      "Rec Loss =  8.746953  -------- Label =  [1]  Case No.  7788\n",
      "Rec Loss =  8.010825  -------- Label =  [1]  Case No.  7798\n",
      "Rec Loss =  7.5274982  -------- Label =  [1]  Case No.  9261\n",
      "Rec Loss =  4.9370375  -------- Label =  [1]  Case No.  9580\n",
      "Rec Loss =  15.51634  -------- Label =  [1]  Case No.  10376\n",
      "Rec Loss =  4.067612  -------- Label =  [1]  Case No.  10520\n",
      "Rec Loss =  1.3866913  -------- Label =  [1]  Case No.  10620\n",
      "Rec Loss =  3.4350863  -------- Label =  [1]  Case No.  11653\n",
      "Rec Loss =  3.3325393  -------- Label =  [1]  Case No.  11655\n",
      "Rec Loss =  2.2309318  -------- Label =  [1]  Case No.  12376\n",
      "Rec Loss =  2.5541432  -------- Label =  [1]  Case No.  13408\n",
      "Rec Loss =  7.936458  -------- Label =  [1]  Case No.  13599\n",
      "Rec Loss =  12.206465  -------- Label =  [1]  Case No.  15547\n",
      "Rec Loss =  11.587795  -------- Label =  [1]  Case No.  15701\n",
      "Rec Loss =  17.210018  -------- Label =  [1]  Case No.  15853\n",
      "Rec Loss =  17.072529  -------- Label =  [1]  Case No.  15903\n",
      "Rec Loss =  16.806295  -------- Label =  [1]  Case No.  16002\n",
      "Rec Loss =  16.594913  -------- Label =  [1]  Case No.  16158\n",
      "Rec Loss =  16.426771  -------- Label =  [1]  Case No.  16487\n",
      "Rec Loss =  0.9376562  -------- Label =  [1]  Case No.  17501\n",
      "Rec Loss =  0.81206065  -------- Label =  [1]  Case No.  17710\n",
      "Rec Loss =  6.0854635  -------- Label =  [1]  Case No.  19827\n",
      "Rec Loss =  3.5899422  -------- Label =  [1]  Case No.  20149\n",
      "Rec Loss =  7.440956  -------- Label =  [1]  Case No.  20450\n",
      "Rec Loss =  2.1242206  -------- Label =  [1]  Case No.  21125\n",
      "Rec Loss =  6.2652135  -------- Label =  [1]  Case No.  21321\n",
      "Rec Loss =  1.8157153  -------- Label =  [1]  Case No.  21393\n",
      "Rec Loss =  7.891714  -------- Label =  [1]  Case No.  21761\n",
      "Rec Loss =  9.848066  -------- Label =  [1]  Case No.  21982\n",
      "Rec Loss =  12.240511  -------- Label =  [1]  Case No.  22117\n",
      "Rec Loss =  11.998058  -------- Label =  [1]  Case No.  22915\n",
      "Rec Loss =  11.87045  -------- Label =  [1]  Case No.  23631\n",
      "Rec Loss =  8.578803  -------- Label =  [1]  Case No.  24020\n",
      "Rec Loss =  1.6055672  -------- Label =  [1]  Case No.  24035\n",
      "Rec Loss =  1.5776365  -------- Label =  [1]  Case No.  24045\n",
      "Rec Loss =  9.069529  -------- Label =  [1]  Case No.  24058\n",
      "Rec Loss =  11.88171  -------- Label =  [1]  Case No.  24278\n",
      "Rec Loss =  11.723037  -------- Label =  [1]  Case No.  24928\n",
      "Rec Loss =  0.54398257  -------- Label =  [1]  Case No.  26498\n",
      "Rec Loss =  0.978151  -------- Label =  [1]  Case No.  26549\n",
      "Rec Loss =  5.245369  -------- Label =  [1]  Case No.  27557\n",
      "Rec Loss =  8.04893  -------- Label =  [1]  Case No.  27710\n",
      "Rec Loss =  6.704536  -------- Label =  [1]  Case No.  30557\n",
      "Rec Loss =  3.4096606  -------- Label =  [1]  Case No.  33210\n",
      "Rec Loss =  3.9158437  -------- Label =  [1]  Case No.  33627\n",
      "Rec Loss =  3.7353394  -------- Label =  [1]  Case No.  34079\n",
      "Rec Loss =  11.862329  -------- Label =  [1]  Case No.  34714\n",
      "Rec Loss =  14.05816  -------- Label =  [1]  Case No.  34980\n",
      "Rec Loss =  0.92143786  -------- Label =  [1]  Case No.  35234\n",
      "Rec Loss =  13.818744  -------- Label =  [1]  Case No.  35428\n",
      "Rec Loss =  10.551589  -------- Label =  [1]  Case No.  35478\n",
      "Rec Loss =  10.203214  -------- Label =  [1]  Case No.  36031\n",
      "Rec Loss =  9.1083555  -------- Label =  [1]  Case No.  40529\n",
      "Rec Loss =  12.134983  -------- Label =  [1]  Case No.  44675\n",
      "Rec Loss =  7.0281706  -------- Label =  [1]  Case No.  46536\n",
      "Rec Loss =  2.024425  -------- Label =  [1]  Case No.  46629\n",
      "Rec Loss =  1.1876132  -------- Label =  [1]  Case No.  48146\n",
      "Rec Loss =  0.71580446  -------- Label =  [1]  Case No.  48225\n",
      "Rec Loss =  3.5066657  -------- Label =  [1]  Case No.  49018\n",
      "Rec Loss =  6.0349917  -------- Label =  [1]  Case No.  52017\n",
      "Rec Loss =  3.3941805  -------- Label =  [1]  Case No.  52297\n",
      "Rec Loss =  3.1298482  -------- Label =  [1]  Case No.  52303\n",
      "Rec Loss =  5.8462167  -------- Label =  [1]  Case No.  53298\n",
      "Rec Loss =  0.68649834  -------- Label =  [1]  Case No.  53828\n",
      "mean =  7.058716\n",
      "std =  4.6576095\n"
     ]
    }
   ],
   "source": [
    "rec_loss = []\n",
    "\n",
    "for i in range(val_features.shape[0]):\n",
    "    \n",
    "    if val_targets[i] == 1:\n",
    "        \n",
    "        test = val_features[i,:]\n",
    "\n",
    "        test = test.reshape([1,30])\n",
    "\n",
    "        z_mean, z_log_var, z = vae.encoder(test)\n",
    "        reconstruction = vae.decoder(z)\n",
    "\n",
    "        reconstruction_loss = tf.keras.losses.MeanSquaredError()(test,reconstruction)\n",
    "        \n",
    "        rec_loss.append(reconstruction_loss.numpy())\n",
    "\n",
    "\n",
    "        print(\"Rec Loss = \", reconstruction_loss.numpy(), \" -------- Label = \", val_targets[i], \" Case No. \", i)\n",
    "\n",
    "rec_loss = np.array(rec_loss)\n",
    "print(\"mean = \", np.mean(rec_loss))\n",
    "print(\"std = \", np.std(rec_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8bfe2279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.7462541 ,  -0.50769436,   2.6397295 ,  -4.164056  ,\n",
       "         3.7277195 ,   1.124849  ,  -1.683369  ,  -1.2245529 ,\n",
       "         0.51499057,  -3.5956087 ,  -5.744471  ,   3.3477724 ,\n",
       "        -7.4962306 ,  -1.657718  , -12.934678  ,  -0.2816221 ,\n",
       "        -1.6018841 ,  -3.7281365 ,   0.09827992,  -2.1891088 ,\n",
       "         0.669623  ,   0.54346186,  -1.3017883 ,  -0.5808547 ,\n",
       "        -0.36568624,   0.4449785 ,   0.09471209,   2.115266  ,\n",
       "         1.5862252 ,  -0.36251542], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features[6728,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f3b2326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cba35b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659e3cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac95280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5310fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a173c37b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c6a4505",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygad\n",
    "\n",
    "\n",
    "def fitness_func(ga_instance, solution, solution_idx):\n",
    "    \n",
    "    particle = val_features[6728,:]\n",
    "    particle = particle.reshape([1,30])\n",
    "    \n",
    "#     abn_subspace = solution * val_features[6728,:]\n",
    "    \n",
    "#     abn_subspace = abn_subspace.reshape([1,30])\n",
    "    \n",
    "    \n",
    "\n",
    "    z_mean, z_log_var, z = vae.encoder(particle)\n",
    "    reconstruction_1 = vae.decoder(z)\n",
    "    \n",
    "    replace = reconstruction_1 * solution\n",
    "    \n",
    "    abn_subspace = 1 - solution\n",
    "    \n",
    "    particle_abn = particle * abn_subspace\n",
    "    \n",
    "    particle_rec = particle_abn + replace\n",
    "    \n",
    "    \n",
    "    z_mean, z_log_var, z = vae.encoder(particle_rec)\n",
    "    reconstruction_1 = vae.decoder(z)\n",
    "    \n",
    "    rec_loss = tf.keras.losses.MeanSquaredError()(particle,particle_rec)\n",
    "    fitness = rec_loss.numpy()\n",
    "    \n",
    "    return fitness\n",
    "\n",
    "\n",
    "def on_generation(ga):\n",
    "    print(\"Generation\", ga.generations_completed)\n",
    "    \n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    \n",
    "    print(solution_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "85736d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_func_avg(ga_instance, solution, solution_idx):\n",
    "    \n",
    "    inliers = val_features[10:15,:]\n",
    "    \n",
    "    avg_ins = np.mean(val_features[10:15,:], axis=0)\n",
    "    avg_ins = avg_ins.reshape([1,30])\n",
    "    \n",
    "    particle = val_features[6728,:]\n",
    "    particle = particle.reshape([1,30])\n",
    "    \n",
    "#     abn_subspace = solution * val_features[6728,:]\n",
    "    \n",
    "#     abn_subspace = abn_subspace.reshape([1,30])\n",
    "\n",
    "    avg_in_rec = []\n",
    "    \n",
    "    for index in range(inliers.shape[0]):\n",
    "        \n",
    "        candidate_inlier = inliers[index,:]\n",
    "        candidate_inlier = candidate_inlier.reshape([1,30])\n",
    "        \n",
    "        in_remain = candidate_inlier * solution\n",
    "        \n",
    "        in_normal_subspace = 1 - solution\n",
    "        \n",
    "        in_replace = in_normal_subspace * avg_ins\n",
    "        \n",
    "        in_candidate = in_remain + in_replace\n",
    "        \n",
    "        z_mean, z_log_var, z = vae.encoder(in_candidate)\n",
    "        in_candidate_rec = vae.decoder(z)\n",
    "        \n",
    "        \n",
    "        rec_loss = tf.keras.losses.MeanSquaredError()(in_candidate,in_candidate_rec)\n",
    "        \n",
    "        avg_in_rec.append(rec_loss.numpy())\n",
    "    \n",
    "    avg_in_rec = np.array(avg_in_rec)\n",
    "    avg_in_rec = np.mean(avg_in_rec)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "#     z_mean, z_log_var, z = vae.encoder(particle)\n",
    "#     reconstruction_1 = vae.decoder(z)\n",
    "    \n",
    "    out_remain = particle * solution\n",
    "    \n",
    "    out_normal_subspace = 1 - solution\n",
    "    \n",
    "    out_replace = avg_ins * out_normal_subspace\n",
    "    \n",
    "    out_candidate = out_remain + out_replace\n",
    "    \n",
    "    \n",
    "    z_mean, z_log_var, z = vae.encoder(out_candidate)\n",
    "    out_candidate_rec = vae.decoder(z)\n",
    "    \n",
    "    rec_loss = tf.keras.losses.MeanSquaredError()(out_candidate,out_candidate_rec)\n",
    "    rec_loss = rec_loss.numpy()\n",
    "    \n",
    "    fitness = rec_loss / avg_in_rec\n",
    "    \n",
    "    return fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67171a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_function = fitness_func_avg\n",
    "\n",
    "num_generations = 50\n",
    "num_parents_mating = 4\n",
    "\n",
    "sol_per_pop = 100\n",
    "num_genes = val_features[6728,:].shape[0]\n",
    "\n",
    "init_range_low = -2\n",
    "init_range_high = 5\n",
    "\n",
    "parent_selection_type = \"sss\"\n",
    "keep_parents = 1\n",
    "\n",
    "space = [[0,1] for i in range(num_genes)]\n",
    "\n",
    "crossover_type = \"single_point\"\n",
    "\n",
    "mutation_type = \"random\"\n",
    "mutation_percent_genes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "46dc9472",
   "metadata": {},
   "outputs": [],
   "source": [
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating,\n",
    "                       fitness_func=fitness_function,\n",
    "                       sol_per_pop=sol_per_pop,\n",
    "                       num_genes=num_genes,\n",
    "                       init_range_low=init_range_low,\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_parents=keep_parents,\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_percent_genes=mutation_percent_genes,\n",
    "                       on_generation=on_generation,\n",
    "                       gene_space = space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e868f986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1\n",
      "37.11245\n",
      "Generation 2\n",
      "41.05748\n",
      "Generation 3\n",
      "45.728626\n",
      "Generation 4\n",
      "45.678024\n",
      "Generation 5\n",
      "45.5867\n",
      "Generation 6\n",
      "45.5867\n",
      "Generation 7\n",
      "45.998726\n",
      "Generation 8\n",
      "46.43835\n",
      "Generation 9\n",
      "46.453487\n",
      "Generation 10\n",
      "46.453487\n",
      "Generation 11\n",
      "46.453487\n",
      "Generation 12\n",
      "46.453487\n",
      "Generation 13\n",
      "46.453487\n",
      "Generation 14\n",
      "46.453487\n",
      "Generation 15\n",
      "47.00801\n",
      "Generation 16\n",
      "47.113224\n",
      "Generation 17\n",
      "47.113224\n",
      "Generation 18\n",
      "47.113224\n",
      "Generation 19\n",
      "47.503582\n",
      "Generation 20\n",
      "47.38894\n",
      "Generation 21\n",
      "47.38894\n",
      "Generation 22\n",
      "47.38894\n",
      "Generation 23\n",
      "47.38894\n",
      "Generation 24\n",
      "47.38894\n",
      "Generation 25\n",
      "47.38894\n",
      "Generation 26\n",
      "47.409275\n",
      "Generation 27\n",
      "47.38894\n",
      "Generation 28\n",
      "47.38894\n",
      "Generation 29\n",
      "47.38894\n",
      "Generation 30\n",
      "47.38894\n",
      "Generation 31\n",
      "47.38894\n",
      "Generation 32\n",
      "47.38894\n",
      "Generation 33\n",
      "47.38894\n",
      "Generation 34\n",
      "47.644253\n",
      "Generation 35\n",
      "47.424953\n",
      "Generation 36\n",
      "47.424953\n",
      "Generation 37\n",
      "47.424953\n",
      "Generation 38\n",
      "47.424953\n",
      "Generation 39\n",
      "47.424953\n",
      "Generation 40\n",
      "47.424953\n",
      "Generation 41\n",
      "47.424953\n",
      "Generation 42\n",
      "47.424953\n",
      "Generation 43\n",
      "47.424953\n",
      "Generation 44\n",
      "47.424953\n",
      "Generation 45\n",
      "47.424953\n",
      "Generation 46\n",
      "47.424953\n",
      "Generation 47\n",
      "47.424953\n",
      "Generation 48\n",
      "47.424953\n",
      "Generation 49\n",
      "47.91089\n",
      "Generation 50\n",
      "47.81949\n"
     ]
    }
   ],
   "source": [
    "ga_instance.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c8ab1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the best solution : [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0.]\n",
      "Fitness value of the best solution = 47.819488525390625\n"
     ]
    }
   ],
   "source": [
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101bd600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e80634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc91e5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60e16f19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.67609   ,  0.29879466, -0.51317704,  0.03845291, -0.26599112,\n",
       "       -0.4089473 , -0.11063142, -0.08701693,  0.02064687,  0.32344753,\n",
       "       -0.24708238, -0.94346046,  0.38582838,  0.5944903 , -0.40336066,\n",
       "       -0.1687354 ,  0.26231766, -0.567821  ,  0.17933348, -0.24484256,\n",
       "        0.30691004,  0.12367544,  0.04679886, -0.19573799,  0.12336917,\n",
       "       -0.37529045, -0.22803795, -0.13733166, -0.05003484,  0.4847347 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_features[10:15,:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6507dcd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 30)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features[10:15,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b716a905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43cb3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
