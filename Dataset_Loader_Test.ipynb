{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c60452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f6ebed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "(46463, 9)\n"
     ]
    }
   ],
   "source": [
    "# Replace 'your_file.csv' with the path to your CSV file\n",
    "csv_file = './dataverse_files/shuttle-unsupervised-ad.csv'\n",
    "\n",
    "# Read the CSV file using pandas\n",
    "data = pd.read_csv(csv_file)\n",
    "\n",
    "# Extract the last column and convert it to a numpy array\n",
    "last_column = data.iloc[:, -1].values\n",
    "\n",
    "# Convert \"o\" to 0 and \"n\" to 1 in the last column\n",
    "last_column = np.where(last_column == \"o\", 0, 1)\n",
    "\n",
    "# Print the first few rows of the last column as a numpy array\n",
    "print(last_column)\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "data_n = data[:,:-1]\n",
    "labels = last_column\n",
    "\n",
    "print(data_n.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d39313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "702f1a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_n = data[:,:-1]\n",
    "labels = last_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ab8d90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9babd8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46463,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af5e727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a39218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e6b109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6d68b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68823ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/data/mnist_combined.csv'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "def prepare_mnist_dataset(class_1=0, class_2=6, n_outliers=100):\n",
    "    # Load MNIST dataset\n",
    "    mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "\n",
    "    # Extract data and labels\n",
    "    data, labels = mnist['data'], mnist['target'].astype(np.int)\n",
    "\n",
    "    # Select two classes\n",
    "    class_1_data = data[labels == class_1]\n",
    "    class_2_data = data[labels == class_2]\n",
    "\n",
    "    # Select a subset of class_2 as outliers\n",
    "    np.random.shuffle(class_2_data)\n",
    "    outliers = class_2_data[:n_outliers]\n",
    "\n",
    "    # Combine class_1 data and outliers\n",
    "    combined_data = np.vstack([class_1_data, outliers])\n",
    "\n",
    "    # Create labels for normal (n) and outliers (o)\n",
    "    labels = np.array(['n'] * len(class_1_data) + ['o'] * n_outliers)\n",
    "\n",
    "    # Save to a CSV file\n",
    "    df = pd.DataFrame(combined_data)\n",
    "    df['label'] = labels\n",
    "    df.to_csv('./dataverse_files/mnist_06_combined.csv', index=False)\n",
    "\n",
    "    return '/mnt/data/mnist_combined.csv'\n",
    "\n",
    "# Example usage: combine class 0 as inliers and class 1 as outliers\n",
    "csv_file_path = prepare_mnist_dataset(class_1=0, class_2=6, n_outliers=100)\n",
    "\n",
    "csv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8834b6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 14:11:21.135407: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-17 14:11:29.520342: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-11-17 14:11:29.520791: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/macula/SMATousi/.conda/envs/mac-deep/lib/:/home/macula/SMATousi/.conda/envs/mac-deep/lib/python3.7/site-packages/nvidia/cudnn/lib\n",
      "2023-11-17 14:11:29.520829: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "29515/29515 [==============================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26421880/26421880 [==============================] - 1s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "5148/5148 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4422102/4422102 [==============================] - 0s 0us/step\n",
      "CSV file saved at: ./dataverse_files/fashion_mnist_TB_combined.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "def prepare_fashion_mnist_dataset(class_1=0, class_2=1, n_outliers=100):\n",
    "    # Load Fashion MNIST dataset\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "    # Combine training and testing data\n",
    "    images = np.concatenate([train_images, test_images])\n",
    "    labels = np.concatenate([train_labels, test_labels])\n",
    "\n",
    "    # Flatten the images to 1D arrays\n",
    "    images_flattened = images.reshape(images.shape[0], -1)\n",
    "\n",
    "    # Select two classes\n",
    "    class_1_data = images_flattened[labels == class_1]\n",
    "    class_2_data = images_flattened[labels == class_2]\n",
    "\n",
    "    # Select a subset of class_2 as outliers\n",
    "    np.random.shuffle(class_2_data)\n",
    "    outliers = class_2_data[:n_outliers]\n",
    "\n",
    "    # Combine class_1 data and outliers\n",
    "    combined_data = np.vstack([class_1_data, outliers])\n",
    "\n",
    "    # Create labels for normal (n) and outliers (o)\n",
    "    labels = np.array(['n'] * len(class_1_data) + ['o'] * n_outliers)\n",
    "\n",
    "    # Save to a CSV file\n",
    "    df = pd.DataFrame(combined_data)\n",
    "    df['label'] = labels\n",
    "    csv_file_path = './dataverse_files/fashion_mnist_TB_combined.csv'\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "    return csv_file_path\n",
    "\n",
    "# Example usage: combine class 0 (T-shirt/top) as inliers and class 1 (Trouser) as outliers\n",
    "csv_file_path = prepare_fashion_mnist_dataset(class_1=0, class_2=2, n_outliers=100)\n",
    "print(f\"CSV file saved at: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd11b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
